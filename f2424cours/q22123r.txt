Gradient Descent Intuition.В предыдущем видео мы дали математическое определение градиентного спуска.Теперь давайте рассмотрим алгоритм подробнее, чтобы лучше понять, как он работает и почему каждый шаг градиентного спуска имеет смысл.Вот определение алгоритма градиентного спуска, которое мы дали в прошлый раз.Напомню, что вот этот коэффициент, альфа — это скорость обучения. Он задает размер изменения параметра тета-j на каждом шаге. Второй множитель — это частная производная.В этом видео я хочу дать вам более глубокое понимание того, как работают эти элементы и какой смысл они вместе придают изменению параметра.Чтобы передать вам это понимание, я хочу немного упростить задачу и снова минимизировать функцию одного переменного.То есть наша функция J будет зависеть только от одного параметра, тета первого, так же, как в одном из предыдущих видео.Где тета первое — действительное число.Тогда у нас будут плоские графики, которые проще воспринимать.И давайте попробуем понять, как градиентный спуск работает с этой функцией. [клик]Положим, моя функция выглядит так. J от тета первого, и тета первое — действительное число.Допустим, я начал градиентный спуск вот с этого значения тета первого. То есть мы начинаем идти с этой точки на графике моей функции.Градиентный спуск будет изменятьзначение тета первого на тета первое минус альфа умножить на d по d тета первому от функции J от тета первого, так?Краткое отступление: видите это обозначение производной, да?Если вы не поняли, почему я обозначаю ее по-другому по сравнению с прошлым разом, не как частную производную,если вы не знаете разницы между частной производной и вот этим «d по d тета», ничего страшного.Формально говоря, математики называют это частной производной, а это — производной из-за того, что эти функции зависят от разного числа переменных. Но для нас сейчас эта техническая подробность несущественна, считайте эти символы частной производной и «d по d тета» одним и тем же.Так что об отличиях можете сейчас не задумываться. Я буду использовать строгое математическое обозначение,но для наших учебных целей это одно и то же. Обратимся к тому, что делает это присваивание.Нам нужно вычислить эту производную... Не знаю, приходилось ли вам иметь дело с производными,но производная в этой точке, это, по сути, вот что:Проведите касательную  в этой точке, просто прямую красную линию. Посмотрим на наклон этой линии.Он как раз соответствует производной.То есть производная это наклон касательной, так, а наклон прямой это, конечно же, вот эта высота, деленная на длину этого горизонтального отрезка.Так.Наклон этой прямой положителен, значит, производная в этой точке положительна.Значит, вычисляя новое значение тета первого, я вычту из тета первого некоторое положительное число, умноженное на альфа.Верно?А альфа, параметр скорости обучения, всегда положительное число.Так что я возьму тета первое и присвою новое значение, тета первое минус что-то.В результате тета первое сдвинется влево.Я уменьшил тета первое, и, как видно, это правильно, потому что я сделал шаг в этом направлении, то есть в направлении минимума функции.Так что, похоже, градиентный спуск делает что-то разумное.Разберем еще один пример.Пусть у меня есть та же функция J.Я попробую нарисовать такой же график для J от тета первого.И теперь предположим, что начальное значение моего параметра вот здесь, слева.В этой точке.Ей соответствует вот эта точка на поверхности.Теперь, чтобы взять производную, d по d тета первое от J, в этой точке, мне нужно посмотретьна наклон вот этой прямой.Производная в этой точке — это наклон этой прямой.Но эта прямая уходит вниз, а значит, ее наклон отрицателен.Согласны?Или, другими словами, ее производная в этой точке отрицательна, это то же самое, что отрицательный наклон касательной.То есть этот член меньше или равен нулю,и когда я буду вычислять новое значение тета первого, я вычту альфа, умноженное на некоторое отрицательное число.Вычитая из тета первого отрицательное число я в результате увеличу значение параметра, верно?Потому что вычитая отрицательное число я на самом деле добавляю что-то положительное, то есть увеличиваю тета первое.Так что, начав отсюда, мы увеличим значение тета первого, что, похоже, снова приближает меня к минимуму функции.Надеюсь, это дало вам некоторое понимание сути вот этой производной.Теперь давайте разберемся с коэффициентом альфа, скоростью обучения, и посмотрим, как он работает.Вот шаг нашего алгоритма, правило изменения параметра.Давайте посмотрим, что будет, если выбрать альфа слишком маленьким или слишком большим.Для первого примера возьмем очень маленькое значение альфа.Вот график моей функции J от тета первого.Начнем, к примеру, здесь.Если альфа мало, значит, я буду домножать корректирующую величину на какое-то маленькое число.И шаг, который я сделаю, будет крохотным.Да? Один шаг вот сюда.Из этой точки я сделаю еще один шаг.Но, поскольку альфа мало, то шаг снова будет крохотным.То есть, если скорость обучения слишком маленькая,мне придется делать вот эти крошечные сдвиги в сторону минимума, и может понадобиться очень много шагов, прежде чем я дойду.При маленьком альфа спуск будет слишком медленным, потому что шаги будут слишком маленькими.И потребуется сделать много шагов, чтобы оказаться хотя бы примерно в районе глобального минимума.Теперь рассмотрим случай, когда альфа слишком большое. Снова нарисую график функции J от тета. Оказывается, при слишком большом альфа, градиентный спуск может проскочить точку минимума. Он может никогда не остановиться и может даже разойтись.Вот что я имею в виду.Положим, я начну с вот этой точки, довольно близко к минимуму.Производная указывает направо, но при слишком большом значении альфа я сделаю слишком большой шаг.Например, вот такой огромный шаг.Согласны?Я сделал огромный шаг, и теперь значение моей функции затрат возросло.Я начинал с этого значения, а сейчас стоимость стала выше.Теперь моя производная указывает влево, так что мы уменьшим тета.Но поскольку скорость обучения велика, я в итоге снова сделаю огромный шаг, и попадувот сюда.Так?При такой большой скорости обучения на следующей итерации я тоже сделаю огромный шаг и снова проскочу минимум, и так далее... и уже заметно, что я вообще-то все больше удаляюсь от минимального значения.Так что, если альфа слишком велико, алгоритм может никогда не остановиться или вообще разойтись.Теперь я хочу задать вам вопрос.Внимание, вопрос с подвохом.Когда я сам изучал эту тему, мне потребовалось много времени, чтобы это понять.Что если ваше начальное значение тета первого уже соответствует локальному минимуму?Что тогда сделает шаг градиентного спуска?Итак, предположим, начальное значение тета первого попало в локальный минимум.То есть, смотрите, пусть вот это ваше начальное значение тета первого, и ему соответствует этот локальный экстремум, локальный минимум.В этом случае, в локальном экстремуме, производная будет равна нулю.Поскольку касательная в этой точке горизонтальна, ее наклон равен нулю, значит, этот член выраженияравен нулю.Таким образом, на шаге градиентного спуска, вы присваиваете тета первому величину тета первого минус альфа умножить на ноль. То есть, если вы уже в локальном экстремуме, ваш параметр останется неизменным, вы присвоите тета первому значение тета первого. То есть в этом случае шаг алгоритма градиентного спуска не делает ничего.Он не меняет значение параметра, хотя, по нашей задумке, должен.Оставляет его в точке локального экстремума.Это также объясняет, как градиентный спуск может остановиться в локальном минимуме даже при фиксированном коэффициенте скорости обучения.Сейчас я поясню, что имею в виду.Посмотрим на такой пример.Вот функция J от тета,которую я хочу минимизировать, и допустим, я инициализирую алгоритм градиентного спуска вот в этой точке, отмеченной пурпурным.Один шаг алгоритма приведет меня, скажем, сюда, потому что здесь моя производная имеет довольно большой уклон, так? Теперь я нахожусь в этой зеленой точке, и на следующем шаге спуска моя производная, то есть наклон касательной, будет меньше, чем в пурпурной точке, верно?Поскольку по мере приближения к минимуму значение производной приближается к нулю. Так что я сделал шаг градиентного спуска, и теперь моя производная стала меньше. Сделаю еще один шаг.Из зеленой точки он будет немного меньше, чем тот, что я сделал из пурпурной.Теперь я нахожусь в этой точке, красной, еще ближе к глобальному минимуму, и производная здесь еще меньше, чем была в зеленой точке.И на следующем шаге градиентного спуска из-за значения производной величина изменения тета первого будет еще меньше, то есть мы сделаем вот такой небольшой шаг. И по мере работы алгоритмамы будем автоматически делать все меньшие шаги, до тех пор пока не окажемся в точке минимума.Вкратце повторю, о чем мы говорили.Алгоритм градиентного спуска по мере приближения к локальному минимуму будет делат ь все меньшие шаги, поскольку, чем ближе к локальному минимуму, тем... по определению, в локальном минимуме значение производной равно нулю...Так вот, по мере приближения к локальному минимуму этот член выражения будет становиться все меньше, и градиентный спуск на каждом шаге будет все меньше изменять параметр.Таким образом, нет нужды уменьшать альфа по мере работы алгоритма.Итак, это алгоритм градиентного спуска, с помощью которого можно минимизировать любую функцию затрат, не только функцию затрат J, которая возникла в задаче линейной регрессии.В следующем видео мы вернем функции J вид функции затрат из задачи линейной регрессии,функции среднеквадратических отклонений, построенной ранее,и применим к ней алгоритм градиентного спуска.В результате мы получим наш первый обучающий алгоритм, алгоритм линейной регрессии.