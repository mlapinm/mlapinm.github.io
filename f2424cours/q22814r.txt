Reconstruction from Compressed Representation.В некоторых предыдущих видео я говорил о PCA как о алгоритме сжатия, где вы можете сказать, 1,000-мерные данные и сжимать его в 100-мерный векторный объект. Или иметь трехмерные данные и сжать их в двумерное представление. Итак, если это алгоритм сжатия, должен быть способ вернуться от этого сжатого представления назад к приближению ваших исходных высокомерных данных. Итак, учитывая zi, которые могут быть 100-мерными, как вы вернетесь к вашему первоначальному представлению, xi, который, возможно, был 1000-мерным. В этом видео я хотел бы описать, как это сделать.
Play video starting at ::40 and follow transcript0:40
В алгоритме PCA у нас может быть такой пример, так что , может быть, это мой пример x1, и, возможно, это мой пример x2. Мы берем эти примеры, и проецируем их на эту одномерную поверхность. И теперь нам нужно использовать действительное число, скажем z1, чтобы указать местоположение этих точек после того, как они были проецированы на эту одномерную поверхность. Итак, учитывая точку z1, как мы можем вернуться к этому оригинальному двухмерному пространству? В частности, учитывая точку z, которая является R, можем ли мы сопоставить это с некоторым приблизительным представлением x и R2 независимо от исходного значения данных? Итак, в то время как z равно U уменьшить транспонирование x, если вы хотите идти в противоположном направлении, уравнение для , то есть, мы собираемся написать х ок. U уменьшить, раз z. И снова, чтобы проверить размеры, здесь U уменьшить будет n по k размерному вектору, z собирается быть k по одномерному вектору. Таким образом, вы умножаете их, которые будут n на единицу, так что x apm будет n размерным вектором. И поэтому намерение PCA, то есть, если квадратная ошибка проекции не слишком велика, заключается в том, что этот x приблизительно будет близок к тому, что было исходным значением x, которое вы использовали для получения z в первую очередь. Чтобы показать картину того, как это выглядит, вот как это выглядит. То, что вы получаете обратно от этой процедуры, это точки, которые лежат на проекции этого, на зеленую линию. Итак, чтобы взять наш ранний пример, если мы начали с этого значения x1, и мы получили это значение z1, если вы подключите z1 через эту формулу, чтобы получить x1 ок. то эта точка здесь, это будет x1 ок., который будет в R2. И аналогично, если вы сделаете ту же процедуру, это будет x2 прибл. И это довольно приличное приближение к исходным данным. Вот как вы возвращаетесь из низкомерного представления z, обратно к несжатому представлению данных. Мы возвращаем аппроксимацию к исходным данным x. И мы также называем этот процесс реконструкции исходных данных , где мы думаем о попытке воссоздать исходное значение x из сжатого представления.
Play video starting at :3:16 and follow transcript3:16
Итак, учитывая немаркированный набор данных, теперь вы знаете, как применить PCA и взять ваши высокие размерные объекты x и сопоставить их с этим низкомерным представлением z. И из этого видео, надеюсь, вы также знаете, как взять эти низкопредставленные z и отобразить их обратно в приближение ваших исходных высокомерных данных.
Play video starting at :3:37 and follow transcript3:37
Теперь, когда вы знаете, как реализовать и применять PCA, то, что я хотел бы сделать дальше, это поговорить о некоторых механиках того, как эффективно использовать PCA. И, в частности, в следующем видео, я хотел бы поговорить о том, как выбрать k, как выбрать размерность уменьшенного вектора представления z.