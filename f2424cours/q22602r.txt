Evaluating a Hypothesis.В этом видео я хотел бы поговорить о том, как оценить гипотезу, которая была изучена вашим алгоритмом. В последующих видео мы будем строить на этом , чтобы поговорить о том, как предотвратить проблемы переоснащение и недооснащение, а также. Когда мы подбираем параметры нашего алгоритма обучения , мы думаем о выборе параметров для минимизации ошибки обучения. Можно подумать, что получение действительно низкого значения обучающей ошибки может быть хорошей вещью, но мы уже видели, что только потому, что гипотеза имеет низкую обучающую ошибку, , что не означает, что это обязательно хорошая гипотеза. И мы уже видели пример того, как гипотеза может переместиться. И поэтому не обобщить новые примеры не в тренировочном наборе. Итак, как вы можете сказать, может ли гипотеза быть перегруженной. В этом простом примере мы могли бы построить гипотезу h из x и просто посмотреть, что происходит. Но в целом для проблем с большим количеством функций, чем только одна функция, для проблем с большим количеством функций, подобных этим становится трудно или может быть невозможно построить, как выглядит гипотеза , и поэтому нам нужен какой-то другой способ оценить нашу гипотезу. Стандартный способ оценки усвоенных гипотез выглядит следующим образом. Предположим, что у нас есть такой набор данных. Здесь я только что показал 10 обучающих примеров, , но, конечно, обычно у нас могут быть десятки или сотни или, может быть, тысячи обучающих примеров. Чтобы убедиться, что мы можем оценить нашу гипотезу, то, что мы собираемся сделать, это разделить данные, которые у нас есть на две части. Первая часть будет нашим обычным обучающим набором , а вторая часть будет нашим тестовым набором, и довольно типичным разделением этого все данные, которые у нас есть в тренировочном наборе и тестовом наборе может быть около 70%, 30% разделить. Сегодня стоит больше, чтобы сорвать тренировочный набор и относительно меньше тестового набора. И так теперь, если у нас есть какой-то набор данных, мы запускаем синус скажем 70% данных, чтобы быть нашим учебным набором, где здесь «m» , как обычно, наше количество обучающих примеров , а остальная часть наших данных может быть назначена для того, чтобы стать нашим тестовым набором. И здесь я собираюсь использовать нотацию m индекс test , чтобы обозначить количество тестовых примеров. И в общем, этот индекс тест будет обозначать примеры , которые приходят из тестового набора, так что x1 индекс тест, y1 индекс индекс - мой первый пример, который, я думаю, в этом примере может быть этим примером здесь. Наконец, одна последняя деталь , тогда как здесь я нарисовал это так, как будто первые 70% идет на тренировочный набор, а последние 30% - на тестовый набор. Если есть какие-то обычные для данных. Лучше отправить случайное 70% ваших данных на тренировочный набор и случайное 30% ваших данных на тестовый набор. Так что, если ваши данные уже были отсортированы случайным образом, вы могли бы просто взять первые 70% и последние 30% , что если бы ваши данные не были упорядочены случайным образом, было бы лучше случайным образом перетасовать или , чтобы случайным образом изменить порядок примеров в вашем тренировочном наборе. Прежде чем вы узнаете отправку первых 70% в тренировочном наборе и последних 30% тестового набора. Вот тогда довольно типичная процедура для того, как вы будете тренировать и тестировать алгоритм обучения и регрессию обучения. Во-первых, вы узнаете параметры theta из набора тренировок , так что вы минимизируете обычную ошибку обучения j theta, где j theta здесь был определен, используя этот 70% всех данных, которые у вас есть. Есть только данные о тренировках. И тогда вы вычислите тестовую ошибку. И я собираюсь обозначить ошибку теста как тест индекса j. Итак, что вы делаете, это взять свой параметр theta , который вы узнали из набора обучения, и подключить его здесь и вычислить ошибку набора тестов. Который я собираюсь написать следующим образом. Таким образом, это в основном средняя квадратная ошибка , измеренная на вашем тестовом наборе. Это в значительной степени то, что вы ожидаете. Поэтому, если мы запустим каждый тестовый пример через вашу гипотезу с параметром theta и просто измерим квадрат ошибки , которую ваша гипотеза имеет на вашем m подстрочном тесте, тестовые примеры. И, конечно, это определение ошибки набора тестов , если мы используем линейную регрессию и используем квадрат метрику ошибок. Как насчет того, если бы мы делали проблему классификации и сказали, что вместо этого использовали логистическую регрессию. В таком случае процедура обучения и тестирование говорят, что логистическая регрессия очень похожа сначала мы сделаем параметры из данных обучения, , что первые 70% данных. И он вычислит ошибку теста следующим образом. Это та же целевая функция , как мы всегда используем, но мы просто логистическая регрессия, за исключением того, что теперь определяет с помощью наш m подстрочный тест, тестовые примеры. Хотя это определение тестового набора ошибки j индекс теста вполне разумно. Иногда существует альтернативная метрика наборов тестов, которая может быть проще интерпретировать, , и это ошибка неправильной классификации. Это также называется ошибкой неправильной классификации 0, с нулевым значением, означающим, что вы либо получаете правильный пример, либо вы ошиблись. Вот что я имею в виду. Позвольте определить ошибку предсказания. То есть h от x. И учитывая метку y как равно единице, если моя гипотеза выводит значение больше, чем равное пяти и Y равно нулю, или если моя гипотеза выводит значение менее 0,5, а у равна единице, право собственности, так что оба этих случая основные ответить если ваша гипотеза ошибочно пометила пример , предполагая, что ваш порог равен 0,5. Так что либо думал, что это скорее будет 1, но на самом деле это было 0, или ваша гипотеза, скорее всего, была 0, но метка была 1. И в противном случае, мы определяем эту функцию ошибки равную нулю. Если ваша гипотеза в основном классифицировала пример y правильно. Затем мы могли бы определить ошибку теста, , используя метрику ошибки неправильной классификации, чтобы быть один из m тестов суммы от i равно одному к m подстрочному тесту ошибки h от x (i) test bood запятой y (i). И так это просто мой способ написать, что это точно часть примеров в моем тестовом наборе , что моя гипотеза неправильно помечена. И вот определение ошибки тестового набора с использованием ошибки неправильной классификации метрики неправильной классификации 0 1. Так что это стандартный метод оценки , насколько хороша научная гипотеза. В следующем видео мы адаптируем эти идеи , чтобы помочь нам делать такие вещи, как выбор особенностей , как степень полинома для использования с алгоритмом обучения или выбрать параметр регуляризации для алгоритма обучения.