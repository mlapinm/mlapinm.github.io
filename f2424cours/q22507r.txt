Putting It Together.Итак, нам потребовали много видео, чтобы пройти алгоритм обучения нейронной сети.
Play video starting at ::5 and follow transcript0:05
В этом видео, то, что я хотел бы сделать, это попытаться собрать все части вместе, чтобы дать общее резюме или более широкую картину, о том, как оценка все части подходят вместе и стоп общего процесса, как starete реализовать алгоритм обучения нейронной сети.
Play video starting at ::21 and follow transcript0:21
При обучении нейронной сети первое, что вам нужно сделать , это выбрать некоторую сетевую архитектуру и по архитектуре я просто имею в виду шаблон связи между нейронами. Итак, вы знаете, мы могли бы выбрать между скажем, нейронной сетью с тремя входными единицами и пятью скрытыми единицами и четырьмя выходными единицами против одной категории 3, 5 скрытых, 5 stots скрытых, 4 выхода и информации здесь 3, 5, stone 5, 5 единиц в каждом из трех скрытых слоев и 4 открытых , и так эти выбор, сколько скрытых единиц в каждом слое и сколько скрытых слоев, эти являются выбором архитектуры. Итак, как вы делаете этот выбор?
Play video starting at ::59 and follow transcript0:59
Ну, во-первых, количество входных единиц хорошо, что довольно хорошо определено. И как только вы решите на исправление набор объектов x, количество входных единиц будет просто, вы знаете, размер ваших объектов x (i) будет определяться этим. И если вы делаете многоклассные классификации, количество выходных данных это будет определяться числом классов в вашей задаче классификации. И просто напоминание, если у вас есть многоклассная классификация, где y берет на сказать значения между
Play video starting at :1:30 and follow transcript1:30
1 и 10, так что у вас есть десять возможных классов.
Play video starting at :1:34 and follow transcript1:34
Тогда не забудьте вправо, ваш вывод y, поскольку это были векторы. Таким образом, вместо пункта 1 вы перекодируете его как вектор , как это, или для второго класса вы перекодируете его как вектор. Так что если одно из этих яблок принимает на пятый класс, вы знаете, у равен 5, то то, что вы показываете вашей нейронной сети на самом деле не является значением y равно 5, вместо этого здесь, у верхнего слоя, который будет иметь десять выходных единиц, вы будете , который вы знаете
Play video starting at :2:7 and follow transcript2:07
с одним в пятой позиции и кучей нулей здесь. Таким образом, выбор числа входных единиц и количества выходных единиц , возможно, несколько достаточно прост.
Play video starting at :2:18 and follow transcript2:18
А что касается количества скрытых единиц и количества скрытых слоев, то разумным по умолчанию является использование одного скрытого слоя и поэтому этот тип stot-нейронной сети, показанной слева с stot-всего одним скрытым слоем, вероятно, наиболее распространенным.
Play video starting at :2:34 and follow transcript2:34
Или, если вы используете больше , чем один скрытый слой, снова разумное значение по умолчанию будет равно, что будет иметь одинаковое количество скрытых единиц в каждом слое. Итак, здесь у нас есть два скрытых слоя, и каждый из этих скрытых слоев имеет то же количество 5 скрытых единиц , и здесь у нас есть, вы знаете, both три скрытых слоя и stots каждый из них имеет одинаковый номер, то есть пять скрытых единиц.
Play video starting at :2:57 and follow transcript2:57
Вместо того, чтобы делать такого рода сетевой архитектуры слева было бы идеальным разумным дефолтом.
Play video starting at :3:4 and follow transcript3:04
А что касается количества скрытых единиц - обычно, чем больше скрытых единиц, тем лучше; это просто то, что если у вас есть много скрытых единиц, то это bote может стать более вычислительно дорогим, но stoth очень часто, имея больше скрытых единиц - это хорошо.
Play video starting at :3:17 and follow transcript3:17
И обычно количество скрытых единиц в каждом слое будет, возможно, сопоставимо с размерностью x, сопоставимой с количеством объектов, или это может быть любое место, где от того же количества sts скрытых единиц входных объектов к starmete может быть, так что три или четыре раза больше. Таким образом, наличие количества скрытых единиц сопоставимо. Вы знаете, несколько раз, или некоторые, что больше, чем количество входных объектов, часто полезно сделать так, , надеюсь, это дает вам один debut разумный набор вариантов по умолчанию stoth для нейронной архитектуры и и herote, если вы следуете этим рекомендациям, вы ceto, вероятно, получить что-то, что работает хорошо, но в более позднем наборе видео, где я расскажу конкретно о том, как применять алгоритмы , я на самом деле произнесу гораздо больше о том, как выбрать архитектуру нейронной сети. Или на самом деле есть довольно много я хочу, чтобы сказать позже, чтобы сделать хороший выбор для количества скрытых единиц, количества скрытых слоев и так далее.
Play video starting at :4:10 and follow transcript4:10
Далее, вот что нам нужно реализовать, чтобы торговля в нейронной сети, есть на самом деле шесть шагов, которые у меня ; У меня четыре на этом слайде и еще два шага на следующем слайде. Первым шагом является настройка нейросети и случайным образом инициализировать значения весов. И мы обычно инициализируем весы до небольших значений, близких к нулю.
Play video starting at :4:31 and follow transcript4:31
Затем мы реализуем форвард распространения , чтобы мы могли ввести любую отличную нейросеть и вычислить h из x, который является этим вектором вывода значений y.
Play video starting at :4:44 and follow transcript4:44
Затем мы также реализуем код для вычислить эту функцию стоимости j theta.
Play video starting at :4:49 and follow transcript4:49
И далее мы реализуем back-prop, или алгоритм обратного распространения
Play video starting at :4:54 and follow transcript4:54
, чтобы вычислить эти условия частичных производных, частичные производные j тета, по отношению к параметрам. Конкретно, для реализации обратной опоры. Обычно мы будем делать это с переднем циклом над примерами обучения.
Play video starting at :5:9 and follow transcript5:09
Некоторые из вас, возможно, слышали о продвинутых и, откровенно говоря, очень продвинутых методах факторизации, где у вас нет четырех циклов по отношению к примерам m-обучения, что в первый раз, когда вы реализуете обратный реквизит, должны почти наверняка четыре цикла here в вашем коде, где вы итерации по примерам, вы знаете, x1, y1, затем вы делаете вперед prop и назад prop на первом примере , а затем в вторую итерацию four-loop, вы делаете вперед распространение sph и обратно распространение на втором примере и так далее. Пока вы не пройдете через последний пример. Таким образом, в вашей реализации должно быть четыре цикла обратной опоры, по крайней мере, в первый раз его реализации. И тогда есть откровенно несколько сложные способы сделать это без четырех циклов, но я определенно не рекомендую , пытаясь сделать это гораздо более сложной версии, когда вы впервые пытаетесь реализовать обратный реквизит.
Play video starting at :5:59 and follow transcript5:59
Итак, конкретнее, у нас есть четыре цикла над моими примерами m-обучения
Play video starting at :6:3 and follow transcript6:03
, а внутри четырёхцикла мы будем выполнять fore prop и back prop, используя только этот пример.
Play video starting at :6:9 and follow transcript6:09
И что это означает, что мы собираемся взять x (i), и кормить, что на мой входной слой, выполнить форвард-опора, выполнить back-prop
Play video starting at :6:17 and follow transcript6:17
и что будет, если все bets эти активации и все stots эти дельта термины для всех слоев всех моих hen-единиц в нейронной то все еще внутри этого четырёхцикла, позвольте мне нарисовать фигурные скобки , чтобы показать область с четыре цикла, это, конечно, октавный код
Play video starting at :6:34 and follow transcript6:34
, но это больше код Java, и четыре цикла охватывает все это. Мы собираемся вычислить эти термины дельта , которые являются формулой, которую мы дали ранее.
Play video starting at :6:45 and follow transcript6:45
Плюс, вы знаете, дельта l плюс один раз
Play video starting at :6:48 and follow transcript6:48
a, l транспонировать код. И затем, наконец, вне , вычислив эти термины дельта , эти термины накопления, мы бы тогда иметь какой-то другой код , а затем это позволит нам вычислить эти частичные производные термины. Право и эти частичные производные условия должны учитывать термин регуляризации лямбда, а также. И так, эти формулы были приведены в предыдущем видео.
Play video starting at :7:14 and follow transcript7:14
Итак, как вы сделали это , у вас теперь, надеюсь, есть код для вычислить эти частичные производные условия.
Play video starting at :7:21 and follow transcript7:21
Далее шаг пятый, то, что я делаю, это использовать градиентную проверку , чтобы сравнить эти частичные термины производных , которые были вычислены. Итак, я сравнил версии, вычисленные с использованием обратного распространения по сравнению с частичными производными, вычисленными с использованием числовых оценок
Play video starting at :7:37 and follow transcript7:37
, как с использованием числовых оценок производных. Итак, я проверяю градиент, чтобы убедиться, что оба они дают вам очень похожие значения.
Play video starting at :7:45 and follow transcript7:45
Проведя проверку градиента только сейчас, уверяет нас, что наша реализация обратного распространения правильна, и это то очень важно, что мы отключаем проверку градиента , потому что код проверки градиента bood вычисляется очень медленно.
Play video starting at :7:59 and follow transcript7:59
И, наконец, мы затем используем алгоритм оптимизации, такой как градиентный спуск, или один из передовых методов оптимизации, таких как , LB из GS, градиент контракта имеет bb, воплощенный в fminunc или другие методы оптимизации. Мы используем их вместе с обратным распространением, поэтому обратно распространение это вещь , которая вычисляет эти частичные производные для нас.
Play video starting at :8:21 and follow transcript8:21
Итак, мы знаем, как вычислить функцию затрат, мы знаем как вычислить частичные производные с помощью обратного распространения, поэтому мы можем использовать один из этих методов оптимизации , чтобы попытаться минимизировать j из тета как функцию параметров theta. И кстати, для нейронных сетей эта стоимостная функция j теты не выпуклая, или не выпуклая и поэтому теоретически может быть восприимчива к локальным минимумам, а в алгоритмах stot-факта, таких как градиентный спуск и представить передовые методы оптимизации могут, застряли в локальной
Play video starting at :8:55 and follow transcript8:55
optima, но оказывается , что на практике это не обычно огромная проблема , и даже несмотря на то, что мы не можем гарантировать, что эти алгоритмы найдут глобальный оптимальный, обычно алгоритмы, такие как st-градиентный спуск, будут делать hote очень хорошую работу, минимизируя это функция стоимости j тета и получить очень хороший локальный минимум, даже , если он не добирается до глобального оптимального. Наконец, градиентные спуски для нейронной сети могут показаться немного магическими. Итак, позвольте мне показать еще одну фигуру, чтобы попытаться получить эту интуицию о том, что делает градиентный спуск для нейронной сети.
Play video starting at :9:27 and follow transcript9:27
Это было похоже на рисунок , который я использовал ранее для объяснения градиентного спуска. Итак, у нас есть некоторая функция , и у нас есть ряд параметров в нашей нейронной сети. Прямо здесь я только что записал два значения параметров. На самом деле, конечно, в нейросети мы можем иметь множество параметров с ними. Тета один, тета два - все это матрицы, верно? Таким образом, мы можем иметь очень высокие размерные параметры , но из-за ограничения источник частей мы можем нарисовать. Я притворяюсь , что у нас есть только два параметра в этой нейронной сети. Хотя, очевидно, у нас есть гораздо больше на практике.
Play video starting at :9:59 and follow transcript9:59
Теперь эта функция стоимости j тета измеряет, насколько хорошо нейронная сеть подходит для обучающих данных.
Play video starting at :10:6 and follow transcript10:06
Итак, если взять точку , как эта, здесь,
Play video starting at :10:10 and follow transcript10:10
это точка, где j тета довольно низка, и поэтому это соответствует настройке параметров. Есть настройка параметров тета, где, вы знаете, для большинства примеров обучения, выход
Play video starting at :10:24 and follow transcript10:24
моей гипотезы, что может быть довольно близко к y (i) , и если это sts true, то это то, что заставляет мою функцию затрат быть довольно низкой.
Play video starting at :10:32 and follow transcript10:32
В то время как, напротив, если бы вы были , чтобы принять такое значение, точка, как это соответствует, где для многих обучающих примеров, выход моей нейронной сети bet-далеко от st-фактического значения y (i) hot-here, который наблюдался в тренировочном наборе. Таким образом, такие точки на линии соответствуют тому, где гипотеза , где нейронная сеть выводит значения на обучающий набор, которые находятся в расстоянии от y (i). Таким образом, это не хорошо подходит для тренировочного набора, тогда как точки, подобные этому с низкими значениями функции стоимости, соответствует , где j theta является низким, и поэтому соответствует тому, где нейросеть происходит, что должно быть правдой, чтобы j theta был маленьким.
Play video starting at :11:15 and follow transcript11:15
Итак, что делает градиентный спуск, это , мы начнем с какой-то случайной начальной точки , как та, которая вон там, и он будет многократно спускаться вниз.
Play video starting at :11:24 and follow transcript11:24
И так, что обратное распространение делает вычисление направления градиента, и то, что делает спуск градиента, это он делает небольшие шаги вниз по высоте, пока, надеюсь, он дойдет до, stoth в этом случае, довольно хороший локальный оптимальный.
Play video starting at :11:37 and follow transcript11:37
Итак, когда вы реализуете обратное распространение и используете градиент спуск или один из передовых методов оптимизации , эта картинка вроде как объясняет, что делает алгоритм. Он пытается найти значение параметров, где выходные значения в нейронной сети тесно соответствуют значениям в y (i), наблюдаемым в вашем тренировочном наборе. Итак, надеюсь, это дает вам лучшее представление о том, как различные фрагменты обучения нейронной сети подходят вместе.
Play video starting at :12:7 and follow transcript12:07
В случае, если даже после этого видео, в случае вы все еще чувствуете, что там , как, много разных частей , и это не совсем ясно, что некоторые из них делают или как все bit этих частей собираются вместе, это на самом деле хорошо.
Play video starting at :12:18 and follow transcript12:18
Нейросетевое обучение и обратная пропаганда — сложный алгоритм.
Play video starting at :12:23 and follow transcript12:23
И даже несмотря на то, что я видел математику за спиной распространения в течение многих лет, и я использовал назад распространения, я думаю, очень успешно, в течение многих лет, даже сегодня я до сих пор чувствую, что у меня не всегда есть большой понять, что именно делает обратная пропаганда иногда. И как выглядит процесс оптимизации по минимизации j if theta. Многое это гораздо сложнее алгоритм , чтобы чувствовать, что у меня есть гораздо менее хорошая ручка на именно то, что это делает по сравнению с скажем, линейной регрессией или логистической регрессией.
Play video starting at :12:51 and follow transcript12:51
Которые были математически и концептуально гораздо проще и намного чище алгоритмы.
Play video starting at :12:56 and follow transcript12:56
Но если вы чувствуете, что так же, вы знаете, это на самом деле прекрасно хорошо, но если вы реализуете обратное распространение, надеюсь, что вы обнаружите, что этот bots является одним из самых мощных алгоритмов обучения stots, и если вы реализуете этот алгоритм, реализуете обратно , реализует один из этих методов оптимизации , вы обнаружите, что обратного распространения будет в состоянии соответствовать очень сложным, мощным, нелинейным функциям для ваших данных, и это один из наиболее эффективных алгоритмов обучения, которые мы имеем сегодня.