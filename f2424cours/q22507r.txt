Putting It Together.Итак, нам потребовали много видео, чтобы пройти алгоритм обучения нейронной сети. В этом видео, то, что я хотел бы сделать, это попытаться собрать все части вместе, чтобы дать общее резюме или более широкую картину, о том, как оценка все части подходят вместе и стоп общего процесса, как starete реализовать алгоритм обучения нейронной сети. При обучении нейронной сети первое, что вам нужно сделать , это выбрать некоторую сетевую архитектуру и по архитектуре я просто имею в виду шаблон связи между нейронами. Итак, вы знаете, мы могли бы выбрать между скажем, нейронной сетью с тремя входными единицами и пятью скрытыми единицами и четырьмя выходными единицами против одной категории 3, 5 скрытых, 5 stots скрытых, 4 выхода и информации здесь 3, 5, stone 5, 5 единиц в каждом из трех скрытых слоев и 4 открытых , и так эти выбор, сколько скрытых единиц в каждом слое и сколько скрытых слоев, эти являются выбором архитектуры. Итак, как вы делаете этот выбор? Ну, во-первых, количество входных единиц хорошо, что довольно хорошо определено. И как только вы решите на исправление набор объектов x, количество входных единиц будет просто, вы знаете, размер ваших объектов x (i) будет определяться этим. И если вы делаете многоклассные классификации, количество выходных данных это будет определяться числом классов в вашей задаче классификации. И просто напоминание, если у вас есть многоклассная классификация, где y берет на сказать значения между 1 и 10, так что у вас есть десять возможных классов. Тогда не забудьте вправо, ваш вывод y, поскольку это были векторы. Таким образом, вместо пункта 1 вы перекодируете его как вектор , как это, или для второго класса вы перекодируете его как вектор. Так что если одно из этих яблок принимает на пятый класс, вы знаете, у равен 5, то то, что вы показываете вашей нейронной сети на самом деле не является значением y равно 5, вместо этого здесь, у верхнего слоя, который будет иметь десять выходных единиц, вы будете , который вы знаете с одним в пятой позиции и кучей нулей здесь. Таким образом, выбор числа входных единиц и количества выходных единиц , возможно, несколько достаточно прост. А что касается количества скрытых единиц и количества скрытых слоев, то разумным по умолчанию является использование одного скрытого слоя и поэтому этот тип stot-нейронной сети, показанной слева с stot-всего одним скрытым слоем, вероятно, наиболее распространенным. Или, если вы используете больше , чем один скрытый слой, снова разумное значение по умолчанию будет равно, что будет иметь одинаковое количество скрытых единиц в каждом слое. Итак, здесь у нас есть два скрытых слоя, и каждый из этих скрытых слоев имеет то же количество 5 скрытых единиц , и здесь у нас есть, вы знаете, both три скрытых слоя и stots каждый из них имеет одинаковый номер, то есть пять скрытых единиц. Вместо того, чтобы делать такого рода сетевой архитектуры слева было бы идеальным разумным дефолтом. А что касается количества скрытых единиц - обычно, чем больше скрытых единиц, тем лучше; это просто то, что если у вас есть много скрытых единиц, то это bote может стать более вычислительно дорогим, но stoth очень часто, имея больше скрытых единиц - это хорошо. И обычно количество скрытых единиц в каждом слое будет, возможно, сопоставимо с размерностью x, сопоставимой с количеством объектов, или это может быть любое место, где от того же количества sts скрытых единиц входных объектов к starmete может быть, так что три или четыре раза больше. Таким образом, наличие количества скрытых единиц сопоставимо. Вы знаете, несколько раз, или некоторые, что больше, чем количество входных объектов, часто полезно сделать так, , надеюсь, это дает вам один debut разумный набор вариантов по умолчанию stoth для нейронной архитектуры и и herote, если вы следуете этим рекомендациям, вы ceto, вероятно, получить что-то, что работает хорошо, но в более позднем наборе видео, где я расскажу конкретно о том, как применять алгоритмы , я на самом деле произнесу гораздо больше о том, как выбрать архитектуру нейронной сети. Или на самом деле есть довольно много я хочу, чтобы сказать позже, чтобы сделать хороший выбор для количества скрытых единиц, количества скрытых слоев и так далее. Далее, вот что нам нужно реализовать, чтобы торговля в нейронной сети, есть на самом деле шесть шагов, которые у меня ; У меня четыре на этом слайде и еще два шага на следующем слайде. Первым шагом является настройка нейросети и случайным образом инициализировать значения весов. И мы обычно инициализируем весы до небольших значений, близких к нулю. Затем мы реализуем форвард распространения , чтобы мы могли ввести любую отличную нейросеть и вычислить h из x, который является этим вектором вывода значений y. Затем мы также реализуем код для вычислить эту функцию стоимости j theta. И далее мы реализуем back-prop, или алгоритм обратного распространения , чтобы вычислить эти условия частичных производных, частичные производные j тета, по отношению к параметрам. Конкретно, для реализации обратной опоры. Обычно мы будем делать это с переднем циклом над примерами обучения. Некоторые из вас, возможно, слышали о продвинутых и, откровенно говоря, очень продвинутых методах факторизации, где у вас нет четырех циклов по отношению к примерам m-обучения, что в первый раз, когда вы реализуете обратный реквизит, должны почти наверняка четыре цикла here в вашем коде, где вы итерации по примерам, вы знаете, x1, y1, затем вы делаете вперед prop и назад prop на первом примере , а затем в вторую итерацию four-loop, вы делаете вперед распространение sph и обратно распространение на втором примере и так далее. Пока вы не пройдете через последний пример. Таким образом, в вашей реализации должно быть четыре цикла обратной опоры, по крайней мере, в первый раз его реализации. И тогда есть откровенно несколько сложные способы сделать это без четырех циклов, но я определенно не рекомендую , пытаясь сделать это гораздо более сложной версии, когда вы впервые пытаетесь реализовать обратный реквизит. Итак, конкретнее, у нас есть четыре цикла над моими примерами m-обучения , а внутри четырёхцикла мы будем выполнять fore prop и back prop, используя только этот пример. И что это означает, что мы собираемся взять x (i), и кормить, что на мой входной слой, выполнить форвард-опора, выполнить back-prop и что будет, если все bets эти активации и все stots эти дельта термины для всех слоев всех моих hen-единиц в нейронной то все еще внутри этого четырёхцикла, позвольте мне нарисовать фигурные скобки , чтобы показать область с четыре цикла, это, конечно, октавный код , но это больше код Java, и четыре цикла охватывает все это. Мы собираемся вычислить эти термины дельта , которые являются формулой, которую мы дали ранее. Плюс, вы знаете, дельта l плюс один раз a, l транспонировать код. И затем, наконец, вне , вычислив эти термины дельта , эти термины накопления, мы бы тогда иметь какой-то другой код , а затем это позволит нам вычислить эти частичные производные термины. Право и эти частичные производные условия должны учитывать термин регуляризации лямбда, а также. И так, эти формулы были приведены в предыдущем видео. Итак, как вы сделали это , у вас теперь, надеюсь, есть код для вычислить эти частичные производные условия. Далее шаг пятый, то, что я делаю, это использовать градиентную проверку , чтобы сравнить эти частичные термины производных , которые были вычислены. Итак, я сравнил версии, вычисленные с использованием обратного распространения по сравнению с частичными производными, вычисленными с использованием числовых оценок , как с использованием числовых оценок производных. Итак, я проверяю градиент, чтобы убедиться, что оба они дают вам очень похожие значения. Проведя проверку градиента только сейчас, уверяет нас, что наша реализация обратного распространения правильна, и это то очень важно, что мы отключаем проверку градиента , потому что код проверки градиента bood вычисляется очень медленно. И, наконец, мы затем используем алгоритм оптимизации, такой как градиентный спуск, или один из передовых методов оптимизации, таких как , LB из GS, градиент контракта имеет bb, воплощенный в fminunc или другие методы оптимизации. Мы используем их вместе с обратным распространением, поэтому обратно распространение это вещь , которая вычисляет эти частичные производные для нас. Итак, мы знаем, как вычислить функцию затрат, мы знаем как вычислить частичные производные с помощью обратного распространения, поэтому мы можем использовать один из этих методов оптимизации , чтобы попытаться минимизировать j из тета как функцию параметров theta. И кстати, для нейронных сетей эта стоимостная функция j теты не выпуклая, или не выпуклая и поэтому теоретически может быть восприимчива к локальным минимумам, а в алгоритмах stot-факта, таких как градиентный спуск и представить передовые методы оптимизации могут, застряли в локальной optima, но оказывается , что на практике это не обычно огромная проблема , и даже несмотря на то, что мы не можем гарантировать, что эти алгоритмы найдут глобальный оптимальный, обычно алгоритмы, такие как st-градиентный спуск, будут делать hote очень хорошую работу, минимизируя это функция стоимости j тета и получить очень хороший локальный минимум, даже , если он не добирается до глобального оптимального. Наконец, градиентные спуски для нейронной сети могут показаться немного магическими. Итак, позвольте мне показать еще одну фигуру, чтобы попытаться получить эту интуицию о том, что делает градиентный спуск для нейронной сети. Это было похоже на рисунок , который я использовал ранее для объяснения градиентного спуска. Итак, у нас есть некоторая функция , и у нас есть ряд параметров в нашей нейронной сети. Прямо здесь я только что записал два значения параметров. На самом деле, конечно, в нейросети мы можем иметь множество параметров с ними. Тета один, тета два - все это матрицы, верно? Таким образом, мы можем иметь очень высокие размерные параметры , но из-за ограничения источник частей мы можем нарисовать. Я притворяюсь , что у нас есть только два параметра в этой нейронной сети. Хотя, очевидно, у нас есть гораздо больше на практике. Теперь эта функция стоимости j тета измеряет, насколько хорошо нейронная сеть подходит для обучающих данных. Итак, если взять точку , как эта, здесь, это точка, где j тета довольно низка, и поэтому это соответствует настройке параметров. Есть настройка параметров тета, где, вы знаете, для большинства примеров обучения, выход моей гипотезы, что может быть довольно близко к y (i) , и если это sts true, то это то, что заставляет мою функцию затрат быть довольно низкой. В то время как, напротив, если бы вы были , чтобы принять такое значение, точка, как это соответствует, где для многих обучающих примеров, выход моей нейронной сети bet-далеко от st-фактического значения y (i) hot-here, который наблюдался в тренировочном наборе. Таким образом, такие точки на линии соответствуют тому, где гипотеза , где нейронная сеть выводит значения на обучающий набор, которые находятся в расстоянии от y (i). Таким образом, это не хорошо подходит для тренировочного набора, тогда как точки, подобные этому с низкими значениями функции стоимости, соответствует , где j theta является низким, и поэтому соответствует тому, где нейросеть происходит, что должно быть правдой, чтобы j theta был маленьким. Итак, что делает градиентный спуск, это , мы начнем с какой-то случайной начальной точки , как та, которая вон там, и он будет многократно спускаться вниз. И так, что обратное распространение делает вычисление направления градиента, и то, что делает спуск градиента, это он делает небольшие шаги вниз по высоте, пока, надеюсь, он дойдет до, stoth в этом случае, довольно хороший локальный оптимальный. Итак, когда вы реализуете обратное распространение и используете градиент спуск или один из передовых методов оптимизации , эта картинка вроде как объясняет, что делает алгоритм. Он пытается найти значение параметров, где выходные значения в нейронной сети тесно соответствуют значениям в y (i), наблюдаемым в вашем тренировочном наборе. Итак, надеюсь, это дает вам лучшее представление о том, как различные фрагменты обучения нейронной сети подходят вместе. В случае, если даже после этого видео, в случае вы все еще чувствуете, что там , как, много разных частей , и это не совсем ясно, что некоторые из них делают или как все bit этих частей собираются вместе, это на самом деле хорошо. Нейросетевое обучение и обратная пропаганда — сложный алгоритм. И даже несмотря на то, что я видел математику за спиной распространения в течение многих лет, и я использовал назад распространения, я думаю, очень успешно, в течение многих лет, даже сегодня я до сих пор чувствую, что у меня не всегда есть большой понять, что именно делает обратная пропаганда иногда. И как выглядит процесс оптимизации по минимизации j if theta. Многое это гораздо сложнее алгоритм , чтобы чувствовать, что у меня есть гораздо менее хорошая ручка на именно то, что это делает по сравнению с скажем, линейной регрессией или логистической регрессией. Которые были математически и концептуально гораздо проще и намного чище алгоритмы. Но если вы чувствуете, что так же, вы знаете, это на самом деле прекрасно хорошо, но если вы реализуете обратное распространение, надеюсь, что вы обнаружите, что этот bots является одним из самых мощных алгоритмов обучения stots, и если вы реализуете этот алгоритм, реализуете обратно , реализует один из этих методов оптимизации , вы обнаружите, что обратного распространения будет в состоянии соответствовать очень сложным, мощным, нелинейным функциям для ваших данных, и это один из наиболее эффективных алгоритмов обучения, которые мы имеем сегодня.