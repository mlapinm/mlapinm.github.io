Data For Machine Learning.В предыдущем видео мы говорили о показателях оценки. В этом видео, я хотел бы немного поменять треки и коснуться еще одного важного аспекта дизайна системы машинного обучения , , которые часто возникают, и это вопрос о том, сколько данных stots тренироваться. Теперь, в некоторых предыдущих видео, я предостерег от слепо выходить и просто тратить много времени на сбор большого количества данных о , потому что это только те, что иногда это на самом деле поможет. Но оказывается, что при определенных условиях, и я скажу в этом видео, что эти условия , получение большого объема данных и обучение по bit определенного типа алгоритма обучения stots, может быть самым эффективным способом получить cetary алгоритм обучения делать очень хорошо производительность. И это возникает достаточно часто , что если эти условия имеют истинное для вашей проблемы, и если вы можете получить много данных, это может быть очень хороший способ получить stoth очень высокий алгоритм обучения производительности. Итак, в этом видео, давайте поговорим об этом больше. Позвольте мне начать с рассказа. Много лет назад два исследователя , которые я знаю, Мишель Банко и Эрик Броул провели следующее увлекательное исследование. Они были заинтересованы в изучении эффекта использования различных алгоритмов обучения по сравнению с попытками их на разных науках обучения, они рассматривали проблему bbotклассифицирования между путаными словами, stots так, например, в предложении: placete for breakfast I ели, должно быть, два или тоже? Ну, для этого примера на завтрак я съел два, 2 яйца. Итак, это один пример набора запутанных слов, и это другой набор. Таким образом, они взяли машинное обучение проблемы, подобные этим, своего рода контролируемое обучение проблемы, чтобы попытаться классифицировать , что такое подходящее слово для перейти в определенную позицию в английском предложении. Они взяли несколько разных алгоритмов обучения , которые были, знаете, вроде как учтено состояние искусства в тот момент, когда они проводили исследование в bot2001, поэтому они взяли дисперсию stots, примерно дисперсию stay по логистической регрессии под названием Perceptron. Они также взяли некоторые из их алгоритмов, которые были довольно в то время, но несколько меньше используется сейчас, так что, когда алгоритм также очень похожи к которому является регрессией, но отличается в некотором роде, много средств используется несколько меньше, используется cernote не слишком много прямо сейчас называется алгоритмом обучения на основе памяти, который снова используется несколько меньше. Но я поговорю немного об этом позже. И они использовали наивный алгоритм , о котором они будут на самом деле говорить в этом курсе. Точные алгоритмы этих деталей не важны. Подумайте об этом, как, знаете, просто выбрать четыре разных алгоритма классификации и действительно точные алгоритмы не важны. Но то, что они сделали, это они изменили размер обучающего набора и опробовали эти алгоритмы обучения на диапазоне размеров обучающих наборов, и это результат, который они получили. И тенденции очень ясно сначала большинство эти внешние комнаты дают удивительно похожую производительность. И во-вторых, по мере увеличения размера набора тренировок , на горизонтальной оси является размер тренировочных кадров в миллионах идти от вы знаете, что bott сто тысяч до stots тысячи миллионов, что является citacy миллиард учебных примеров. Производительность алгоритмов все в значительной степени монотонно увеличиваются и тот факт, что если вы выберете любой алгоритм, может быть выбрать «более низкий алгоритм», но , если вы дадите этому «нижнему алгоритму stots» больше данных, то из этих примеров, похоже, что скорее всего, обыграл даже «превосходный алгоритм». Так что, поскольку это оригинальное исследование , которое является очень влиятельным, было множество различных исследований , показывающих схожие результаты , которые показывают, что многие различные алгоритмы обучения, которые вы знаете, имеют тенденцию к stoth, может иногда, в зависимости от деталей, может дать довольно похожие диапазоны производительности, но что может действительно стимулировать производительность, это вы можете дать алгоритму тонну учебных данных. И это, результаты, подобные этим , привели к поговорке в машинном обучении, что часто в машинном обучении это не тот, кто имеет лучший алгоритм, который bit побеждает, это тот, кто имеет stots большинство данных Так что когда это cote true, и когда это не так? Потому что у нас есть обучение алгоритм, для которого это верно, то получение много данных часто , возможно, лучший способ обеспечить , что у нас есть алгоритм с высокой производительностью, а не stoth вы знаете, обсуждая, что именно из этих элементов использовать. Давайте попробуем выложить набор предположений, при которых, имея массивный тренировочный набор, мы думаем, сможет помочь. Предположим, что в нашей проблеме машинного обучения функции x имеют достаточную информацию, с которой мы можем использовать для точного прогнозирования y. Например, если мы возьмем запутанные слова все из них, что мы имели на предыдущем слайде. Предположим, что он имеет x захват, что окружающие слова вокруг пробела, который мы пытаемся заполнить. Таким образом, функции захватывают то мы хотим иметь, иногда на завтрак у меня есть черные яйца. Тогда да, что довольно много информации, чтобы сказать мне , что слово, которое я хочу посередине является ДВА и что не слово К и его не слово ТОО. Итак, функции захватывают, знаете, один из этих окружающих слов, то, что дает мне достаточно информации, чтобы довольно однозначно решить, что такое метка y или в другими словами, что такое слово, которое я должен использовать, чтобы заполнить эту пустую из нашего набора из трех запутанные слова. Так вот пример того, что будущий ex имеет достаточную информацию для конкретного y. Для пример счетчика. Рассмотрим проблему предсказания цены дома от только размер дома и не от других признаков . Так что , если вы представляете, что я вам говорю , что дом, вы знаете, 500 квадратных футов, но я не даю вам никаких других особенностей. Я не говорю вам, что дом находится в дорогой части города. Или если я не скажу вам, что дом, количество комнат в доме, или как красиво обставлен дом , или ли дом новый или старый. Если я не скажу вам ничего другого , кроме того, что это 500 квадратных футов дом, ну есть так много других факторов, которые будут иметь отношение к цене дома, кроме только размер, когда вы знаете, это размер, это на самом деле точно прогнозировать цену. Так что было бы счетчиком примером этого предположения , что объекты имеют достаточную информацию , чтобы предсказать цену до желаемого уровня точности. То, как я думаю о тестировании это предположение, один из способов я часто думаю об этом, как часто я спрашиваю себя. Учитывая входные объекты x, учитывая объекты, учитывая ту же информацию, доступную, а также алгоритм обучения. Если бы мы пошли к человеческому эксперту в этой области. Может ли человеческие эксперты на самом деле или может человеческий эксперт уверенно предсказать значение y. Для этого первый пример, если мы идем к, вы знаете эксперта-человека, говорящего на английском языке. Вы идете к кому-то, что говорит по-английски хорошо, правильно, то человеческий эксперт на английском языке просто читать большинство людей, как вы и я, вероятно, мы, вероятно, будет в состоянии так что это дает мне уверенность , что x позволяет нам точно предсказать y, но в отличие от , если мы идем к эксперту по ценам на человека. Как, может быть, эксперт риэлтор, верно, кто-то , который продает дома на жизнь. Если я просто скажу им размер дома, и я расскажу им, что цена хорошо, даже эксперт в ценообразовании или продаже bot-домов не сможет мне сказать, и так что это нормально, что речь для примера цены на жилье зная, что только размер не дает предположил меня достаточно информация для предсказания цены на дом. Итак, допустим, это предположение имеет место. Посмотрим тогда, когда у много данных может помочь. Предположим, что функции имеют достаточно информации , чтобы предсказать значение y y. И предположим, что мы используем алгоритм обучения с большим количеством параметров, поэтому sts может быть логистическая регрессия или линейная регрессия с большим количеством функций. Или одна вещь, которую я иногда делаю, одна вещь, которую я часто делаю на самом деле, это использовать нейросеть со многими скрытыми единицами. Это был бы еще один алгоритм обучения с большим количеством параметров. Таким образом, все это мощные алгоритмы обучения с большим количеством параметров, которые могут соответствовать очень сложным функциям. Итак, я собираюсь назвать это, я будет думать об этих алгоритмах как с низким уклоном, потому что вы знаете, что мы можем соответствовать очень сложным функциям и потому, что у нас есть очень мощный алгоритм обучения, они могут соответствовать очень сложным функциям. Скорее всего, если мы запустим эти алгоритмы на наборах данных, он сможет правильно соответствовать тренировочный , и поэтому, надеюсь, что ошибка обучения будет медленной. Теперь скажем, мы используем массивный, массивный тренировочный набор, в этом случае, если у нас есть огромный тренировочный набор, то , надеюсь, даже если у нас есть много параметров но если учебный набор немного больше, чем количество параметров, то, надеюсь, эти альбомы вряд ли будут перегружать. Правильно, потому что у нас есть такой массовый набор и по вряд ли перегрузится то, что означает, что ошибка обучения будет, надеюсь, что boot близка к ошибке теста. Наконец, положив эти два вместе, что ошибка поезда набор мала и ошибка тестового набора близка к обучающей ошибке, что это два вместе подразумевают, что, надеюсь, ошибка тестового набора также будет небольшой. Другой способ подумать об этом заключается в том, что для того, чтобы иметь алгоритм обучения высокой производительности , мы хотим, чтобы он не имел высокого смещения и не имел высокой дисперсии. Таким образом, проблема смещения, которую мы собираемся решить , убедившись, что у нас есть алгоритм обучения со многими параметрами и так что дает нам низкий алоритм смещения, и с помощью stots очень большой обучающий набор, это гарантирует, что у нас нет проблемы дисперсии здесь. Так что, надеюсь, наш алгоритм будет не иметь дисперсии, и поэтому это, потянув эти два вместе, , что мы в конечном итоге с низким уклоном и низким дисперсией hbd алгоритмом обучения, и этот stots позволяет нам делать хорошо hote на тестовом наборе. И в основном это ключевые ингредиенты предполагая, что функции имеют достаточно информации, и мы имеют богатый класс функций , поэтому он гарантирует низкую смещенность, hbit, а затем он имеет массивный обучающий набор, что это то, что гарантирует большую дисперсию. Таким образом, это дает нам набор условий, скорее надеюсь, некоторое понимание того, что такое проблема , когда, если у вас есть много данных, и вы тренируете алгоритм обучения stots с большим количеством параметров, это может быть хорошим способом дать высокую производительность обучения Алгоритм и на самом деле, я думаю, что ключевой тест, который я часто спрашиваю себя, являются первым, может ли человеческие эксперты посмотреть на особенности x и уверенно предсказать значение both y. во-вторых, можем ли мы действительно получить большой обучающий набор и обучить алгоритм обучения с большим количеством параметров в наборе тренировок , и если вы не можете сделать оба значения, то это чаще дает вам очень добрый алгоритм обучения производительности.