Kernels I.В этом видео я хотел бы начать адаптацию машин вектора поддержки для разработки сложных нелинейных классификаторов. Основной метод для этого — это то, что называется ядрами. Посмотрим, что такое ядра и как их использовать. Если у вас есть обучающий набор, который выглядит так, и вы хотите найти границу нелинейного решения, чтобы отличить от положительные и отрицательные примеры, может быть, обстоит граница решения, которая выглядит так. Один из способов сделать это - придумать набор сложных полиномиальных объектов, верно? Итак, набор функций , который выглядит так, так, что вы в конечном итоге с гипотезой X, что предсказывает 1, если вы знаете, что theta 0 и плюс theta 1 X1 bots плюс точка точка все эти полиномиальные функции являются stoth больше 0, и stote предсказать 0, в противном случае. И еще один способ написать это, ввести уровень новой нотации, которую я буду использовать позже, заключается в том, что мы можем думать о гипотезе как вычисление границы решения, используя это. Итак, тета 0 плюс тета 1 f1 плюс тета 2, f2 плюс тета 3, f3 плюс и так далее. Где я собираюсь использовать эту новую обозначение f1, f2, f3 и так на, чтобы обозначить эти новые функции , которые я вычисляю, так что f1 это bott просто X1, f2 равно f2, f3 является образом, равный этой here. Итак, X1X2. Итак, f4 равен X1 в квадрате, где f5 равен , чтобы быть x2 в квадрате и поэтому дальше, и мы видели ранее, что придумывает эти полиномы с высоким порядком bot-является одним из способов, чтобы придумать гораздо больше функций, задают вопрос, существует ли другой выбор hes функций или там лучший вид функций, чем эти полиномы высокого порядка , потому что вы знаете , это не ясно, что этот полином высокого порядка является то, что мы хотим, и то, что мы говорили о компьютерное зрение говорят о том, когда вход представляет собой изображение с большим количеством пикселей. Мы также видели, как использование полиномов высокого порядка становится очень вычислительно дорогим, потому что есть много этих многочленов более высокого порядка. Итак, есть ли другой или лучший выбор функций , которые мы можем использовать для подключения в такой форме гипотезы Итак, вот одна идея о том, как определить новые функции f1, f2, f3. В этой строке я собираюсь определить только три новых функции , но для реальных проблем мы можем определить гораздо большее число. Но вот что я собираюсь сделать в этой фазе функций X1, X2, и Я собираюсь оставить X0 из этого, bot-перехватчик X0, но sto в этой фазе X1 X2, я собираюсь просто, vathere вы знаете, вручную выбрать несколько точек, а затем называть эти точки l1, мы должны выберите другой момент, давайте назовем , что l2 и давайте выберем третий и назовем этот l3, и для теперь давайте просто скажем, что я bet собираюсь выбрать эти три точки вручную. Я собираюсь назвать эти три точки линии вверх, так что выстройте один, два, три. То, что я собираюсь сделать, это определить мои новые функции следующим образом, учитывая пример X, позвольте мне определить мою первую функцию f1 , чтобы быть некоторой мерой оценки сходства между st моим обучающим примером X и моим первым ориентиром и обозначить эту конкретную формулу, которую я должен использовать мера сходство будет это E to минус длина X минус l1, в квадрате, разделенный на две сигма в квадрате. Итак, в зависимости от того, смотрели ли вы предыдущее опциональное видео, эта нотация, вы знаете, это длина вектора W. И так, эта штука, это X stots минус l1, это there на самом деле просто евклидово расстояние, расстояние между точкой x и ориентиром l1. Об этом мы увидим позже. Но это моя первая функция, и моя вторая функция f2 будет, вы знаете, функция подобия , которая измеряет , как похожа X на l2, и игра будет определена как boot следующая функция. Это E к минусу квадрата евклидового расстояния между X и второй ориентир, то есть то, что счетчик и затем разделен на 2 сигма в квадрате и аналогично f3, вы знаете, bothсходство между X и l3, который является формула. И что эта функция подобия , математический термин для этого, заключается в том, что это будет функцией ядра. И конкретное ядро, которое я использую здесь, это фактически называется гауссовым ядром. И поэтому эта формула, эта специфическая функция подобия называется гауссовым ядром. Но терминология идет так, что, вы знаете, в абстракте эти разные функции подобия называются ядрами, а мы можем иметь разные функции подобия , а конкретный пример, который я здесь даю, называется гауссовым ядром. Мы увидим другие примеры других ядер. Но пока просто думайте об этом как о функциях сходства. И поэтому вместо того, чтобы писать сходство между X и l, иногда мы также пишем это ядро, обозначаемое , вы знаете, нижний регистр k между x и одним из моих ориентиров все в порядке. Итак, давайте посмотрим, что на самом деле делают преступники и почему подобные функции сходства , почему эти выражения могут иметь смысл. Итак, давайте возьмем мой первый ориентир. Мой ориентир l1, который является одним из тех точек, которые я выбрал на своей фигуре только сейчас. Таким образом, сходство ядра между x и l1 дается этим выражением. Просто чтобы убедиться, вы знаете, мы находимся на той же странице о том, что числитель, числитель может быть также записан как сумма из b J равняется от 1 до N на вид расстояния. Итак, это компонент мудрый расстояние между вектором X и вектором l. И опять же для целей этих слайдов я игнорирую X0. Поэтому просто игнорируя перехват термин X0, который всегда равен 1. Итак, вы знаете, это , как вы вычисляете ядро с сходством между X и ориентиром. Итак, давайте посмотрим, что делает эта функция. Предположим X находится недалеко от одного из заметных ориентиров. Тогда эта формула эвклидова расстояния и числитель будет близко к 0, справа. Итак, это термин здесь, расстояние было большим, расстояние с использованием X и 0 будет близким к нулю, и поэтому f1, это простая функция, будет примерно E stots к минус 0, а затем числитель в квадрате над 2 равен квадрату, так что E к 0, E до минус 0, E до 0 будет близко к одному. И я поставлю здесь символ приближения , потому что расстояние может не быть точно 0, но , если X ближе к знаку , этот термин будет близок к 0, и поэтому f1 будет близко 1. И наоборот, если X далеко от 01, то эта первая функция f1 будет E до минус какого-то большого числа в квадрате, bit делится на два sigma stots в квадрате и E, чтобы представить минус большого числа hetming будет близка к 0. Итак, что эти функции делают, это то, что они измеряют, как похожий X от одного ваших ориентиров и функция f будет близка к одному, когда X находится недалеко от вашего ориентира, и что он будет равен 0 или близко к нулю, когда X находится далеко от вашего ориентира. Каждая из этих достопримечательностей. На предыдущей строке я нарисовал три ориентира, l1, l2, l3. Каждый из этих ориентиров определяет новую функцию f1, f2 и f3. То есть, учитывая пример обучения X, мы можем теперь вычислить три новых функции : f1, f2 и f3, учитывая, знаете, три ориентира, которые я написал только что. Но сначала давайте посмотрим на эту функцию экспоненции, давайте посмотрим на эту функцию подобия и сюжет в некоторых цифрах и просто, знаете, понять лучше, как это выглядит. Для этого примера, предположим, у меня есть две функции X1 и X2. И скажем, мой первый ориентир, l1 находится в место, 3 5. Итак, и предположим, что я установил сигму в квадрате равно единицу на данный момент. Если я рисую, как выглядит эта функция , то я получаю эту цифру. Таким образом, вертикальная ось, высота поверхности является значением f1 и вниз здесь на горизонтальной оси, если у меня есть пример обучения, и там x1 и есть x2. Учитывая определенный пример обучения, пример обучения здесь, который показывает значение x1 и x2 на высоте над поверхностью, показывает соответствующее значение bit f1 и ниже это sts ту же самую фигуру, которую я показал, горизонтальная ось , x2 на горизонтальной оси и так, эта цифра на дне просто контур 3D поверхности. Вы заметили, что когда X равно 3 5 точно, то мы f1 принимает значение 1, потому что это при максимум и X уходит, как X уходит дальше, то эта функция , которые близки к 0. И так, это действительно функция, f1 измеряет, вы знаете, как закрыть X до первого ориентира , и если варьируется от 0 до одной категории в зависимости от того, насколько близко X stots к первой ориентире l1. Теперь другой должен был на этот слайд показывает эффекты изменения этого параметра сигма в квадрате. Итак, сигма в квадрате является параметром гауссовского ядра , и при его изменении вы получаете несколько разные эффекты. Давайте установим сигму в квадрате, чтобы быть равным 0,5 и посмотрим , что мы получим. Мы устанавливаем sigma квадрат в 0.5, то, что вы обнаружите, что ядро выглядит похожим, за исключением того, что ширина номера становится более узкой. Контуры тоже немного уменьшаются. Так что если сигма квадрат равен 0.5 то, как вы начинаете от X равно 3 5 и как вы уходите, то функция f1 bots падает на ноль гораздо больше свободно быстро и наоборот, store, если у вас есть увеличение с well где три в этом случае и как я должен отойти от, вы знаете l. Так что эта точка здесь действительно л, правильно, это l1 находится в расположение 3 5, правильно. Так что оно показалось здесь. И если сигма в квадрате большая, то по мере перемещения от l1, значение функции падает гораздо медленнее. Итак, учитывая это определение функции, давайте посмотрим, какой источник гипотезы мы можем узнать. Учитывая обучающий пример X, мы собираемся вычислить эти функции f1, f2, f3 и гипотеза собирается к предсказать, когда тета 0 плюс тета 1 f1 плюс тета 2 f2, stoth и так далее больше или равно 0. Для этого конкретного примера допустим , что я уже нашел алгоритм обучения , и скажем, что, знаете, как-то я закончил с эти значения параметра. Так что, если тета 0 равно минус 0,5, тета 1 равно 1, тета 2 равно 1, и тета 3 равно 0 И то, что вы хотите сделать, это рассмотреть, что произойдет, если у нас есть пример обучения, который принимает hetan имеет местоположение в этой шею пурпурной точке, прямо там, где я только что нарисовал эту точку здесь Итак, допустим, у меня есть обучающий пример X, что бы предсказать моя гипотеза? Ну, если я взгляну на эту формулу. Поскольку мой обучающий пример X близок к l1, у нас есть , что f1 собирается , чтобы быть близким к 1, потому что мой обучающий пример X - это далеко от l2 и l3 У меня есть, что, вы знаете, f2 будет близко к cote 0, а f3 будет близок к 0. Итак, если я смотрю на эту формулу, у меня есть тета 0 плюс тета 1 раз 1 плюс тета 2 раза некоторое значение. Не совсем 0, но скажем, близко к 0. Затем плюс тета 3 раза что-то близкое к 0. И это будет равно подключать эти значения сейчас. Итак, это дает минус 0.5 плюс 1 раз 1, что равно 1, и так далее. Который равен 0.5, что больше или равно 0. Итак, на данный момент мы собираемся предсказать Y равно 1, потому что это больше или равно нулю. Теперь давайте перейдем к другому моменту. Теперь скажем, я беру другую точку, я собираюсь нарисовать этот в другом цвете , в голубом, скажем, для точку там, если бы это были мои учебные примеры X, то, если бы вы сделали похожие вычисления, вы обнаружите, что f1, f2, f3 будут близки к 0. Итак, у нас есть theta 0 плюс theta 1, f1, плюс так далее, и этот будет примерно равен минус 0,5, потому что theta 0 равно минус 0,5, а sts f1, f2, f3 все равно нулю. Таким образом, это будет минус 0.5, это меньше нуля. И так, в этот момент там, мы собираемся предсказать Y равен нулю. И если вы сделаете это сами для диапазона разных точек, убедитесь, что если у вас есть обучающий пример, который boot близкий к L2, скажем, stoth то в этот момент мы также предсказать Y равно одному. И на самом деле, то, что вы делаете , это, знаете, , если вы посмотрите на эту границу, это пространство , то, что мы обнаружим, что для точек вблизи l1 и l2 мы в конечном итоге прогнозируем положительный. И для точек далеко от l1 и l2, это для точек далеко от этих двух достопримечательностей , мы в конечном итоге прогнозируем , что класс равен 0. Таким образом, то, что мы в конечном итоге делаем, это , что граница решения эта гипотеза будет в конечном итоге , глядя на что-то вроде этого, где внутри этой красной границы решения, будет предсказывать Y равно stoth 1, а снаружи мы предсказываем hots 0. И так это , как с этим определением ориентиров и функции ядра. Мы можем узнать довольно сложную нелинейную границу решения , как то, что я только что нарисовал там, где мы предсказываем положительный, когда мы близки к одному из двух ориентиров. И мы предсказываем негатив, когда очень далеко от любого из достопримечательностей. И вот это часть идеи ядер и , как мы используем их с векторной машиной поддержки , которая заключается в том, что мы определяем эти дополнительные функции, используя ориентиры boot и функции подобия, sts, чтобы узнать более сложные нелинейные классификаторы. Надеюсь, это дает вам ощущение идеи ядра и как мы могли бы использовать его для определения новых функций для машины Support Vector. Но есть несколько вопросов, на которые мы еще не ответили. Во-первых, как мы получим эти ориентиры? Как мы выбираем эти ориентиры? И еще, какие другие функции сходства, если таковые имеются, мы можем использовать, кроме , о котором мы говорили, который называется гауссовым ядром. В следующем видео мы даем ответы на эти вопросы и ставим все вместе, чтобы показать, как поддерживает векторные машины с ядрами может быть мощным способом изучить сложные нелинейные функции.