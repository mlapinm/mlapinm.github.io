Stochastic Gradient Descent.Для многих алгоритмов обучения, среди которых линейная регрессия, логистическая регрессия и нейронные сети, способ получения алгоритма был придумывая функцию стоимости или придумывая цель оптимизации. А затем используя алгоритм, такой как градиентный спуск, чтобы минимизировать эту функцию затрат. У нас очень большой тренировочный набор градиентный спуск становится вычислительно очень дорогостоящей процедурой. В этом видео мы поговорим о модификации базового алгоритма градиентного спуска под названием Stochastic gradient dascus, , которая позволит нам масштабировать эти алгоритмы до гораздо больших тренировочных наборов. Предположим, что вы тренируете модель линейной регрессии с использованием градиентного спуска. Как краткий итог, гипотеза будет выглядеть так, и функция стоимости будет выглядеть так, , которая является суммой половины средней квадратной ошибки вашей гипотезы на примерах тренировок m, и функция затрат, которую мы уже видели, выглядит как такая функция в форме лука. Итак, построенная как функция параметров theta 0 и theta 1, функция стоимости J является своего рода луковичной функцией. И градиентный спуск выглядит так, где во внутреннем цикле градиентного спуска вы неоднократно обновляете параметры тета, используя это выражение. В остальной части этого видео я буду продолжать использовать линейную регрессию в качестве примера. Но идеи здесь, идеи Stochastic градиентного спуска полностью общие, а также применимы к другим алгоритмам обучения , таким как логистическая регрессия, нейронные сети и другие алгоритмы, которые основаны на тренировочной градиентной спуске на конкретном учебном наборе. Итак, вот картина того, что делает градиентный спуск, если параметры инициализированы до точки там , то при запуске градиентного спуска различные итерации градиентного спуска будут принимать параметры к глобальному минимуму. Так что возьмите траекторию, которая выглядит так, и прямо к глобальному минимуму. Теперь проблема с градиентным спуском заключается в том, что если m большой. Тогда вычисление этого производного термина может быть очень дорогим, потому что сюрприз, суммируя все m примеров. Так что если м 300 миллионов, хорошо. Так что в Соединенных Штатах насчитывается около 300 миллионов человек. Таким образом, данные переписи США или США могут иметь в порядке столько записей. Таким образом, вы хотите подогнать модель линейной регрессии к этому, тогда вам нужно суммировать более 300 миллионов записей. И это очень дорого. Чтобы дать алгоритму имя, эта конкретная версия градиентного спуска также называется пакетным градиентным спуском. И термин Batch относится к тому факту, что мы рассматриваем все примеры обучения за раз. Мы называем это своего рода партией всех обучающих примеров. И это действительно не лучшее название, но это то, что люди машинного обучения называют именно этой версией градиентного спуска. И если вы действительно представляете, что у вас есть 300 миллионов записей переписи, хранящихся на диске. Способ работы этого алгоритма заключается в том, что вам нужно прочитать в памяти компьютера все 300 миллионов записей, чтобы вычислить этот производный термин. Вам необходимо передать все эти записи через компьютер, потому что вы не можете сохранить все записи в памяти компьютера. Так что вам нужно прочитать их и медленно, знаете, накапливать сумму, чтобы вычислить производную. А потом выполнив всю эту работу, что позволяет сделать один шаг градиентного спуска. И теперь тебе нужно сделать все это снова. Вы знаете, сканируйте все 300 миллионов записей, накапливайте эти суммы. И выполнив всю эту работу, вы можете сделать еще один маленький шаг, используя градиентный спуск. А потом сделай это снова. А потом ты сделаешь еще третий шаг. И так далее. Так что это займет много времени, чтобы заставить алгоритм сходиться. В отличие от градиентного спуска Batch, то, что мы собираемся сделать, это придумать другой алгоритм , который не должен смотреть на все примеры обучения в каждой итерации, , но это нужно смотреть только на один пример обучения в одной итерации. Прежде чем перейти к новому алгоритму, вот просто алгоритм пакетного градиентного спуска, выписанный снова с тем, что является функцией стоимости и что является обновлением и, конечно, этот термин здесь, , который используется в правиле градиентного спуска, то есть частичной производной по отношению к параметры theta J нашей цели оптимизации, J train theta. Теперь рассмотрим более эффективный алгоритм, который лучше масштабируется до больших наборов данных. Для того, чтобы отработать алгоритмы под названием Стохастический градиентный спуск, это векторы функции стоимости несколько иначе, то они определяют стоимость параметра theta в отношении обучающего примера x (i), y (i) быть равным в половину квадратной ошибки , что моя гипотеза несет на этом примере, x (i), y (i). Таким образом, этот термин функции стоимости действительно измеряет, насколько хорошо моя гипотеза работает на одном примере x (i), y (i). Теперь вы заметили, что общая функция стоимости j поезда теперь может быть записана в этой эквивалентной форме. Таким образом, j поезд - это всего лишь среднее по моим m учебных примеров стоимости моей гипотезы на этом примере x (i), y (i). Вооружившись таким видом функции стоимости для линейной регрессии, позвольте мне сейчас написать, что делает Стохастический градиентный спуск. Первым шагом стохастического градиентного спуска является случайное перетасовка набора данных. Таким образом, я имею в виду случайным образом перетасовать или случайным образом изменить порядок тренировок m. Это своего рода стандартный шаг предварительной обработки, вернитесь к этому через минуту. Но основная работа стохастического градиентного спуска затем выполняется в следующем. Мы собираемся повторить для i равно от 1 до m. Поэтому мы будем повторно сканировать мои примеры обучения и выполнить следующее обновление. Собираюсь обновить параметр theta j как theta j минус alpha раз h (i) минус y (i) раз x (i) j. И мы будем делать это обновление как обычно для всех значений j. Теперь вы заметили, что этот термин здесь именно то, что мы имели внутри суммирования для пакетного градиентного спуска. На самом деле, для тех из вас, которые являются исчислением, можно показать, что этот термин здесь, вот этот термин здесь, равен частичной производной по отношению к моему параметру theta j стоимости параметров theta на x (i), y (i). Где стоимость, конечно, эта вещь, которая была определена ранее. И просто обертывание алгоритма, позвольте мне закрыть фигурные скобки вон там. Итак, что делает стохастический градиентный спуск, это на самом деле сканирование с помощью обучающих примеров. И сначала он будет смотреть на мой первый пример обучения x (1), y (1). И затем, глядя только на этот первый пример, он будет принимать как в основном небольшой шаг градиента спуска по отношению к стоимости только этого первого учебного примера. Другими словами, мы рассмотрим первый пример и немного изменим параметры, чтобы соответствовать только первому примеру обучения немного лучше. Сделав это внутри этого внутреннего цикла for-loop, затем перейдем ко второму примеру обучения. И то, что он собирается сделать, это сделать еще один маленький шаг в пространстве параметров, поэтому измените параметры немного, чтобы попытаться подойти только второй пример обучения немного лучше. Сделав это, затем перейдёт к моему третьему примеру обучения. И измените параметры, чтобы попытаться подойти только к третьему примеру обучения немного лучше, и так далее , пока вы не знаете, вы пройдете весь тренировочный набор. И тогда этот цикл ультра повтора может привести к тому, что он займет несколько проходов по всему комплекту тренировок. Этот вид стохастического градиентного спуска также мотивирует, почему мы хотели начать с случайного перетасования набора данных. Это не показывает нам, что когда мы сканируем сайт обучения здесь, , что мы в конечном итоге посещаем примеры обучения в каком-то случайном порядке. В зависимости от того, пришли ли ваши данные случайным образом отсортированы или были ли они изначально отсортированы в некотором странном порядке, на практике это просто ускорило бы преобразования в Stochastic градиентный спуск немного. Поэтому в интересах безопасности обычно лучше случайным образом перетасовать набор данных, если вы не уверены , если он пришел к вам в случайном порядке. Но что более важно, другой взгляд на стохастический градиентный спуск , что это очень похоже на спуск, но вместо того, чтобы подвести итоги этих градиентных терминов по всем примерам тренировок, , что мы делаем, это то, что мы берем этот градиентный термин, используя только один пример обучения , и мы начинаем , чтобы добиться прогресса в улучшении параметров уже. Вместо того, чтобы, вы знаете, ждать «пока пройтись по всем 300 000 записей переписи США, скажем, вместо того, чтобы сканировать все примеры обучения , прежде чем мы сможем немного изменить параметры и добиться прогресса к глобальному минимуму. Для стохастического градиентного спуска вместо этого нам просто нужно взглянуть на один пример обучения , и мы уже начинаем двигаться вперед в этом случае параметров к глобальному минимуму. Итак, вот алгоритм, выписанный снова, где первый шаг - случайным образом перетасовать данные , а второй шаг - это то, где выполняется реальная работа, где это обновление по отношению к одному примеру обучения x (i), y (i). Итак, давайте посмотрим, что этот алгоритм делает с параметрами. Ранее мы видели, что когда мы используем градиентный спуск Batch, , который является алгоритмом, который смотрит на все обучающие примеры во времени, Пакетный градиентный спуск будет, как вы знаете, принимать разумно прямую траекторию, чтобы добраться до глобального минимума. В отличие от стохастического градиентного спуска каждая итерация будет намного быстрее , потому что нам не нужно суммировать все обучающие примеры. Но каждая итерация просто пытается лучше соответствовать одному примеру обучения. Итак, если мы начнем стохастический градиентный спуск, о, давайте начнем стохастический градиентный спуск в такой точке. Первая итерация, вы знаете, может принимать параметры в этом направлении и , может быть, вторая итерация, глядя только на второй пример, может быть случайно, мы получаем более неудачно и фактически направляемся в плохое направление с такими параметрами. На третьей итерации, где мы пытались изменить параметры, чтобы соответствовать только третьим примерам обучения, может быть, мы в конечном итоге будем двигаться в этом направлении. А потом мы рассмотрим четвертый пример обучения и сделаем это. Пятый пример, шестой пример, седьмой и так далее. И когда вы запускаете Stochastic градиентный спуск, вы обнаружите, что он обычно перемещает параметры в направлении глобального минимума, но не всегда. Так что возьмите более случайный, замкнутый путь, чтобы посмотреть глобальный минимум. И на самом деле, когда вы запускаете Стохастический градиентный спуск, он на самом деле не сходится в том же смысле, что и пакетный градиентный спуск , и то, что он делает, непрерывно блуждает в каком-то регионе, который находится в каком-то регионе, близком к глобальному минимуму, , но он не просто доходит до глобальный минимум и оставайтесь там. Но на практике это не проблема, потому что, знаете, , пока параметры заканчиваются в каком-то регионе, может быть, это довольно близко к глобальному минимуму. Итак, поскольку параметры заканчиваются довольно близко к глобальному минимуму, это будет довольно хорошая гипотеза и поэтому обычно выполняется Stochastic gradient dasces , мы получаем параметр около глобального минимума, и это достаточно для, вы знаете, практически любых, самых практических целей. Только одна последняя деталь. В Стохастическом градиентном спуске, у нас был этот внешний цикл повтор, который говорит, чтобы сделать этот внутренний цикл несколько раз. Итак, сколько раз мы повторяем этот внешний цикл? В зависимости от размера тренировочного набора, выполнения этого цикла может быть достаточно одного раза. И до, вы знаете, может быть 10 раз может быть типичным , поэтому мы можем в конечном итоге повторить этот внутренний цикл в любом месте от одного до десяти раз. Итак, если у нас есть действительно большой набор данных, как эта перепись США дала нам пример , о котором я говорил с 300 миллионами примеров, возможно, что к тому времени, когда вы пройдете всего один проход через свой тренировочный набор. Итак, это для i равняется от 1 до 300 миллионов. Возможно, что к тому времени, когда вы прошли один проход через ваш набор данных , у вас уже может быть совершенно хорошая гипотеза. В этом случае, вы знаете, этот внутренний цикл вам может понадобиться сделать только один раз, если m очень, очень большой. Но в целом, принимая от 1 до 10 проходит через ваш набор данных, вы знаете, может быть довольно распространенный. Но на самом деле это зависит от размера вашего тренировочного набора. И если вы контрастируете это с градиентным спусканием пакета. При пакетном спуске градиента после прохождения всего набора тренировок вы бы сделали только один шаг градиентного спуска. Итак, одна из этих маленьких ступеней градиентного спуска, где вы просто делаете один небольшой шаг градиентного спуска , и именно поэтому Stochastic градиентный спуск может быть намного быстрее. Итак, это был алгоритм стохастического градиентного спуска. И если вы его реализуете, надеюсь, это позволит вам масштабировать многие ваши алгоритмы обучения до гораздо больших наборов данных и получить гораздо больше производительности таким образом.