Deciding What to Do Next Revisited.Мы говорили о том, как оценивать алгоритмы обучения , говорили о выборе модели, много говорили о смещении и дисперсии. Итак, как это помогает нам понять , что потенциально плодотворно, потенциально не плодотворно вещи, чтобы попытаться сделать, чтобы улучшить производительность алгоритма обучения.
Play video starting at ::15 and follow transcript0:15
Вернемся к нашему оригинальному примеру и пойдем к результату.
Play video starting at ::21 and follow transcript0:21
Итак, вот наш предыдущий пример о том, что, возможно, соответствует регуляризованной линейной регрессии и обнаруживает, что она не работает так хорошо, как мы надеемся. Мы сказали, что у нас есть это меню вариантов. Итак, есть ли способ выяснить, какие из них могут быть плодотворными? Первое, что все это было получить больше обучающих примеров. Для чего это хорошо, это помогает исправить высокую дисперсию.
Play video starting at ::45 and follow transcript0:45
И конкретно, если у вас вместо проблема с высоким уклоном и не имеют проблемы дисперсии, то мы видели в предыдущем видео , что получение больше обучающих примеров,
Play video starting at ::54 and follow transcript0:54
в то время как, возможно, просто не собирается много помочь вообще. Итак, первый вариант полезен только если вы, скажем, построили кривые обучения и выясните, что у вас есть хотя бы немного дисперсии, что означает, что ошибка перекрестной валидации, вы знаете, sts немного больше, чем ошибка вашего тренировочного набора. Как насчет того, чтобы попробовать меньший набор функций? Ну, пытаясь меньший набор функций , это снова что-то, что фиксирует высокую дисперсию.
Play video starting at :1:17 and follow transcript1:17
И другими словами, если вы выясните , глядя на кривые обучения или что-то еще, что вы использовали, , которые имеют высокую проблему смещения ; затем для доброты sakes, не тратьте время, пытаясь тщательно выбрать размер меньшего набора функций для использования. Потому что, если у вас проблема с высоким уклоном, использование меньшего количества функций не поможет. В то время как, напротив, если вы посмотрите на кривые обучения или что-то еще вы выясните, что у вас проблема с высокой дисперсией, то, действительно пытается выбрать размер меньшего набора функций, stoth, которые действительно могут быть очень хорошим использованием вашего времени. Как насчет попытки получить дополнительные функции , добавления функций, как правило, не всегда, но обычно мы думаем об этом как о решении
Play video starting at :1:54 and follow transcript1:54
для исправления проблем с высоким уклоном. Так что, если вы добавляете дополнительные функции , это обычно потому, что
Play video starting at :2:1 and follow transcript2:01
ваша текущая гипотеза слишком просто , и поэтому мы хотим, чтобы попытались получить дополнительные функции для того, чтобы наша гипотеза могла лучше соответствовать обучающему набору. И аналогичным образом, добавление полиномиальных объектов; это еще один способ добавления объектов, и поэтому есть еще один способ попробовать исправить проблему высокого смещения.
Play video starting at :2:21 and follow transcript2:21
И если конкретно, если ваши кривые обучения показывают вам , что у вас все еще есть проблема с высокой дисперсией, то, вы знаете, опять же, это , возможно, менее хорошее использование вашего времени.
Play video starting at :2:30 and follow transcript2:30
И, наконец, уменьшается и увеличивается лямбда. Это быстро и легко попробовать, Я думаю, что они менее вероятно будут пустой тратой, знаете, многих месяцев вашей жизни. Но уменьшая лямбда, вы уже знаете, что фиксирует высокий уклон.
Play video starting at :2:45 and follow transcript2:45
В случае, если это не ясно вам, вы знаете, я призываю вас приостановить видео и подумать над этим, что убедит себя, что уменьшение лямбда помогает исправить высокий уклон, в то время как увеличение объема lambda фиксирует высокую дисперсию.
Play video starting at :2:59 and follow transcript2:59
И если вы не уверены, почему это так, сделайте паузу видео и убедитесь, что вы можете убедить себя, что это так. Или взгляните на кривые , которые мы строили в конце предыдущего видео, и попытайтесь убедиться, что вы понимаете, почему это так.
Play video starting at :3:15 and follow transcript3:15
Наконец, давайте возьмем все , которые мы узнали, и соотносим его обратно к нейросетям и так, вот некоторые практические советы о том, как я обычно выбираю архитектуру или шаблон связи stots нейронных сетей, которые я использую.
Play video starting at :3:30 and follow transcript3:30
Итак, если вы устанавливаете нейросеть, один из вариантов будет соответствовать, скажем, довольно небольшой нейронной сети с вы знаете, относительно мало скрытых единиц, может быть просто обогнать одну скрытую единицу. Если вы устанавливаете нейронную сеть, один из вариантов будет соответствовать относительно небольшой нейронной сети с, скажем,
Play video starting at :3:48 and follow transcript3:48
относительно небольшим, может быть, только одним скрытым слоем и, возможно, только относительно небольшим количеством sts скрытых единиц. Таким образом, подобная сеть может иметь относительно несколько параметров и быть более склонна к недооснащению.
Play video starting at :4: and follow transcript4:00
Основным преимуществом этих небольших нейронных сетей является то, что вычисления будут дешевле.
Play video starting at :4:5 and follow transcript4:05
Альтернативой было бы подгонка, возможно, относительно большой нейронной сети с большим количеством скрытых единиц — есть много скрытых в одном — или с более скрытыми слоями.
Play video starting at :4:16 and follow transcript4:16
Таким образом, эти нейронные сети, как правило, имеют больше параметров и, следовательно, более склонны к переоборудованию.
Play video starting at :4:22 and follow transcript4:22
Один недостаток, часто не основной, но что-то, о чем думать , заключается в том, что если у вас есть большое количество нейронов в вашей сети, то это может быть более вычислительно дорогим.
Play video starting at :4:33 and follow transcript4:33
Хотя в пределах разумного, это часто, надеюсь, не огромная проблема.
Play video starting at :4:36 and follow transcript4:36
Основная потенциальная проблема этих гораздо больших нейронных сетей заключается в том, что они могут быть более склонны к переоборудованию , и оказывается, если вы применяете нейронные сети очень часто используя большую нейросеть часто это на самом деле больше, тем лучше, но если это переоборудование, вы можете затем используйте регуляризацию для адреса переоборудования, обычно используя большую нейросеть, используя регуляризацию для адреса, что часто более эффективно, чем использование небольшой нейронной сети. И основным возможным недостатком является то, что он может быть более дорогостоящим.
Play video starting at :5:10 and follow transcript5:10
И, наконец, одним из других решений является, скажем, количество скрытых слоев, которые вы хотите иметь, верно? Итак, вы хотите один скрытый слой или вы хотите три скрытых слоя, как мы показали здесь, или вы хотите два скрытых слоя?
Play video starting at :5:23 and follow transcript5:23
И обычно, как я думаю, что я сказал в предыдущем видео, использование одного скрытого слоя является разумным по умолчанию, но , если вы хотите выбрать количество номеров скрытых слоев, одна вещь, которую вы можете попробовать, это попробуйте тренировать нейронные сети с одним скрытым слоем или двумя скрытыми слоями или тремя скрытыми слоями и посмотреть, какая из этих нейронных сетей лучше всего работает на наборах перекрестной валидации. Вы берете свои три нейронные сети с одним, двумя и тремя скрытыми слоями и вычисляете ошибку перекрестной валидации в Jcv и все их оценки и используйте это, чтобы stots выбрать, какой из этих средств вы считаете лучшей нейронной сетью.
Play video starting at :6:2 and follow transcript6:02
Итак, это все для смещения и дисперсии и способов , как кривые обучения, которые пытались диагностировать эти проблемы. Насколько вы думаете , для одного может быть правдивым или не правдивым, чтобы попытаться улучшить производительность алгоритма обучения.
Play video starting at :6:16 and follow transcript6:16
Если вы поняли содержание последних нескольких видео, и если вы применяете их, вы на самом деле быть гораздо более эффективным уже и получение алгоритмов обучения для работы над проблемами и даже большой долей, stots может быть большинство практиков есть машинного обучения здесь в Силиконовая Долина сегодня делает эти вещи в качестве своей полной занятости.
Play video starting at :6:35 and follow transcript6:35
Так что я надеюсь, что эти части советов по опыту в диагностике
Play video starting at :6:42 and follow transcript6:42
помогут вам значительно эффективно и мощно применять обучение и оценка заставить их работать очень хорошо.