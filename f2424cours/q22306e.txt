Advanced Optimization.In the last video, we talked about gradient descent for minimizing the cost function J of theta for logistic regression.
Play video starting at ::7 and follow transcript0:07
In this video, I'd like to tell you about some advanced optimization algorithms and some advanced optimization concepts.
Play video starting at ::15 and follow transcript0:15
Using some of these ideas, we'll be able to get logistic regression
Play video starting at ::19 and follow transcript0:19
to run much more quickly than it's possible with gradient descent. And this will also let the algorithms scale much better to very large machine learning problems, such as if we had a very large number of features. Here's an alternative view of what gradient descent is doing. We have some cost function J and we want to minimize it. So what we need to is, we need to write code that can take as input the parameters theta and they can compute two things: J of theta and these partial derivative terms for, you know, J equals 0, 1 up to N. Given code that can do these two things, what gradient descent does is it repeatedly performs the following update. Right? So given the code that we wrote to compute these partial derivatives, gradient descent plugs in here and uses that to update our parameters theta.
Play video starting at :1:8 and follow transcript1:08
So another way of thinking about gradient descent is that we need to supply code to compute J of theta and these derivatives, and then these get plugged into gradient descents, which can then try to minimize the function for us. For gradient descent, I guess technically you don't actually need code to compute the cost function J of theta. You only need code to compute the derivative terms. But if you think of your code as also monitoring convergence of some such, we'll just think of ourselves as providing code to compute both the cost function and the derivative terms.
Play video starting at :1:42 and follow transcript1:42
So, having written code to compute these two things, one algorithm we can use is gradient descent.
Play video starting at :1:48 and follow transcript1:48
But gradient descent isn't the only algorithm we can use. And there are other algorithms, more advanced, more sophisticated ones, that, if we only provide them a way to compute these two things, then these are different approaches to optimize the cost function for us. So conjugate gradient BFGS and L-BFGS are examples of more sophisticated optimization algorithms that need a way to compute J of theta, and need a way to compute the derivatives, and can then use more sophisticated strategies than gradient descent to minimize the cost function.
Play video starting at :2:21 and follow transcript2:21
The details of exactly what these three algorithms is well beyond the scope of this course. And in fact you often end up spending, you know, many days, or a small number of weeks studying these algorithms. If you take a class and advance the numerical computing.
Play video starting at :2:36 and follow transcript2:36
But let me just tell you about some of their properties.
Play video starting at :2:40 and follow transcript2:40
These three algorithms have a number of advantages. One is that, with any of this algorithms you usually do not need to manually pick the learning rate alpha.
Play video starting at :2:50 and follow transcript2:50
So one way to think of these algorithms is that given is the way to compute the derivative and a cost function. You can think of these algorithms as having a clever inter-loop. And, in fact, they have a clever
Play video starting at :3:1 and follow transcript3:01
inter-loop called a line search algorithm that automatically tries out different values for the learning rate alpha and automatically picks a good learning rate alpha so that it can even pick a different learning rate for every iteration. And so then you don't need to choose it yourself.
Play video starting at :3:21 and follow transcript3:21
These algorithms actually do more sophisticated things than just pick a good learning rate, and so they often end up converging much faster than gradient descent.
Play video starting at :3:32 and follow transcript3:32
These algorithms actually do more sophisticated things than just pick a good learning rate, and so they often end up converging much faster than gradient descent, but detailed discussion of exactly what they do is beyond the scope of this course.
Play video starting at :3:45 and follow transcript3:45
In fact, I actually used to have used these algorithms for a long time, like maybe over a decade, quite frequently, and it was only, you know, a few years ago that I actually figured out for myself the details of what conjugate gradient, BFGS and O-BFGS do. So it is actually entirely possible to use these algorithms successfully and apply to lots of different learning problems without actually understanding the inter-loop of what these algorithms do.
Play video starting at :4:12 and follow transcript4:12
If these algorithms have a disadvantage, I'd say that the main disadvantage is that they're quite a lot more complex than gradient descent. And in particular, you probably should not implement these algorithms - conjugate gradient, L-BGFS, BFGS - yourself unless you're an expert in numerical computing.
Play video starting at :4:30 and follow transcript4:30
Instead, just as I wouldn't recommend that you write your own code to compute square roots of numbers or to compute inverses of matrices, for these algorithms also what I would recommend you do is just use a software library. So, you know, to take a square root what all of us do is use some function that someone else has written to compute the square roots of our numbers.
Play video starting at :4:51 and follow transcript4:51
And fortunately, Octave and the closely related language MATLAB - we'll be using that - Octave has a very good. Has a pretty reasonable library implementing some of these advanced optimization algorithms. And so if you just use the built-in library, you know, you get pretty good results.
Play video starting at :5:8 and follow transcript5:08
I should say that there is a difference between good and bad implementations of these algorithms. And so, if you're using a different language for your machine learning application, if you're using C, C++, Java, and so on, you might want to try out a couple of different libraries to make sure that you find a good library for implementing these algorithms. Because there is a difference in performance between a good implementation of, you know, contour gradient or LPFGS versus less good implementation of contour gradient or LPFGS.
Play video starting at :5:43 and follow transcript5:43
So now let's explain how to use these algorithms, I'm going to do so with an example.
Play video starting at :5:48 and follow transcript5:48
Let's say that you have a problem with two parameters
Play video starting at :5:53 and follow transcript5:53
equals theta zero and theta one. And let's say your cost function is J of theta equals theta one minus five squared, plus theta two minus five squared.
Play video starting at :6:2 and follow transcript6:02
So with this cost function. You know the value for theta 1 and theta 2. If you want to minimize J of theta as a function of theta. The value that minimizes it is going to be theta 1 equals 5, theta 2 equals equals five.
Play video starting at :6:15 and follow transcript6:15
Now, again, I know some of you know more calculus than others, but the derivatives of the cost function J turn out to be these two expressions. I've done the calculus.
Play video starting at :6:26 and follow transcript6:26
So if you want to apply one of the advanced optimization algorithms to minimize cost function J. So, you know, if we didn't know the minimum was at 5, 5, but if you want to have a cost function 5 the minimum numerically using something like gradient descent but preferably more advanced than gradient descent, what you would do is implement an octave function like this, so we implement a cost function,
Play video starting at :6:49 and follow transcript6:49
cost function theta function like that,
Play video starting at :6:52 and follow transcript6:52
and what this does is that it returns two arguments, the first J-val, is how
Play video starting at :6:58 and follow transcript6:58
we would compute the cost function J. And so this says J-val equals, you know, theta one minus five squared plus theta two minus five squared. So it's just computing this cost function over here.
Play video starting at :7:10 and follow transcript7:10
And the second argument that this function returns is gradient. So gradient is going to be a two by one vector,
Play video starting at :7:18 and follow transcript7:18
and the two elements of the gradient vector correspond to the two partial derivative terms over here.
Play video starting at :7:27 and follow transcript7:27
Having implemented this cost function,
Play video starting at :7:29 and follow transcript7:29
you would, you can then
Play video starting at :7:31 and follow transcript7:31
call the advanced optimization
Play video starting at :7:34 and follow transcript7:34
function called the fminunc - it stands for function minimization unconstrained in Octave -and the way you call this is as follows. You set a few options. This is a options as a data structure that stores the options you want. So grant up on, this sets the gradient objective parameter to on. It just means you are indeed going to provide a gradient to this algorithm. I'm going to set the maximum number of iterations to, let's say, one hundred. We're going give it an initial guess for theta. There's a 2 by 1 vector. And then this command calls fminunc. This at symbol presents a pointer to the cost function
Play video starting at :8:13 and follow transcript8:13
that we just defined up there. And if you call this, this will compute, you know, will use one of the more advanced optimization algorithms. And if you want to think it as just like gradient descent. But automatically choosing the learning rate alpha for so you don't have to do so yourself. But it will then attempt to use the sort of advanced optimization algorithms. Like gradient descent on steroids. To try to find the optimal value of theta for you. Let me actually show you what this looks like in Octave.
Play video starting at :8:40 and follow transcript8:40
So I've written this cost function of theta function exactly as we had it on the previous line. It computes J-val which is the cost function. And it computes the gradient with the two elements being the partial derivatives of the cost function with respect to, you know, the two parameters, theta one and theta two.
Play video starting at :8:59 and follow transcript8:59
Now let's switch to my Octave window. I'm gonna type in those commands I had just now. So, options equals optimset. This is the notation for setting my
Play video starting at :9:9 and follow transcript9:09
parameters on my options, for my optimization algorithm. Grant option on, maxIter, 100 so that says 100 iterations, and I am going to provide the gradient to my algorithm.
Play video starting at :9:23 and follow transcript9:23
Let's say initial theta equals zero's two by one. So that's my initial guess for theta.
Play video starting at :9:30 and follow transcript9:30
And now I have of theta,
Play video starting at :9:32 and follow transcript9:32
function val exit flag
Play video starting at :9:37 and follow transcript9:37
equals fminunc constraint.
Play video starting at :9:40 and follow transcript9:40
A pointer to the cost function.
Play video starting at :9:43 and follow transcript9:43
and provide my initial guess.
Play video starting at :9:46 and follow transcript9:46
And the options like so. And if I hit enter this will run the optimization algorithm.
Play video starting at :9:53 and follow transcript9:53
And it returns pretty quickly. This funny formatting that's because my line, you know, my
Play video starting at :9:59 and follow transcript9:59
code wrapped around. So, this funny thing is just because my command line had wrapped around. But what this says is that numerically renders, you know, think of it as gradient descent on steroids, they found the optimal value of a theta is theta 1 equals 5, theta 2 equals 5, exactly as we're hoping for. The function value at the optimum is essentially 10 to the minus 30. So that's essentially zero, which is also what we're hoping for. And the exit flag is 1, and this shows what the convergence status of this. And if you want you can do help fminunc to read the documentation for how to interpret the exit flag. But the exit flag let's you verify whether or not this algorithm thing has converged.
Play video starting at :10:43 and follow transcript10:43
So that's how you run these algorithms in Octave.
Play video starting at :10:47 and follow transcript10:47
I should mention, by the way, that for the Octave implementation, this value of theta, your parameter vector of theta, must be in rd for d greater than or equal to 2. So if theta is just a real number. So, if it is not at least a two-dimensional vector or some higher than two-dimensional vector, this fminunc may not work, so and if in case you have a one-dimensional function that you use to optimize, you can look in the octave documentation for fminunc for additional details.
Play video starting at :11:18 and follow transcript11:18
So, that's how we optimize our trial example of this simple quick driving cost function. However, we apply this to let's just say progression.
Play video starting at :11:27 and follow transcript11:27
In logistic regression we have a parameter vector theta, and I'm going to use a mix of octave notation and sort of math notation. But I hope this explanation will be clear, but our parameter vector theta comprises these parameters theta 0 through theta n because octave indexes,
Play video starting at :11:46 and follow transcript11:46
vectors using indexing from 1, you know, theta 0 is actually written theta 1 in octave, theta 1 is gonna be written. So, if theta 2 in octave and that's gonna be a written theta n+1, right? And that's because Octave indexes is vectors starting from index of 1 and so the index of 0.
Play video starting at :12:6 and follow transcript12:06
So what we need to do then is write a cost function that captures the cost function for logistic regression. Concretely, the cost function needs to return J-val, which is, you know, J-val as you need some codes to compute J of theta and we also need to give it the gradient. So, gradient 1 is going to be some code to compute the partial derivative in respect to theta 0, the next partial derivative respect to theta 1 and so on. Once again, this is gradient
Play video starting at :12:37 and follow transcript12:37
1, gradient 2 and so on, rather than gradient 0, gradient 1 because octave indexes is vectors starting from one rather than from zero.
Play video starting at :12:47 and follow transcript12:47
But the main concept I hope you take away from this slide is, that what you need to do, is write a function that returns
Play video starting at :12:55 and follow transcript12:55
the cost function and returns the gradient.
Play video starting at :12:58 and follow transcript12:58
And so in order to apply this to logistic regression or even to linear regression, if you want to use these optimization algorithms for linear regression.
Play video starting at :13:7 and follow transcript13:07
What you need to do is plug in the appropriate code to compute these things over here.
Play video starting at :13:15 and follow transcript13:15
So, now you know how to use these advanced optimization algorithms.
Play video starting at :13:19 and follow transcript13:19
Because, using, because for these algorithms, you're using a sophisticated optimization library, it makes the just a little bit more opaque and so just maybe a little bit harder to debug. But because these algorithms often run much faster than gradient descent, often quite typically whenever I have a large machine learning problem, I will use these algorithms instead of using gradient descent.
Play video starting at :13:43 and follow transcript13:43
And with these ideas, hopefully, you'll be able to get logistic progression and also linear regression to work on much larger problems. So, that's it for advanced optimization concepts.
Play video starting at :13:55 and follow transcript13:55
And in the next and final video on Logistic Regression, I want to tell you how to take the logistic regression algorithm that you already know about and make it work also on multi-class classification problems.