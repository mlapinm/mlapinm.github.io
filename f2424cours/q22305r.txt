Simplified Cost Function and Gradient Descent.
В этом видео мы выясним немного более простой способ написать функцию стоимости , чем мы использовали до сих пор.
И мы также выясним, как применить градиентный спуск , чтобы соответствовать параметрам логистической регрессии.
Итак, к концу этого, видео вы знаете, как реализовать полностью рабочую версию логистической регрессии.
Вот наша функция затрат для логистической регрессии.
Наша общая функция затрат в 1 над m умножить сумму по торговому набору стоимость составления различных прогнозов на разных примерах меток y i.
И это стоимость одного примера, который мы разработали ранее.
И просто хочу напомнить вам, что для классификационных задач в наших тренировочных наборах, а фактически даже для примеров, теперь, когда наш тренировочный набор y всегда равен нулю или единице, верно?
Это своего рода часть математического определения y.
Поскольку y либо ноль, либо один, мы сможем придумать более простой способ написать эту функцию стоимости.
И в частности, вместо того, чтобы записывать эту функцию стоимости на две отдельные строки с двумя отдельными случаями, поэтому y равен одному, а y равен нулю.
Я покажу вам способ взять эти две строки и сжать их в одно уравнение.
И это сделало бы удобнее записать функцию стоимости и вывести градиентный спуск.
Конкретно, мы можем записать функцию стоимости следующим образом.
Мы говорим, что стоимость H (x), y.
Я собираюсь написать это как -y раз log h (x) - (1-y) раз log (1-h (x)).
И я покажу вам через секунду, что это выражение, нет, это уравнение, является эквивалентным способом, или более компактным способом, записывать это определение функции стоимости, которую мы имеем здесь.
Посмотрим, почему это так.
Мы знаем, что есть только два возможных случая.
Y должен быть равен нулю или единицу.
Итак, предположим, что Y равен одному.
Если у равно 1, то это уравнение говорит, что стоимость равна, хорошо, если у равна 1, то эта вещь здесь равна 1.
И 1 минус y будет равен 0, правильно.
Таким образом, если у равен 1, то 1 минус у равен 1 минус 1, что, следовательно, равно 0.
Таким образом, второй срок умножается на 0 и уходит.
И мы остались только с этим первым термином, который y раз log- y раз log (h (x)).
Y равно 1, что равно -log h (x).
И это уравнение именно то, что мы имеем здесь, если y = 1.
Другой случай - если y = 0.
И если это так, то наша запись функции cos говорит, что, хорошо, если y равно 0, то этот термин здесь будет равен нулю.
В то время как 1 минус y, если y равен нулю, будет равен 1, , потому что 1 минус y становится 1 минус 0, что просто равно 1.
И поэтому функция затрат упрощает только этот последний срок здесь, верно?
Потому что кулак термин здесь умножается на ноль, и поэтому он исчезает, и поэтому он просто остается с этим последним термином, который является -log (1- h (x)).
И вы можете убедиться, что этот термин здесь именно то, что мы имели для , когда y равен 0.
Это показывает, что это определение стоимости просто более компактный способ взять оба этих выражения, случаи y =1 и y = 0, и записать их в более удобном виде с одной строкой.
Поэтому мы можем написать все наши функции стоимости для логистической регрессии следующим образом.
Именно это 1 над м суммы этих функций стоимости.
И подключив определение для стоимость, которую мы разработали ранее, мы заканчиваем этим.
И мы просто ставим знак минус снаружи.
И почему мы выбираем эту конкретную функцию, , в то время как похоже, что могут быть другие функции стоимости, которые мы могли бы выбрать.
Хотя у меня не будет времени подробно останавливаться на этом курсе, эта функция затрат может быть получена из статистики , используя принцип оценки максимальной правдоподобия.
Что является идеей в статистике для , как эффективно находить данные параметров для разных моделей.
И он также имеет хорошее свойство, что он выпуклый.
Таким образом, это функция затрат, которую по существу все используют при установке моделей логистической регрессии.
Если вы не понимаете терминов, которые я только что сказал, если вы не знаете, что такое принцип оценки максимальной правдоподобия, не беспокойтесь об этом.
Но это просто более глубокое обоснование и обоснование за этой конкретной функцией затрат, чем у меня есть время, чтобы войти в этот класс.
Учитывая эту функцию стоимости, для того, чтобы соответствовать параметрам, то, что мы собираемся сделать, это попытаться найти параметры theta, которые минимизируют J из theta.
Поэтому, если мы попытаемся минимизировать это, это даст нам некоторый набор параметров theta.
Наконец, если нам будет дан новый пример с некоторым набором функций x, мы можем взять те, которые мы подходим к нашему обучательному набору и вывести наше предсказание как это.
И просто, чтобы напомнить вам, вывод моей гипотезы я собираюсь интерпретировать как вероятность того, что y равна единице.
И учитывая входные x и параметризованные тета.
Но просто, вы можете думать об этом как о моей гипотезе, оценивая вероятность , что y равен единице.
Таким образом, все, что остается сделать, это выяснить, как на самом деле свести к минимуму J theta как функцию theta так , что мы можем фактически соответствовать параметрам нашего тренировочного набора.
Способ минимизации функции затрат - это использование градиентного спуска.
Вот наша функция затрат, и если мы хотим минимизировать ее как функцию theta, вот наш обычный шаблон для классифицированного спуска, где мы неоднократно обновляем каждый параметр, принимая, обновляя его как сам минус обучение луч альфа раз этот производный термин.
Если вы знаете какое-то исчисление, не стесняйтесь взять этот термин и попытаться вычислить производную самостоятельно и посмотреть, можете ли вы упростить его до того же ответа, который я получаю.
Но даже если вы не знаете исчисления, не беспокойтесь об этом.
Если вы действительно вычислите это, то, что вы получаете это уравнение, и просто напишите его здесь.
Это сумма от i равна от одного до m по существу ошибки раз xij.
Поэтому, если вы возьмете этот частичный производный термин и подключите его обратно сюда, мы можем затем записать наш алгоритм градиентного спуска следующим образом.
И все, что я сделал, это я взял производный термин для предыдущего слайда и подключил его туда.
Итак, если у вас есть n объектов, у вас будет векторный параметр theta, который с параметрами theta 0, theta 1, theta 2, вплоть до theta n.
И вы будете использовать это обновление для одновременного обновления всех ваших значений theta.
Теперь, если взять это правило обновления и сравните его с тем, что мы делали для линейной регрессии.
Вы можете быть удивлены, осознав, что, ну, это уравнение было именно тем, что мы имели для линейной регрессии.
На самом деле, если вы посмотрите на более ранние видео и посмотрите на правило обновления, правило Градиентного спуска для линейной регрессии.
Это выглядело точно так же, как я нарисовал здесь внутри синей коробки.
Итак, линейная регрессия и логистическая регрессия разные алгоритмы или нет?
Ну, это решается, заметив, что для логистической регрессии, то, что изменилось определение этой гипотезы.
Так как в то время как для линейной регрессии у нас было h (x) равно theta transpose X, теперь это определение h (x) изменилось.
И вместо этого теперь один за один плюс е к отрицательному транспонировать x.
Таким образом, несмотря на то, что правило обновления выглядит косметически идентичным, потому что определение гипотезы изменилось, это на самом деле не то же самое, что градиентный спуск для линейной регрессии.
В более раннем видео, когда мы говорили о градиентном спуске для линейной регрессии , мы говорили о том, как контролировать градиентный спуск, чтобы убедиться, что он сходится Обычно я применяю тот же метод к логистической регрессии, тоже для мониторинга градиентного спуска, чтобы убедиться, что он сходится правильно.
И, надеюсь, вы сами сможете понять, как применить эту технику к логистической регрессии.
При реализации логистической регрессии с градиентным спусканием, у нас есть все эти разные значения параметров, тета нуля до тета n, которые нам нужно обновить с помощью этого выражения.
И одна вещь, которую мы могли бы сделать, это иметь цикл for.
Таким образом, для i равен нулю n, или для i равен одному к n плюс один.
Таким образом, обновите каждое из этих значений параметров по очереди.
Но, конечно, вместо того, чтобы использовать цикл for, в идеале мы также использовали бы реализацию векторного подъема.
Чтобы реализация векторного подъема могла обновить все эти m плюс один параметр все одним махом.
И чтобы проверить свое собственное понимание, вы можете увидеть, можете ли вы понять, как сделать реализацию векторного подъема с помощью этого алгоритма.
Итак, теперь вы знаете, как реализовать градиентные спуски для логистической регрессии.
Была одна последняя идея, о которой мы говорили ранее, для линейной регрессии , которая заключалась в масштабировании функций.
Мы видели, как масштабирование объектов может помочь сходиться градиентного спуска быстрее для линейной регрессии Идея масштабирования объектов также относится к градиентным спускам для логистической регрессии И все же у нас есть функции, которые имеют очень разные масштабы, тогда применение масштабирования функции также может ускорить спуск профилирования для логистической регрессии.
Вот и все, теперь вы знаете, как реализовать логистическую регрессию, и это очень мощный, и , вероятно, самый широко используемый алгоритм классификации в мире.
И теперь вы знаете, как мы заставить его работать на себя.