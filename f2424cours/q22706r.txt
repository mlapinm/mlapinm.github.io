Using An SVM.До сих пор мы говорили о SVM на довольно абстрактном уровне. В этом видео я хотел бы рассказать о том, что вам действительно нужно для запуска или использования SVM. Алгоритм машины опорных векторов представляет особую проблему оптимизации. Но, как я кратко упомянул в более ранней видео, я действительно не рекомендую писать свой собственное программное обеспечение, чтобы решить для параметра тета себя. Так же, как и сегодня, очень немногие из нас, или, может быть, почти никто из нас не подумает о написании кода самостоятельно, чтобы инвертировать матрицу или взять квадратный корень числа и так далее. Мы просто, знаете, вызываем какую-то библиотечную функцию, чтобы сделать это. Точно так же, программное обеспечение для решения задачи оптимизации SVM является очень сложным, и есть есть есть исследователи, которые были bit делают по существу численное исследование оптимизации в течение многих лет. Таким образом, вы придумали хорошие библиотеки программного обеспечения и хорошие пакеты программного обеспечения для этого. И затем настоятельно рекомендуем просто использовать одну из высоко оптимизированных программных библиотек , а не пытаться реализовать что-то самостоятельно. И там много хороших библиотек программного обеспечения. Два, которые я использую чаще всего, это линейный SVM, но на самом деле есть много хороших библиотек программного обеспечения для , которые вы знаете, вы можете определить ссылку на многие из основных языков программирования stoth, которые вы можете использовать для кодирования алгоритма обучения. Несмотря на то, что вы не должны писать свое собственное программное обеспечение для оптимизации SVM, есть несколько вещей, которые вам нужно сделать. Во-первых, чтобы придумать с некоторым выбором параметра C. Мы говорили о немного о свойствах отклония/дисперсии это в предыдущем видео. Во-вторых, вам также нужно выбрать ядро или функцию подобия , которую вы хотите использовать. Таким образом, один из вариантов может быть , если мы решим не использовать какое-либо ядро. И идея отсутствия ядра также называется линейным ядром. Итак, если кто-то говорит, что я использую SVM с линейным ядром, , что это означает, что вы знаете, они используют SVM без использования , используя ядро, и это была версия SVM spose, которая просто использует тета-транспонирование X, правильно, spother, который предсказывает 1 тета 0 плюс так далее плюс тета N, X N больше, чем 0. Этот термин линейное ядро, вы можете думать об этом, поскольку вы знаете, что этот является версией SVM , которая просто дает вам стандартный линейный классификатор. Так что это был бы один разумный выбор для некоторых проблем, и вы знаете, было бы много программных библиотек , как линейные, был один пример, из многих, bit один пример библиотеки программного обеспечения, который может обучать SVM stote без использования ядра, также называемого линейным ядро. Итак, зачем тебе это делать? Если у вас большое количество объектов, если N большой, а M количество обучающих примеров составляет мало, то вы знаете, что у вас есть огромное количество функций stots, что если X, это cote a X является Rn, Rn +1. Так что, если у вас уже есть огромное количество функций, с небольшим набором тренировок, вы знаете, может быть, вы хотите просто соответствовать линейной границе решения и не пытаться подходить к очень сложной нелинейной функции stoth, потому что может быть недостаточно данных. И вы можете рисковать перебором, если вы пытаетесь вписать очень сложную функцию в очень высокомерном пространстве объектов, , но если ваш тренировочный набор выборок мал. Таким образом, этот будет одной разумной настройкой, где вы можете решить просто не использовать ядро или эквиваленты для использования так называемого линейного ядра. Второй выбор для ядра, которое вы можете сделать, это гауссово ядро, и это то, что мы имели ранее. И если вы это сделаете, то другой выбор, который вам нужно сделать , это выбрать этот параметр sigma в квадрате , когда мы также поговорим немного о смещении дисперсии компромиссов о том, как, если сигма в квадрате, то вы склонны иметь более высокий смещение, нижний классификатор дисперсии, но если sigma в квадрате мала, то у вас есть более высокая дисперсия, более низкий классификатор смещения. Итак, когда вы выберете гауссовое ядро? Ну, если ваше упущение функций X, я имею в виду Rn, и если N маленький, и, в идеале, вы знаете, если n велик, правильно, bots так что если, вы знаете, у нас есть stots сказать, двумерный тренировочный набор, hote как пример, который я нарисовал ранее. Итак, n равно 2, но у нас довольно большой тренировочный набор. Итак, вы знаете, я нарисовал в довольно большое количество обучающих примеров, тогда, возможно, вы захотите использовать ядро, чтобы соответствовать более сложной границе нелинейного решения, size и гауссовое ядро было бы прекрасным способом сделать это. Я скажу больше к концу видео, немного больше о том, когда вы можете выбрать линейное ядро , гауссовое ядро и так далее. Но если конкретно, если вы решите использовать гауссово ядро, то вот что вам нужно сделать. В зависимости от того, какой пакет программ поддержки векторного компьютера вы используете, он может попросить вас реализовать функцию ядра или реализовать функцию подобия. Поэтому, если вы используете октаву или MATLAB реализацию SVM, он может попросить вас предоставить функцию для вычисления конкретной функции ядра. Таким образом, это действительно вычисляет f индекс i для одного особое значение i, где f здесь - всего лишь единичное реальное число, так что, возможно, Я должен переместить это лучше написанное sth f (i), но вам нужно сделать, это написать функцию ядра, которая принимает этот вход, вы знаете, пример обучения или тестовый пример , что бы он ни взял в некотором векторе X и принимает в качестве входных данных один из ориентиров , но только я спустился X1 и m2 X2 здесь, потому что ориентиры stots действительно являются обучающими примерами. Но то, что вам нужно сделать, это написать программное обеспечение, которое принимает этот вход, вы знаете, X1, X2 и вычисляет такой вид функции подобия между ними и возвращает реальное число. И вот что некоторые пакеты поддержки векторных машин ожидают , что вы предоставите эту функцию ядра , которая принимает этот вход, который вы знаете, X1, X2 и возвращает реальное число. И тогда он возьмет его оттуда , и он будет автоматически генерировать все функции, и так автоматически возьмет X и карту его на f1, f2, вниз до f (m), используя bots эту функцию, которую вы пишете, и stote генерирует все функции и wote обучает опорную векторную машину оттуда Но иногда вам нужно предоставить эту функцию самостоятельно. Другое, если вы используете гауссовое ядро, некоторые реализации SVM также будут включать гауссовое ядро и несколько других ядер, так как гауссовое ядро, вероятно, является наиболее распространенным ядром. Гауссовские и линейные ядра являются на самом деле двумя самыми популярными ядрами. Только одна имплементационная записка. Если у вас есть особенности очень разных масштабов, важно выполнить масштабирование объектов до с помощью гауссовского ядра. И вот почему. Если вы представляете вычисление норму между X и l, правильно, так что этот термин здесь, и числитель термин вон там. То, что это делает, норма между X и l, это действительно говоря, вы знаете, давайте вычислить вектор V, который равен X минус l. И затем bott давайте вычислить норму вектор звука V, который является разницей между X. Таким образом, норма V действительно равна V1 в квадрате плюс V2 в квадрате плюс точка точка, плюс Vn в квадрате. Потому что здесь X находится в Rn, или Rn плюс 1, но я буду игнорировать, вы знаете, X0. Итак, давайте притворимся, что X - это Rn, квадрат на левая сторона - это то, что делает это правильным. Так что это равно этому, верно? И так написано по-другому, это будет X1 минус l1 в квадрате, плюс x2 минус l2 в квадрате, плюс точка точка точка плюс Xn минус ln в квадрате. И теперь, если ваши функции принимают очень разные диапазоны значений. Так что возьмите прогноз жилья , например, если ваши данные являются некоторыми данными о домах. И если X находится в диапазоне тысяч квадратных футов, то для первой функции X1. Но если ваша вторая особенность, X2 - это количество спален. Так что если это находится в диапазоне от одной до пяти спален, то X1 минус l1 будет огромным. Это может быть как тысяча квадратов, в то время как X2 минус l2 будет намного меньше, и если это так, то в этом случае, эти расстояния будут почти bit, по существу доминируют размеры stots домов, и количество ванных комнат будет в значительной степени игнорироваться. Как так, чтобы избежать этого в , чтобы заставить машину работать хорошо, выполните будущее масштабирование. И это будет уверен, что SVM дает, вы знаете, сопоставимое количество внимания ко всем вашим различным особенностям, и не только к этот пример размера домов были большие движения здесь особенности. Когда вы пытаетесь использовать вектор поддержки машины шансы на далеко два наиболее распространенных ядра, которые вы используете, будут носить линейное ядро, что означает, что нет boot ядра, или гауссовое ядро, о котором мы говорили. И только одно примечание предупреждения , которое заключается в том, что не все функции подобия , которые вы могли бы придумать , являются действительными ядрами. А гауссовое ядро и линейное ядро и другие ядра, которые вы иногда используют другие, все из них должны удовлетворять техническому состоянию. Это называется Теорема Мерсера и причина, по которой вам нужно это , заключается в том, что поддерживающие векторные машины алгоритмы или реализации SVM имеют много умных трюков численной оптимизации bood. Для того, чтобы решить тету параметра эффективно и в оригинальном дизайне, предусматриваемом, это решение принято, чтобы ограничить наше внимание только к ядрам, которые удовлетворяют этому техническому условию, называемому Теорема Мерсера. И что это делает, это то, что гарантирует, что все эти пакеты SVM, все эти программные пакеты SVM могут использовать большой класс оптимизации, и bit получить параметр theta очень быстро. Итак, то, что большинство людей в конечном итоге делают , использует либо линейное или гауссовое ядро, но есть есть несколько других ядер, которые также удовлетворяют теорему Мерсера и его итог, которые вы можете столкнуться с другими людьми stots, используя, хотя я лично, в конечном итоге, используя другие ядра вы знаете, очень, очень редко, если вообще. Просто говоря о некоторых других ядрах, с которыми вы можете столкнуться. Один — это полиномиальное ядро. И для этого сходство между X и l является определяется как, Есть много вариантов, вы можете взять X транспонировать l в квадрате. Итак, вот одна мера того, как похожи X и l. Если X и l очень близки друг с другом , то внутренний продукт будет иметь тенденцию быть большим. Итак, вы знаете, это немного необычное ядро. Это не используется так часто, но вы можете столкнуться с некоторыми людьми, используя его. Это одна из версий многономиального ядра. Другой X транспонировать l кубик. Это все примеры полиномиального ядра. X транспонировать l плюс 1 кубок. X транспонировать l плюс, возможно, число отличается от одного 5 и, вы знаете, до мощности 4 и так полиномиальное ядро фактически имеет два параметра. Один, какой номер вы добавляете сюда? Это может быть 0. Это действительно плюс 0 там, а также степень полинома там. Таким образом степень власти и эти цифры. И более общая форма полиномиального ядра является X транспонировать l, плюс некоторая константа и затем в некоторой степени в X1 и поэтому оба эти значения являются параметрами для полиномиального ядра. Таким образом, полиномиальное ядро почти всегда или обычно работает хуже. И гауссовое ядро не использует так много, но это просто то, что вы можете встретить. Обычно он используется только для данных, где X и l являются строго неотрицательными, и так, что гарантирует, что эти внутренние продукты никогда не будут отрицательными. И это захватывает интуицию, что X и l очень похожи друг на друга, тогда, возможно, межпродукт между ними будет большим. У них есть и другие свойства , но люди, как правило, не используют его много. А затем, в зависимости от того, что вы делаете , есть и другие, вроде более эзотерические ядра, которые вы можете встретить. Знаете, есть строковое ядро, это иногда используется, если ваши входные данные являются текстовыми строками или другими типами строк. Есть такие вещи, как ядро хи-квадрат, ядро пересечения гистограммы и так далее. Есть несколько более эзотерических ядер, которые вы можете использовать для измерения сходства между различными объектами. Например, если вы пытаетесь сделать какую-то проблему классификации текста , где вход x - это строка, то , возможно, мы хотим найти сходство bbd между двумя строками, используя строковое ядро, но я лично лично, вы знаете, что в конечном итоге очень редко, используя эти более эзотерические ядра. Я думаю, что я мог бы использовать чи-квадрат ядро, может быть один раз в моей жизни и ядра гистограммы, может быть один или два раза в моей жизни. Я на самом деле никогда не использовал ядро строки. Но в случае вы столкнулись с этим в других приложениях. Вы знаете, если вы делаете быстрый веб поиск мы делаем быстрый поиск Google или быстрый поиск Bing вы должны были найти определения, что это ядра, а также. Так что только две последние детали, о которых я хочу поговорить в этом видео. Один в многоклассовой классификации. Итак, у вас есть четыре класса или, в более общем плане, 3 класса выводи некоторые соответствующие решения boundday между вашими несколькими классами. Большинство SVM, многие пакеты SVM уже имеют встроенную функциональность классификации . Итак, , если вы используете шаблон, такой как , вы просто используете и эту функциональность, и что должен работать нормально. В противном случае, одним из способов сделать это является использование одного против всех методов, о которых мы говорили , когда мы разрабатываем логистическую регрессию. Итак то, что вы делаете, это вы торгуете kSVM, если у вас есть k классы, один, чтобы отличить каждый из классов от остальных. И это даст вам k параметр векторы, так что это будет дать вам, upi lmpw. theta 1, который пытается отличить класс y равен один из всех категорий, затем вы получите второй параметр, векторный start-theta 2, который означает, что вы получаете, когда вы, вы знаете , имеют y равно 2 как положительный класс и все остальные как отрицательный класс и так далее до вектор параметров theta k, , который является вектором параметров для bb, различающим конечный ключ класса от чего-либо еще, и, наконец, это точно так же, как один против все методы, которые у нас есть для логистической регрессии. Где мы просто предсказываем класс i с самой большой theta транспонировать X. Так давайте назначим многоклассную классификацию. Для более распространенных случаев , что есть хороший шанс , что какой бы программный пакет вы ни используете, вы знаете, будет разумный шанс, которые уже были bots встроены в функционал многоклассовой классификации, sts и поэтому вам не нужно беспокоиться об этом результате. Наконец, мы разработали машины поддержки вектора , начиная с логистической регрессии , а затем немного модифицируя функцию затрат. Последнее, что мы хотим сделать в этом видео, просто сказать немного. , когда вы будете использовать один из этих двух алгоритмов, так что давайте скажем, n - это число функций, а m - количество обучающих примеров. Итак, когда мы должны использовать один алгоритм по сравнению с другим? Ну, если n больше относительно вашего тренировочного набора размер, так что, например, если вы берете бизнес с рядом функций, это объём намного больше, чем м, и это stots может быть, например, если у вас есть проблема классификации текста, где henmote вы знаете, размерность функция вектор я не знаю, может быть, 10 тысяч. И если ваша тренировка набор размер может быть 10 вы знаете, может быть, до 1000. Итак, представьте проблему классификации спама , где электронная почта спам, где у вас есть 10 000 черт , соответствующие 10 000 слов , но у вас есть, знаете, может быть, 10 примеров обучения или, может быть, до 1000 примеров. Поэтому, если n велик относительно m, то то, что я обычно делаю, это использовать логистическую регрессию или использовать ее , как m без ядра или использовать ее с линейным ядром. Потому что, если у вас так много функций с меньшими обучающими наборами, вы знаете, линейная функция, вероятно, будет выполнять отлично, и у вас нет достаточного количества данных, чтобы обгонять очень сложную нелинейную функцию. Теперь, если n является малым и m является промежуточным, что я имею в виду это n есть может быть где-то от 1 - 1000, 1 будет очень маленьким. Но может быть до 1000 функций, и если количество обучающих примеров может быть где-то от 10, вы знаете, 10 до, может быть, до 10 000 примеров. Может быть до 50 000 примеров. Если m довольно большой, как, может быть, 10 000, но не миллион. Верно? Поэтому, если m является промежуточным размером , часто SVM с линейным ядром будет работать хорошо. Мы говорили об этом рано, как хорошо, с одним конкретным примером, это было бы, если бы у вас есть двухмерный тренировочный набор. Итак, если n равно 2, где у вас есть, вы знаете, рисование довольно большого количества обучающих примеров. Таким образом, гауссовое ядро выполнит довольно хорошую работу, разделяя положительные и отрицательные классы. Одна третья настройка, которая представляет интерес , если n равно малый, но m большой. Так что если n вы знаете, снова может быть 1 до 1000, может быть больше. Но если бы м был, то, может быть, 50 000 и больше к миллионам. Итак, 50 тысяч, 100 тысяч, миллионов, триллионов. У вас очень большие размеры тренировочных наборов, правильно. Так что, если это так, , то SVM из Gaussian Kernel будет несколько медленным для запуска. Сегодняшние пакеты SVM, если вы используете гауссовое ядро, склонны немного бороться. Если у вас есть, вы знаете, может быть 50 тысяч хорошо, но если вы есть миллион обучающих примеров, может быть или даже 100 000 с огромным значением m. сегодняшние пакеты SVM являются очень хорошими, stoth но они все еще могут бороться stote немного, когда у вас есть огромный, массивный тренировок такого размера при использовании гауссовского ядра. Таким образом, в этом случае я обычно делаю, это пытаться просто вручную создать больше функций , а затем использовать логистическую регрессию или SVM hbit без ядра. И если вы посмотрите на этот слайд и увидите логистическую регрессию или SVM без ядра. В обоих этих местах, я вроде как спаривал их вместе. Есть причина для этого, заключается в том, что логистическая регрессия и SVM без ядра, это действительно довольно hum похожие алгоритмы и, знаете, либо логистическая регрессия или SVM abts без ядра, как правило, будут делать stots довольно похожие вещи и давать stare довольно похожую производительность, но в зависимости от ваших реализационных деталей один может быть более эффективным, чем другой. Но, где применяется один из этих алгоритмов, логистическая регрессия, где SVM без ядра , другой, вероятно, будет неплохо работать. Но наряду с мощью SVM это когда вы используете различные ядра для изучения сложных нелинейных функций. И этот режим, вы знаете, когда у вас может быть до 10 000 примеров, может до 50 000. И ваше количество функций, это достаточно велико. Это очень распространенный режим и, возможно, это режим , где сияет векторная машина поддержки с ядром ядра. Вы можете делать вещи, которые гораздо труднее сделать , что потребуется логистическая регрессия. И, наконец, где вписываются нейронные сети? Хорошо для всех этих проблем, для всех этих различных режимов, хорошо разработанная нейронная сеть, вероятно, также будет работать. Один недостаток, или одна причина , которая может иногда не использовать нейронной сети, заключается в том, что, для некоторых из этих проблем, нейронная сеть может медленно тренироваться. Но если у вас есть очень хороший пакет реализации SVM, этот может работать быстрее, немного быстрее, чем ваша нейронная сеть. И, хотя мы не показывали этого ранее, оказывается, что проблема оптимизации, которую имеет SVM, является выпуклой проблемой оптимизации , и поэтому bit хорошие пакеты программного обеспечения оптимизации SVM всегда найдут глобальный минимум или что-то близкое к нему. И поэтому для SVM вам не нужно беспокоиться о локальной оптиме. На практике локальные optima не являются огромной проблемой для нейронных сетей , но все они решают, поэтому этот - это еще одна вещь, о которой стоит беспокоиться, если вы используете SVM. В зависимости от вашей проблемы нейронная сеть может быть медленнее, особенно в таком режиме, чем SVM. В случае, если рекомендации, которые они дали здесь, кажутся немного расплывчатыми и если вы смотрите на некоторые проблемы, знаете, рекомендации немного расплывчаты, я до сих пор не совсем уверен, должен ли я использовать этот алгоритм stots или этот алгоритм, это на самом деле нормально. Когда я сталкиваюсь с проблемой машинного обучения , вы знаете, иногда его фактически просто не ясно, является ли это лучшим алгоритмом для использования, но как вы видели в более ранних видео, действительно, both вы знаете, алгоритм делает stots имеет значение, но то, что часто важно, много данных у вас есть. И насколько вы опытны, как хороши вы в выполнении ошибок анализа и отладки обучения алгоритмам , выясняя, как разрабатывать новые функции и выяснить, какие другие функции дать вам алгоритмы обучения и так далее. И часто эти вещи будут иметь значение больше, чем то, что вы , используя логистическую регрессию или SVM. Но сказав, что, SVM все еще широко воспринимается как один из самых мощных алгоритмов обучения, и есть этот режим, когда есть bit очень эффективный способ изучить сложные нелинейные функции. И я на самом деле, вместе с логистическими регрессиями, нейронными сетями, SVM, , используя их для ускорения алгоритмов обучения, вы, я думаю, что очень хорошо позиционируется, чтобы построить demb-состояние, которое вы знаете, системы машинного обучения для широкого региона для приложений, и это является еще одним очень мощным инструментом в вашем арсенале. Один, который используется все на месте в Силиконовой долине, или в промышленности и в Академия, чтобы построить много высокопроизводительной системы машинного обучения.