Cost Function.В этом видео мы определим понятие функции затрат.Она поможет нам наилучшим образом подобрать прямую, описывающую наши данные.В задачах линейной регрессии наш обучающий набор выглядит примерно так.Буквой m, если помните, мы обозначили количество обучающих примеров.Допустим, m равняется 47.А наша гипотеза, с помощью которой мы будем предсказывать стоимость, это такая линейная функция.Еще немного терминологии: эти переменные, тета нулевое и тета первое, я буду называть параметрами модели.В этом видео мы поговорим о том, как научиться выбирать эти параметры, тета нулевое и тета первое.Выбирая различные значения параметров тета нулевое и тета первое, мы будем получать различные функции-гипотезы.Некоторые из вас наверняка знакомы с тем, что я собираюсь продемонстрировать на этом слайде, но все же я приведу несколько примеров в качестве напоминания.Если тета нулевое равно 1.5, а тета первое равно 0, график функции будет выглядеть так.Верно? Функция будет равна 1.5 плюс ноль, умноженный на x, то есть мы получим постоянную функцию, а на графике — горизонтальную линию на уровне 1.5. Если тета нулевое равно 0, а тета первое равно 0.5, график гипотезы получится таким.Прямая должна пройти через эту точку, (2.1), и наша h(x) — точнее, h-тета от x, но я иногда буду опускать «тета» для краткости —так вот, наша h(x) будет равняться просто 0.5 умножить на х, и это ее график.И, наконец, если тета нулевое равняется 1, а тета первое — 0.5, мы получим такой график гипотезы.Он должен пройти через точку (2.2), вот так.Это моя функция h(x), то есть h-тета от x.Все понятно?Вы помните, что это функция h-тета от x, но для краткости я иногда пишу просто h(x).В задаче линейной регрессии у нас есть обучающий набор, например, такой.Наша цель — найти такие значения параметров тета нулевое и тета первое, чтобы прямая линия, которую они описывают, хорошо соответствовала нашим данным.Например, как вот эта линия.Итак, как нам получить значения параметров, которые будут хорошо соответствовать данным?Идея в том, чтобы выбрать параметры тета нулевое и тета первое так, чтобы значение h(x), то есть наше предсказание для входной величины x, было бы близко к известным значениям y по меньшей мере для обучающего набора. Наш обучающий набор состоит из множества примеров проданных домов, для которых нам известен x — площадь дома — и цена, по которой дом был на деле продан.Так давайте постараемся выбрать такие значения параметров, чтобы хотя бы для x из обучающего набора мы получали достаточно точное предсказание y.Теперь более формально.В задаче линейной регрессии мы на самом деле решаем задачу оптимизации.То есть, варьируя параметры тета нулевое и тета первое я буду минимизировать.Вот это значение, так? Мне нужно, чтобы вот эта разница между h(x) и y была минимальной.Для этого я собираюсь минимизировать квадрат разницы между значениями функции-гипотезы и фактической ценой дома.Хорошо?Уточним еще кое-что.Напомню, что я обозначил через (x(i), y(i)) - i-й пример из обучающей выборки.Так что на самом деле мне нужна сумма значений ошибки по всему обучающему набору.Сумма по i от 1 до m к вадратов разницы между этим значением — предсказанием функции-гипотезы для площади дома номер i — и фактической ценой дома. Эту сумму квадратов разницы между предсказанной и фактической ценой по всему обучающему набору я и хочу минимизировать.Напомню, что мы обозначаем через m размер обучающего набора, то есть количество известных примеров.Все понятно?Символ «решетка» (#) в данном случае обозначает «количество».Понятно?И, чтобы немного упростить математические выкладки, я буду работать с этой величиной, деленной на m.Даже, на самом деле, на 2m — то есть мы будем минимизировать среднюю ошибку, деленную пополам. Добавление 1/2 в качестве коэффициента призвано немного упростить расчеты.Если минимизировать половину функции, мы получим те же самые значения параметров тета нулевое и тета первое, что и для самой функции.Продолжайте, если это выражение вам понятно, хорошо?Здесь — функция h с индексом тета от x, как обычно, так?Она равняется тета нулевому плюс тета первому умножить на x(i).А эта запись — минимизировать по тета нулевое и тета первое — означает, что нам нужно найти такие тета нулевое и тета первое, чтобы это выражение приняло минимальное значение.И это выражение зависит от значений тета нулевого и тета первого.Согласны?Резюмирую: мы ставим задачу найти такие значения параметров тета нулевое и тета первое, чтобы усредненное значение ошибки, то есть сумма квадратов отклонений предсказанного значения от фактического по всему обучающему набору, деленная на 2m, было минимальным.И это будет моей общей целевой функцией для линейной регрессии.Я могу переписать задачу немного более четко, по традиции определив функцию ошибки, функцию затрат. Она как раз будет равняться этому выражению.Вот этой формуле, написанной наверху.Тогда задача состоит в том, чтобы минимизировать по тета нулевому и тета первому функцию J от тета нулевого и тета первого.То есть, вот эту функцию затрат.Такую функцию затрат еще называют функцией среднеквадратических отклонений. Почему, собственно, мы берем квадраты ошибок?Оказывается, что такая функция затрат — разумный выбор, она хорошо подходит для большинства регрессионных задач.Есть и другие функции затрат, которые неплохо работают, но сумма квадратов отклонений, вероятно, используется для задач регрессии чаще всего. Далее мы поговорим и о других функциях, но рассмотренный вариант — разумный выбор для большей части задач линейной регрессии.Итак.Это функция стоимости.Пока что мы разобрали лишь математическое определение функции стоимости. В нашем случае это функция J от тета нулевого и тета первого. Наверное, она кажется немного абстрактной, и вам еще неясно, как она работает. В следующих видео мы более подробно рассмотрим, как функция J себя ведет, и постараемся четче понять, что она вычисляет и почему подходит для наших задач.