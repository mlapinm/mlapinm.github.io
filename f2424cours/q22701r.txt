Optimization Objective.
К настоящему времени вы видели целый ряд алгоритмов обучения различиями.
С контролируемым обучением производительность многих контролируемых алгоритмов обучения будет довольно похожа, и реже важно будет ли вы используете алгоритм обучения a или алгоритм обучения b, но то, что важнее будет часто такие вещи, как количество данных, которые вы создаете эти алгоритмы на, а также ваши навыки в применении этих алгоритмов.
Такие вещи, как ваш выбор функций, которые вы разрабатываете, чтобы дать алгоритмам обучения , и как вы выбираете параметр раскрашивания, и такие вещи.
Но есть еще один алгоритм, который очень мощный и очень широко используется как в промышленности, так и в академических кругах, и это называется машиной вектора поддержки.
И по сравнению с логистической регрессией и нейросетями , Support Vector Machine, или SVM иногда дает более чистый, а иногда более мощный способ обучения сложным нелинейным функциям.
Итак, давайте возьмем следующие видео, чтобы поговорить об этом.
Позже в этом курсе я сделаю быстрый опрос ряда различных супервизорных алгоритмов так же, как очень кратко описать их.
Но машина вектора поддержки, учитывая ее популярность и насколько она мощна, это будет последним из супервизорных алгоритмов, на которые я потрачу значительное количество времени в этом курсе, как и с нашей разработкой других алгоритмов обучения, мы начнем с разговора о цель оптимизации.
Итак, давайте приступим к работе над этим алгоритмом.
Чтобы описать машину вектора поддержки, я на самом деле собираюсь начать с логистической регрессии и показать, как мы можем немного изменить ее, и получить то, что по существу является машиной вектора поддержки.
Итак, в логистической регрессии у нас есть привычная форма гипотезы и функция активации сигмоида, показанная справа.
И чтобы объяснить некоторые из математики, я собираюсь использовать z для обозначения тета-транспонирования аксиомы.
Теперь давайте подумаем о том, что мы хотели бы сделать логистическую регрессию.
Если у нас есть пример с y равен одному, и под этим я имею в виду пример либо в учебном наборе, либо в тестовом наборе, либо в наборе перекрестной проверки, но , когда y равен единице, тогда мы вроде как надеемся, что h из x будет близко к одному.
Верно, мы надеемся правильно классифицировать этот пример.
И что имеет x индекс 1, , что это означает, что тета транспонирование x должно быть больше 0.
Таким образом, есть больше, чем знак, что означает намного, гораздо больше 0.
И это потому, что это z, тета транспонирование x - это когда z намного больше 0 далеко справа от сферы.
То, что выходы логистической прогрессии становятся близкими к единицу.
И наоборот, если у нас есть пример, где y равен нулю, то мы надеемся за то, что гипотеза выведет значение, близкое к нулю.
И это соответствует тета-транспонирование x из z намного меньше нуля, потому что , что соответствует гипотезе о том, что значение близко к нулю.
Если вы посмотрите на стоимостную функцию логистической регрессии, вы обнаружите, что каждый пример (x, y) вносит такой термин в общую функцию затрат, верно?
Таким образом, для общей функции затрат, мы также будем иметь сумму на все примеры цепи и 1 над m срок, что это выражение здесь, это термин, что один пример обучения вносит вклад в общую целевую функцию, так что мы можем просто спешить их.
Теперь, если я возьму определение для падения моей гипотезы и подключу его сюда, то я получаю, что каждый пример обучения способствует этому термину, игнорируя один над M, но он вносит этот термин в мою общую функцию затрат для логистической регрессии.
Теперь рассмотрим два случая, когда y равен единице и когда y равен нулю.
В первом случае предположим, что y равен 1.
В этом случае имеет значение только этот первый термин в объективной, , потому что этот один минус y термин будет равен нулю, если y равен единице.
Итак, когда у равен единице, когда в нашем примере х запятая у, когда у равно 1, что мы получаем этот термин.
.
Минус журнал один за одним, плюс E к отрицательному Z, где, как и в последней строке , я использую Z для обозначения данных транспонированных X и, конечно, в стоимости Я должен иметь эту минусовую строку, которую мы просто имели, если Y равен одному, так что это равно к одному, я просто упрощаю таким образом в выражении, которое я записали здесь.
И если мы построим эту функцию как функцию z, то вы обнаружите, что вы получите эту кривую , показанную в левом нижнем углу слайда.
И, таким образом, мы также видим, что когда z равен большому, то есть , когда тета транспонирование x велика, что соответствует значению z, которое дает нам довольно маленькое значение, очень, очень маленький вклад в потребление.
И это объясняет, почему, когда логистическая регрессия видит положительный пример, с y=1, она пытается установить тета-транспорт x как очень большой , потому что это соответствует этому термину, в кросс-функции, будучи малым.
Теперь, чтобы заполнить машину поддержки vec, вот что мы собираемся сделать.
Мы возьмем эту кросс-функцию, этот минус log 1 над 1 плюс e к отрицательному z, и немного изменим его.
Позвольте мне взять этот пункт 1 здесь, и позвольте мне нарисовать кросс-функции, которые вы собираетесь использовать.
Новые функции пропуска могут быть плоскими отсюда и тогда мы рисуем то, что растет как прямая линия, похожая на логистическую регрессию.
Но это будет прямая линия в этой части.
Таким образом, кривая, которую я только что нарисовал пурпурный, и кривая я просто нарисовал фиолетовый и пурпурный, поэтому, если это довольно близкое приближение к кросс-функции, используемой логистической регрессией.
За исключением того, что он теперь состоит из двух сегментов линии, есть эта плоская часть справа , а затем эта прямая часть слева.
И не беспокойтесь о склоне прямой части.
Это не так важно.
Но это новая функция затрат, которую мы будем использовать, когда y равен единице, , и вы можете себе представить, что она должна сделать что-то очень похожее на логистическую регрессию.
Но оказывается, что это даст вычислительные преимущества вектора поддержки и даст нам, позже, более легкую задачу оптимизации , которая будет проще для программного обеспечения решить.
Мы только что говорили о случае y равно одному.
Другой случай - если y равен нулю.
В таком случае, если вы посмотрите на стоимость, тогда будет применяться только второй срок, потому что первый срок уходит, верно?
Если y равно нулю, то у вас есть ноль здесь, поэтому вы остались только со вторым термином выражения выше.
И поэтому стоимость примера, или вклад функции стоимости, будет дана этим термином здесь.
И если вы рисуете это как функцию z, , чтобы иметь чистый z на горизонтальной оси, вы в конечном итоге с этим.
И для вспомогательной векторной машины, еще раз мы собираемся заменить эту синюю линию чем-то подобным и в то же время мы заменим ее новой стоимостью, эта квартира здесь, эта 0 здесь.
И это затем растет как прямая линия, вот так.
Позвольте мне дать имена этих двух функций.
Эта функция слева я буду называть индекс стоимости 1 из z, и эту функцию справа я буду называть индекс стоимости 0 из z.
И индекс просто относится к стоимости, соответствующей когда y равен 1, по сравнению с тем, когда y равен нулю.
Вооруженные этими определениями, теперь мы готовы построить опорную векторную машину.
Вот функция стоимости, j theta, что мы имеем для логистической регрессии.
В случае, если это уравнение выглядит немного незнакомым, это потому, что ранее у нас был знак минус снаружи, но вот что я сделал, я вместо этого переместил минус знаки внутри этих выражений, так что это просто делает его немного другим.
Для машины опорного вектора то, что мы собираемся сделать, это по существу взять это и заменить это на cost1 из z, то есть cost1 из theta транспонировать x.
И мы собираемся взять это и заменить его на cost0 z, , что стоит 0 из theta транспонировать x.
Где стоимость одной функции что у нас было на предыдущем слайде, который выглядит так.
И стоимость нулевой функции, опять же то, что у нас было на предыдущем слайде, и это выглядит так.
Итак, что у нас есть для машины опорного вектора задача минимизации одного над M, сумма Y I раз стоила один, тета транспонирование X I, плюс один минус Y I раз вызывают ноль тета-транспонирования X I, , а затем плюс мой обычный параметр регуляризации.
Как и так.
Теперь, по соглашению, для поддержки векторной машины мы на самом деле пишем вещи немного по-другому.
Мы перепараметризируем это совсем немного по-другому.
Во-первых, мы собираемся избавиться от терминов 1 над m, и это просто немного другое соглашение, которое люди используют для векторных машин поддержки по сравнению с или просто прогрессией.
Но вот что я имею в виду.
Вы один из способов сделать это, мы просто собираемся избавиться от этих более m условий , и это должно дать вам такое же оптимальное значение бета-версии права?
Потому что один над м такой же константой, поэтому , решил ли я эту проблему минимизации с помощью одного над n впереди или нет.
Я должен в конечном итоге иметь такое же оптимальное значение для тета.
Вот что я имею в виду, , чтобы привести вам пример, предположим, что у меня была проблема минимизации.
Минимизируйте длинное число U из U минус пять в квадрате плюс один.
Ну, минимальный из этого случается, что U равен пяти.
Теперь, если бы я взял эту объективную функцию и умножил ее на 10.
Итак, здесь моя проблема минимизации мин над U, 10 U минус пять в квадрате плюс 10.
Ну, значение U, которое сводит к минимуму это все еще U равно пяти правильно?
Так что умножить то, что вы минимизируете, на некоторую константу, 10 в этом случае, это не изменяет значение U, которое дает нам, , что минимизирует эту функцию.
Таким же образом, то, что я сделал, это вычеркивая M , это все, что я делаю, это умножение моей целевой функции на некоторую константу M и это не изменяет значение theta.
Это достигает минимума.
Второй бит нотационного изменения, который, опять же, является более стандартным соглашением при использовании SVM вместо логистической регрессии, является следующим.
Таким образом, для логистической регрессии мы добавляем два термина к объективной функции.
Первый — это термин, который является стоимостью, которая исходит из набора обучения и второй — это строка, которая является термином регуляризации.
И то, что у нас было, мы контролируем компромисс между ними, говоря, то, что мы хотим, это плюс, а затем мой параметр регуляризации лямбда.
А затем раз какой-то другой термин B, где я думаю, что я использую ваш A для обозначения этого первого термина, и я использую B для обозначения второго термина, возможно, без лямбды.
И вместо того, чтобы приоритизировать это как A плюс лямбда B, и так мы сделали, установив разные значения для этого параметра регуляризации лямбда, мы могли бы обменять относительный вес между тем, насколько мы хотели тренировочный набор хорошо, то есть минимизация A, по сравнению с тем, насколько мы заботимся о сохранении значений параметра маленькими, так что это будет, параметр B для машины вектора поддержки, просто по соглашению, мы будем использовать другой параметр.
Поэтому вместо использования лямбда здесь для управления относительным ожиданием между первым и вторым терминами.
Вместо этого мы будем использовать другой параметр, который по соглашению называется C и установлен для минимизации C раз a + B.
Так что для логистической регрессии, если мы установим очень большое значение лямбда, , что означает, что вы дадите B очень высокий вес.
Вот, что если мы устанавливаем C как очень небольшое значение, то, что реагирует на то, чтобы дать B гораздо большую скорость, чем C, чем A.
Так что это просто другой способ управления сделка, это просто другой способ приоритизации того, насколько мы заботимся об оптимизации первого термина, по сравнению с тем, как мы заботимся об оптимизации второго срока.
И если вы хотите, вы можете думать об этом как о параметре C , играя роль, похожую на 1 над лямбдой.
И дело не в том, что это два уравнения или эти два выражения будут равны.
Это равно 1 над лямбдой, это не так.
Скорее, если C равен 1 над лямбдой, то эти две цели оптимизации должны дать вам одно и то же оптимальное значение для тета, поэтому мы просто заполняем это в я собираюсь вычеркнуть лямбда здесь и писать в константе C там.
Таким образом, это дает нам нашу общую целевая функция оптимизации для машины вектора поддержки.
И если вы минимизируете эту функцию, , то у вас есть параметры, изученные SVM.
Наконец, в отличие от логистической регрессии, машина вектора поддержки не выводит вероятность того, что у нас есть эта функция затрат, которую мы минимизируем, чтобы получить данные параметра, и то, что делает векторная машина поддержки , это просто делает предсказание того, что y равен одному или ноль, напрямую.
Таким образом, гипотеза будет предсказывать один , если тета-транспонирование x больше или равно нулю, и она будет предсказывать ноль в противном случае и, узнав параметры тета, это форма гипотезы для опорного вектора машины.
Это было математическое определение того, что делает машина опорных векторов.
В следующих нескольких видео, давайте попробуем вернуться к интуиции о , к чему приводит эта цель оптимизации, и , узнает ли источник гипотез SVM, и мы также поговорим о том, как , чтобы изменить это просто немного к сложным нелинейным функциям.