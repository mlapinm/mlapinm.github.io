Anomaly Detection using the Multivariate Gaussian Distribution.В последнем видео мы говорили о многомерном гауссовом распределении
Play video starting at ::4 and follow transcript0:04
и увидели несколько примеров из видов распределений, которые вы можете моделировать, как вы меняете параметры, mu и sigma. В этом видео давайте возьмем эти идеи и применим их для разработки другого алгоритма обнаружения аномалий.
Play video starting at ::19 and follow transcript0:19
Для повтора многомерного гауссовского распределения и многомерного нормального распределения имеет два параметра, mu и sigma. Где mu это n размерный вектор и сигма,
Play video starting at ::32 and follow transcript0:32
ковариационная матрица, представляет собой матрицу n на n.
Play video starting at ::37 and follow transcript0:37
И вот формула для вероятности X, как параметризируется mu и сигма, и так как вы сами сами меняете mu и sigma, вы можете получить ряд различных распределений stots, например, знаете, это три примера из тех, которые мы видели в предыдущем видео.
Play video starting at ::51 and follow transcript0:51
Итак, давайте поговорим о подгонке параметра или задаче оценки параметра . Вопрос , как обычно, заключается в том, если у меня есть набор примеров X1 через XM, и здесь каждый из этих примеров является объемным вектором n, и я думаю, что мои примеры происходят из многомерного гауссовского распределения.
Play video starting at :1:9 and follow transcript1:09
Как я могу попытаться оценить мои параметры mu и sigma? Ну стандартные формулы для оценивая их, вы установите mu, чтобы быть просто среднее из ваших обучающих примеров.
Play video starting at :1:21 and follow transcript1:21
И вы устанавливаете сигму равную этому. И это на самом деле просто , как сигма, которую мы выписали , когда мы были , используя PCA или алгоритм анализа основных компонентов.
Play video starting at :1:31 and follow transcript1:31
Таким образом, вы просто подключите эти две формулы, и этот даст вам ваш оценочный параметр mu и ваш оценочный параметр sigma.
Play video starting at :1:41 and follow transcript1:41
Итак, учитывая набор данных здесь, как вы оцениваете mu и sigma. Возьмем этот метод и просто подключим его в алгоритм обнаружения аномалий. Итак, как же нам собрать все это вместе, чтобы разработать алгоритм обнаружения аномалий? Вот что мы делаем. Сначала мы берем наш тренировочный набор , и мы подходим к модели , мы подходим P X, вы знаете, установка му и сигма, как описано в описании
Play video starting at :2:3 and follow transcript2:03
на предыдущем слайде.
Play video starting at :2:7 and follow transcript2:07
Далее, когда вам дается новый пример X. Итак, , если вам дан тестовый пример,
Play video starting at :2:12 and follow transcript2:12
позволяет взять более ранний пример, чтобы иметь новый пример здесь. И это мой тестовый пример.
Play video starting at :2:18 and follow transcript2:18
Учитывая новый пример X, то, что мы собираемся сделать, это вычислить P из X, используя эту формулу для многомерного гауссовского распределения.
Play video starting at :2:27 and follow transcript2:27
И тогда, если P из X очень мал, то мы пометили это как аномалия, тогда как, если P из X больше , чем этот параметр epsilon, то мы не будем отмечать это как аномалия. Получается, если мы должны были соответствовать многомерному гауссовскому распределению к этому набору данных, так что только красные кресты, а не зеленый пример, вы получите гауссовое распределение , которое помещает много вероятности вероятности в центральной области, немного меньше вероятности здесь, немного меньше вероятности здесь, немного меньше вероятности здесь,
Play video starting at :2:56 and follow transcript2:56
и очень низкая вероятность в точке, которая выходит отсюда.
Play video starting at :3:1 and follow transcript3:01
Итак, если применить многомерное гауссовое распределение к этому примеру, он фактически будет правильно обозначать этот пример. как аномалия.
Play video starting at :3:16 and follow transcript3:16
Наконец, стоит сказать несколько слов о том, что такое взаимосвязь между многомерной гауссовой моделью распределения, и исходной моделью, где мы bote моделировали P stoth X как произведение этого продукта P из X1, P из X2, доводя до P из Xn.
Play video starting at :3:32 and follow transcript3:32
Оказывается, вы можете доказать математически, я не собираюсь делать доказательство здесь, но вы можете математически доказать, что это отношение , между многомерной гауссовой моделью и stots этот оригинальный. И в частности , оказывается , что исходная модель соответствует многомерным гауссам, где контуры Гауссова всегда выравниваются по оси.
Play video starting at :3:55 and follow transcript3:55
Итак, все три это примеры Гауссовых распределений, которые вы можете поместить с помощью оригинальной модели. Получается, что это соответствует многомерному гауссу, где, вы знаете, многоточие здесь, контуры этого распределения — это получается, что эта модель фактически bit соответствует особому случаю stots многомерного гауссовского распределения. И в частности, этот специальный случай определяется ограничивая
Play video starting at :4:24 and follow transcript4:24
распределение p x, многомерное распределение гауссова p из x, так, что контуры stots функции плотности вероятности, функция распределения вероятности, выравниваются по оси. И поэтому вы можете получить p из x с многомерным гауссовым, который выглядит как это, или как это, или вот так. И вы заметили, что во всех 3 из этих примеров, эти эллипсы, или эти овалы, которые я рисую, имеют свои оси, выровненные с осями X1 X2.
Play video starting at :4:54 and follow transcript4:54
А чего у нас нет, это набор контуров , которые находятся под углом, верно? И это соответствовало примерам, где сигма равна 1 1, 0,8, 0,8. Допустим, с элементами не-0 на от диагоналей. Получается, что можно математически показать, что эта модель на самом деле составляет такой же, как и многомерное распределение по Гауссу, но с ограничением. И ограничение заключается в том, что сигма матрицы ковариации должна иметь 0 на недиагональных элементах. В частности, ковариационная матрица сигма, эта штука здесь, она бы была сигма в квадрате 1, сигма в квадрате 2, вплоть до сигма в квадрате n, а затем возд все на офф диагональные записи, все эти элементы находятся выше и ниже диагонали матрицы, будут равны нулю.
Play video starting at :5:47 and follow transcript5:47
И на самом деле, если взять эти значения сигма, сигма в квадрате 1, сигма в квадрате 2, вниз до сигма в квадрате n, и подключить их сюда, и, знаете, подключить их к этой матрице coвариации stots, тогда hot-две модели фактически идентичны. То есть, эта новая модель,
Play video starting at :6:6 and follow transcript6:06
с использованием многомерного гауссовского распределения,
Play video starting at :6:8 and follow transcript6:08
соответствует точно старой модели , если ковариация матрица сигма, имеет только 0 элементов от диагоналей, ФОТО и в картинках, которые он соответствует иметь Гауссовых распределений,
Play video starting at :6:20 and follow transcript6:20
контуры этой функции распределения выравниваются по оси. Таким образом, вам не разрешено моделировать корреляции между различными функциями.
Play video starting at :6:30 and follow transcript6:30
В этом смысле исходная модель на самом деле является особым случаем этой многомерной гауссовой модели.
Play video starting at :6:38 and follow transcript6:38
Итак, когда вы будете использовать каждую из этих двух моделей? Итак, когда бы вы использовали исходную модель и когда бы вы использовали многомерную гауссовскую модель?
Play video starting at :6:52 and follow transcript6:52
Оригинальная модель, вероятно, используется несколько чаще,
Play video starting at :6:58 and follow transcript6:58
и в то время как многомерное распределение Gaussian используется несколько меньше, но имеет то преимущество, что он может захватить корреляции между функциями. Итак,
Play video starting at :7:10 and follow transcript7:10
предположим, что вы хотите захватить аномалии, где у вас есть разные функции, скажем, где особенности x1, x2 принимают на необычные комбинации значений, поэтому в предыдущем примере stots у нас был тот пример, где аномалия была с загрузкой процессора, а использование памяти принимает необычные комбинаций значений, если
Play video starting at :7:30 and follow transcript7:30
вы хотите использовать исходную модель для захвата этого, то вам нужно только создать дополнительную функцию , такую как X3 равно X1/X2, вы знаете, что, возможно, нагрузка процессора, разделенная на используемую память, или что-то еще, и вам нужно создать дополнительные функции , если есть необычные комбинации значений , где X1 и X2 берут на необычную комбинацию значений , хотя X1 по сам и X2 сам по себе выглядит так, как будто он принимает совершенно нормальное значение.
Play video starting at :7:59 and follow transcript7:59
Но если вы готовы потратить время, чтобы вручную создать дополнительную функцию, подобную этому, , то оригинальная модель будет работать отлично. В то время как, напротив, многомерная гауссовская модель может автоматически фиксировать корреляции между различными объектами. Но у оригинальной модели есть и другие более значительные преимущества, и одно огромное преимущество исходной модели
Play video starting at :8:28 and follow transcript8:28
заключается в том, что она вычислительно дешевле, а другой взгляд на этот заключается в том, что масштабируется лучше для очень большие значения n и очень большое количество функций bit, и так даже , если n были десять тысяч,
Play video starting at :8:39 and follow transcript8:39
или даже если n были равны сто тысячам, оригинальная модель обычно будет работать отлично. В то время как, в отличие от многомерной гауссовой модели, обратите внимание здесь, например , что нам нужно вычислить обратную матрицу сигма, где сигма — это an n на n матрицу
Play video starting at :8:56 and follow transcript8:56
и поэтому вычисление сигмы, если sts sigma — сто тысяч на st-тысячную матрицу, которая будет очень дорогостоящим для вычислений. И поэтому многомерная гауссовская модель масштабируется менее хорошо до больших значений N. И , наконец, для исходной модели , получается, что работать нормально, даже если у вас есть относительно небольшой обучающий набор, это небольшой немаркированный hetan примеры, которые мы используем для моделирования p из x
Play video starting at :9:20 and follow transcript9:20
, конечно, и это отлично работает, даже если M, вы
Play video starting at :9:24 and follow transcript9:24
знаете, может быть 50, 100, работает нормально. В то время как для многомерного гауссова, это является своего рода математическим свойством алгоритма, которое вы должны иметь m больше n, так что количество примеров больше, чем количество объектов, которые у вас есть. И есть математическое свойство того, как мы оцениваем параметры
Play video starting at :9:41 and follow transcript9:41
, что если это не так, так что если m меньше или равно n, , то эта матрица даже не обратима, то есть эта матрица является единственной, и поэтому вы не можете даже использовать многомерную гауссовую модель , если вы не внесите некоторые изменения к нему. Но
Play video starting at :9:54 and follow transcript9:54
типичное правило , которое я использую, я буду использовать многомерную гауссовскую модель только в том случае, если m намного больше n, так что это своего рода hum узкое математическое требование, но
Play video starting at :10:4 and follow transcript10:04
на практике я бы использовал многомерную гауссовскую модель, только если m были довольно немного больше, чем n. Так что если m были больше или равны 10 раз n, скажем , может быть разумным большим правилом, и если
Play video starting at :10:18 and follow transcript10:18
это не удовлетворяет этому, то многомерная гауссовская модель имеет много параметров, правильно, так что эта ковариационная матрица сигма представляет собой матрицу n на n, имеет, вы знаете, примерно n квадратные параметры, потому что это симметричная матрица, она на самом деле ближе к n квадрату по 2 параметрам, но это много параметров, поэтому вам нужно убедитесь, что у вас есть довольно большое значение для m, убедитесь, что у вас достаточно данных, чтобы соответствовать всем этим параметры. И m больше или равно 10 n будет разумным большим правилом, чтобы убедиться, что вы можете оценить эту ковариационную матрицу сигма разумно хорошо.
Play video starting at :10:55 and follow transcript10:55
Таким образом, на практике оригинальная модель показана слева, которая используется чаще. И если вы подозреваете, что вам нужно захватить корреляции между функциями то, что люди часто делают, это просто вручную создавать дополнительные функции, подобные этим, чтобы захватить определенные необычные комбинации значений. Но в проблемах, когда у вас есть очень большой тренировочный набор или m очень велик и n
Play video starting at :11:17 and follow transcript11:17
не слишком велик, то многомерная модель Гаусса стоит рассмотреть и может работать лучше, а также может ли
Play video starting at :11:24 and follow transcript11:24
избавить вас от необходимости в тратить свое время, чтобы вручную case
Play video starting at :11:31 and follow transcript11:31
аномалии оказываются зафиксированы необычными комбинациями значений объектов.
Play video starting at :11:37 and follow transcript11:37
Наконец, я просто хочу кратко упомянуть одно несколько техническое свойство , но если вы используете , подходящую многомерную модель Gaussian , и если вы обнаружите, что coвариационная матрица sigma stots является сингулярным, или вы обнаружите, что она не обратима, они обычно 2 случая для этого. Один из них - если он не может удовлетворить это условие m больше, чем n, а второй случай - если у вас есть избыточные функции. Таким образом, избыточными функциями, я имею в виду , если у вас есть 2 функции, которые одинаковы. Как-то вы случайно сделали две копии функции, так что ваш x1 просто равен x2. Или если у вас есть избыточные функции, такие как, возможно,
Play video starting at :12:12 and follow transcript12:12
, ваши функции X3 равны функции X4, плюс функция X5. Хорошо, так что если у вас есть очень избыточные функции, подобные этим, вы знаете, где, если X3 равен X4 плюс X5, то X3 не содержит никакой дополнительной информации, верно? Вы просто возьмите эти 2 другие функции и добавите их вместе.
Play video starting at :12:27 and follow transcript12:27
И если у вас есть такие избыточные функции, дублированные функции, или такого рода функции, то сигма может быть необратным.
Play video starting at :12:35 and follow transcript12:35
И так есть отладочный набор — это должно происходить очень редко, так что вы, вероятно, не столкнетесь с этим, очень маловероятно, что вам придется беспокоиться об этом — но в случае, если вы реализуете многомерную гауссовскую модель, вы обнаружите, что сигма необратима.
Play video starting at :12:48 and follow transcript12:48
То, что я бы сделал, это сначала убедитесь, что M довольно немного больше, чем N, и если это , то второе, что я делаю, это просто проверить избыточные функции. И поэтому, если есть 2 функции , которые равны, просто избавиться от одного из них, или если у вас есть избыточные, если эти , X3 равно X4 плюс X5, b просто избавиться от избыточной функции stoth, и тогда он должен работать нормально снова. В стороне для тех из вас , которые являются экспертами в линейной алгебре, избыточными функциями, то, что я имею в виду формальный термин - это особенности , которые линейно зависят. Но на практике то, что на самом деле означает , является одной из этих проблем, при которой алгоритм, если вы просто сделаете свои функции ненужными., , который должен решить проблему неинвертируемой сигмы. Но еще раз шансы на то, что вы попадаете в этот на всех довольно низки, так что шансы, вы можете просто применить многомерную модель Гауссова , без необходимости в беспокоиться о том, что сигма является необратным, both до тех пор, пока m больше, чем или равно n. распределение. И если вы примените этот метод , вы сможете иметь алгоритм обнаружения аномалий , который автоматически фиксирует положительные и отрицательные корреляции между вашими различными функциями bit и флаги аномалии stots, если он видит необычную комбинацию значений объектов