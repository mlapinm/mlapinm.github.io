Mini-Batch Gradient Descent.
В предыдущем видео мы говорили о стохастическом градиентном спуске, и о том, как это может быть намного быстрее, чем спуск градиента пакетной обработки.
В этом видео, давайте поговорим о другом варианте этих идей называется мини-пакетный градиентный спуск , они могут работать иногда даже немного быстрее, чем стохастический градиентный спуск.
Подводя итоги алгоритмов, о которых мы говорили до сих пор.
В пакетном градиентном спуске мы будем использовать все m примеров в каждом поколении.
В то время как в Стохастическом градиентном спуске мы будем использовать один пример в каждом поколении.
То, что делает мини-пакетный градиентный спуск, находится где-то между ними.
В частности, с помощью этого алгоритма мы будем использовать b примеры в каждой итерации, где b является параметром, называемым «мини размер пакета» , поэтому идея заключается в том, что это несколько между пакетным градиентным спуском и стохастическим градиентным спуском.
Это точно так же, как спуск градиента партии, за исключением того, что я собираюсь использовать гораздо меньший размер партии.
Типичный выбор для значения b может быть b равно 10, скажем, и типичный диапазон действительно может быть от b равно 2 до b равно 100.
Таким образом, это будет довольно типичный диапазон значений для размера мини-пакета.
И идея заключается в том, что вместо того, чтобы использовать один пример за раз или m примеров за раз, мы будем использовать b примеры за раз.
Так что позвольте мне просто написать это неофициально, мы собираемся получить, скажем, b.
Для этого примера, скажем, b равно 10.
Итак, мы собираемся получить, следующие 10 примеров из моего набора обучения, так что может быть несколько примеров xi, yi.
Если это 10 примеров, то индексация будет до x (i+9), y (i+9) , так что это 10 примеров, а затем мы выполним по существу обновление градиентного спуска, используя эти 10 примеров.
Итак, это любая ставка умножить на одну десятую сумму больше k равно i через i+9 подстрочного индекса theta x (k) минус y (k) умножить x (k) j.
И так в этом выражении, где суммировать градиентные термины над моими десятью примерами.
Итак, это номер десять, то есть, вы знаете, мой мини-размер партии и просто i+9 снова, o 9 происходит от выбора параметра b, а затем после этого мы увеличим, ну знаете, i на десятую, мы перейдем к следующим десяти примерам, а затем продолжим движение вот так.
Так что просто выписать весь алгоритм в полном объеме.
Чтобы упростить индексацию для этого в правом верхнем углу, я собираюсь предположить, что у нас есть мини-пакет размером десять и тренировочный набор размером тысячи, то, что мы собираемся сделать, это иметь такую форму, для i равен 1 и что в 21 году степпинг, в шаге 10, потому что мы смотрим на 10 примеры за раз.
И затем мы выполняем такое обновление градиентного спуска, используя десять примеров за раз , так что этот 10 и этот i+9 являются следствием того, что мой мини-пакет был десять.
И вы знаете, этот окончательный четырехцикл, это заканчивается на 991 здесь, потому что если у меня 1000 обучающих образцов, то мне нужно 100 шагов 10 размера, чтобы пройти свой тренировочный набор.
Итак, это мини-пакетный градиентный спуск.
По сравнению с градиентным спусканием партии, это также позволяет нам добиться прогресса намного быстрее.
Итак, у нас снова есть наш пример, вы знаете, данных переписи США с 300 миллионами обучающих примеров, то мы говорим, что после просмотра первых 10 примеров мы можем начать прогресс в улучшении параметров тета, так что нам не нужно сканировать весь набор тренировок.
Нам просто нужно взглянуть на первые 10 примеров, и это позволит нам добиться прогресса, а затем мы можем посмотреть на вторые десять примеров и немного изменить параметры и так далее.
Итак, поэтому мини-пакетный градиентный спуск может быть быстрее, чем пакетный градиентный спуск.
А именно, вы можете начать прогресс в изменении параметров после просмотра всего десяти примеров вместо того, чтобы ждать, пока вы сканируете каждый пример обучения из 300 миллионов из них.
Итак, как насчет мини-пакетного градиентного спуска по отношению к стохастическому градиентному спуску.
Итак, почему мы хотим рассматривать примеры b за раз, а не рассматривать только один пример за раз, как стохастический градиентный спуск?
Ответ в векторизации.
В частности, мини-пакетный градиентный спуск, скорее всего, превзойти стохастический градиентный спуск только в том случае, если у вас хорошая векторизованная реализация.
В этом случае сумма более 10 примеров может быть выполнена более векторизованным образом , что позволит вам частично распараллеливать ваши вычисления по десяти примерам.
Другими словами, используя соответствующую векторизацию для вычисления остальных терминов, вы можете иногда частично использовать хорошие библиотеки числовой алгебры и распараллеливать ваши вычисления градиента над примерами b, , тогда как если бы вы смотрели только один пример времени со стохастическим градиентным спуском, то, знаете, просто глядя на один пример за раз, их не много, чтобы распараллеливаться.
По крайней мере, здесь меньше распараллеливаться.
Одним из недостатка градиентного спуска Mini-Batch является то, что теперь есть дополнительный параметр b, размер Mini-Batch, с которым вам может потребоваться скрипка, и что, следовательно, может занять время.
Но если у вас есть хорошая векторизованная реализация, это иногда может работать еще быстрее, чем стохастический градиентный спуск.
Это был мини-пакетный градиентный спуск, который является алгоритмом, который в некотором смысле делает что-то , что несколько находится между тем, что делает стохастический градиентный спуск и что делает градиентный спуск Пакетной партии.
И если вы выберете их разумное значение b.
Я обычно использую b равно 10, но, вы знаете, другие значения, от 2 до 100, были бы разумно общими.
Таким образом, мы выбираем значение b, и если вы используете хорошую векторизованную реализацию, иногда это может быть быстрее, чем стохастический градиентный спуск и быстрее, чем пакетный градиентный спуск.