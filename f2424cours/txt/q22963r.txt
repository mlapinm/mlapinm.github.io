Getting Lots of Data and Artificial Data.
Я видел снова и снова, что один из самых надежных способов получить высокопроизводительную систему машинного обучения - взять алгоритм обучения с низким уклоном и обучить его массивным обучающим набором.
Но откуда вы получили столько данных о тренировках?
Оказывается, что заработок машины есть увлекательная идея под названием искусственный синтез данных , это не относится к каждой отдельной проблеме, а применить к конкретной проблеме bdb, часто требует некоторых размышлений и инноваций и проницательности.
Но если эта идея применяется к вашей машине, только проблема, она иногда может быть простым способом получить огромный набор обучения, чтобы дать вашему алгоритму обучения.
Идея искусственного синтеза данных состоит из двух вариаций, главная из которых — если мы по существу создаем данные из [xx], создаем новые данные с нуля.
И второй, если у нас уже есть небольшой тренировочный набор, и мы каким-то образом усилили, что обучение набор или использовать небольшой тренировочный набор, чтобы превратить его в фолти более крупный учебный набор, и в hote это видео мы будем проходить через обе эти идеи.
Чтобы поговорить об искусственной идее синтеза данных , давайте используем часть персонажа фотоконвейера OCR, мы же хотим взять его входное изображение и распознать, какой это характер.
Если мы выйдем и соберем большой набор данных этикеток, вот что это такое и как это выглядит.
Для этого конкретного примера я выбрал квадратное соотношение сторон.
Итак, мы берем квадратные изображения.
И цель состоит в том, чтобы взять патч изображения и распознать символ в середине этого патча изображения.
И ради простоты я собираюсь рассматривать эти изображения как изображения серого масштаба, а не цветные изображения.
Оказывается, что использование цвета , похоже, не помогает в этой конкретной проблеме.
Учитывая этот патч изображения, мы бы хотели признать, что это T.
Учитывая этот патч изображения, мы хотели бы признать, что это '''.
Учитывая этот патч изображения, мы хотели бы признать это как «я» и так далее.
Итак, все это, наши примеры изображений строк, как мы можем придумать гораздо больший набор тренировок?
Современные компьютеры часто имеют огромную библиотеку шрифтов и , если вы используете программное обеспечение для обработки текстов , в зависимости от того, что слово процессор вы используете, вы можете bots иметь все эти шрифты и sts много, многое другое Уже хранится внутри.
И, на самом деле, если вы идете разные сайты, есть , опять же, огромные, бесплатные шрифты библиотеки в Интернете мы можем скачать много, много разных типов шрифтов, сотни или, возможно, тысячи различных шрифтов.
Поэтому, если вы хотите больше обучающих примеров , одна вещь, которую вы можете сделать, это просто взять символы из разных шрифтов и вставить эти символы против b2 разных случайных фонов.
Таким образом, вы можете взять это - и вставить это c на случайный фон.
Если вы делаете, что у вас теперь есть пример обучения изображение персонажа C.
Таким образом, после некоторого количества работы, вы знаете это, и это немного hots работы для synthize реалистичные выглядящие данные.
Но после некоторого объема работы вы можете получить такой синтетический тренировочный набор.
Каждое изображение, показанное справа, на самом деле было синтезированным изображением.
Где вы берете шрифт, может быть случайный шрифт, скачанный из в Интернете, и вы вставляете изображение одного символа или нескольких символов из этого шрифт против этого другого случайного фонового изображения.
И затем примените, возможно, немного размытия операторов - из приложения finder, искажения, которые app finder, означающие только совместное использование и масштабирование и небольшие операции bot-вращения, и если вы не сделаете, что вы получаете синтетический обучающий набор, на то, что показано здесь.
И это работа, класс, это, это требует мысли на работе, чтобы сделать синтетические данные выглядят реалистичными, и если вы выполняете неаккуратную работу по описанию того, как stoth вы создаете синтетические данные, то это на самом деле не будет хорошо работать.
Но если вы посмотрите на , синтетические данные выглядят удивительно похожи на реальные данные.
И поэтому, используя синтетические данные , у вас есть по существу неограниченный запас обучающих примеров для искусственного синтеза обучения И , так что, если вы используете этот источник bot-синтетических данных, у вас есть алгоритм для задачи распознавания символов.
Итак, это пример искусственный синтез данных, где youre в основном создание новых данных с нуля, вы просто генерируете совершенно новые изображения с нуля.
Другой основной подход к искусственному синтезу данных заключается в том, что вы взять примеры, которые у вас в настоящее время, что мы берем реальный пример, может быть, из both реального изображения, и вы создаете лишние данные, с тем чтобы увеличить ваш тренировочный набор.
Итак, вот изображение по сравнению с a из реального изображения, не синтезированное изображение, и я накладывал это с помощью линий сетки только для целей иллюстрации.
На самом деле есть эти —.
Итак, что вы можете сделать, это взять этот алфавит здесь, взять это изображение и ввести искусственные деформации [sp?
] или искусственные искажения в изображении , чтобы они могли взять изображение a и превратить , что в 16 новых примеров.
Таким образом, вы можете взять небольшой тренировочный набор и усилить свой тренировочный набор , чтобы внезапно получить много больше примеров, все это.
Опять же, для того, чтобы сделать это для приложения, он делает думать, и он делает принять понимание, чтобы выяснить , какие наши разумные наборы искажений, или ли эти stots являются способами, которые усиливают и умножают свой обучающий набор, и для определения конкретного примера распознавание символов, введение этих деформаций кажется естественным выбором , но для отличного машинного приложения могут быть разными искажениями, которые могут иметь больший смысл.
Позвольте мне показать один пример из совершенно другой области распознавания речи.
Итак, распознавание речи, скажем у вас есть аудиоклипы, и вы хотите узнать из аудио клип, чтобы распознать, что были слова, произнесенные в этом клипе.
Итак, давайте посмотрим, как один помеченный пример обучения.
Итак, предположим, что у вас есть один пример обучения , кто-то говорит несколько конкретных слов.
Итак, давайте воспроизводим этот аудиоклип здесь.
0 -1-2-3-4-5.
Хорошо, так что кто-то считая от 0 до 5, и поэтому вы хотите, чтобы попытался применить алгоритм обучения , чтобы попытаться распознать слова, сказанные в этом.
Итак, как мы можем усилить набор данных?
Ну, одна вещь, которую мы делаем, это вводят дополнительные звуковые искажения в набор данных.
Итак, здесь я собираюсь добавить фоновые звуки, чтобы имитировать плохое соединение с сотовым телефоном.
Когда вы слышите звуковые звуки, это на самом деле часть аудио трека, это ничего плохого в динамиках, я собираюсь играть это сейчас.
0-1-2-3-4-5.
Правильно, так что вы можете слушать такого рода аудио клип и распознавать звуки, , который кажется еще одним полезным примером обучения иметь, вот еще один пример, шумный фон.
Ноль, один, два, три четыре пять вы знаете автомобилей, проезжающих мимо, люди, идущие в фоновом режиме, вот еще один один, так что принимая оригинальный номер чистый аудио клип, так что он принимает чистый звук от компании кто-то говорит 0 1 2 3, 4 5 мы можем затем автоматически синтезировать эти дополнительные примеры обучения и, таким образом, усиливают один обучающий пример в четыре разных обучающих примера.
Итак, позвольте мне сыграть и этот последний пример 0-1 3-4-5 Таким образом, принимая только один помеченный пример, мы должны пройти через усилия , чтобы собрать только один помеченный пример падение 01205, и по bot-синтезируя дополнительные искажения, stoth путем введения различных фоновых звуков, placeet мы теперь умножили этот во многих других примерах.
Много работы просто автоматически добавляя эти различные фоновые звуки к чистому аудио Просто одно слово предупреждения об синтезе данных путем введения искажений: если вы пытаетесь сделать это stots самостоятельно, искажения, которые вы cote вводите должны быть репрезентативными источник шумов или искажений, которые вы можете увидеть в тестовом наборе.
Итак, для примера распознавания символов, вы знаете, рабочие вещи начинаются на самом деле, своего рода разумный, потому что изображение A, которое выглядит так, то есть, abt- это изображение, которое мы могли бы увидеть в тестовом сете.
Отражать факт И, вы знаете, в правом верхнем углу, что может быть изображением, которое мы могли бы представить увидеть.
И для аудио, ну, мы делаем хотим распознать речь, даже против плохого внутреннего соединения, против различных типов фонового шума, и так что для аудио, мы снова Образ Обобщение примеров на самом деле представитель рода примеров, которые мы хотим, чтобы классифицировать, что мы хотим правильно распознать.
В отличие от этого, обычно это не помогает, возможно, вы на самом деле значение как шум для ваших данных.
Я не уверен, что вы можете видеть это, но то, что мы сделали здесь, взято изображение, и для каждого пикселя, в каждом из них из этих 4 изображений, просто добавил случайный гауссовский шум к каждому пикселю.
Для каждого пикселя, это пиксельная яркость, он бы просто добавить некоторые, знаете, может быть, Гауссовский случайный шум к каждому пикселю.
Так это просто бессмысленный шум, верно?
И так, если вы не ожидаете, что увидят такие виды пиксельных мудрых шумов в вашем тестовом наборе , такой тип noM, чисто случайный бессмысленный шум, скорее всего, будет полезен.
Но процесс искусственного синтеза данных это вы знаете немного искусство, а иногда и вам просто нужно попробовать его и посмотреть, работает ли он.
Но если вы пытаетесь решить, какие искажения добавить, знаете ли, думать о том, какие другие значимые искажения вы могли бы добавить, что bott заставит вас генерировать дополнительные обучающие примеры, которые, по крайней мере, несколько репрезентативные от изображения, которые вы ожидаете увидеть в ваших тестовых наборах.
Наконец, чтобы завершить это видео , я просто хочу сказать пару слов, больше о этой идее получения потери данных через искусственный синтез данных.
Как всегда, прежде чем тратить много усилий, вы знаете, выясняя как создать искусственные примеры обучения , это часто хорошая практика заключается в том, чтобы убедиться, что у вас действительно есть низкий предвзятый стоп перекрестный огонь, и имея cromote гораздо больше учебных данных будет полезно.
И стандартный способ сделать это построить обучающие кривые, и убедиться, что у вас есть только низкий , а также высокий дисперсионный фальсификатор.
Или если у вас нет фальсификатора уклона , вы знаете, еще одна вещь, которая стоит попробовать , это продолжать увеличивать количество функций, которые имеет ваш классификатор, увеличивая количество скрытых единиц stots в вашей сети, говоря, до тех пор, пока у вас на самом деле не будет довольно низкого смещения фальсификатор, и только тогда, если вы положите усилия на создание большой, искусственный учебный набор, так что то, что вы действительно хотите избежать , это потратить на неделю или потратить несколько лишних месяцев, чтобы выяснить, как stoose получить отличный искусственно созданный синтезированный набор данных.
Только для того, чтобы понять, что, вы знаете, ваш алгоритм обучения, производительность не улучшится так сильно, даже когда вам дается огромный набор тренировок.
Вот о моем обычном совете о тестировании, которое вы действительно можете использовать большого набора тренировок, прежде чем потратить много усилий, чтобы получить этот большой набор тренировок.
Во-вторых, когда я работаю над проблемами машинного обучения, один вопрос Я часто задаю команде , с которыми я работаю, часто спрашиваю моих учеников, а именно, сколько работы bit было бы, чтобы получить в 10 раз больше даты, чем мы в настоящее время.
Когда я сталкиваюсь с новым приложением машинного обучения очень часто, я сяду с командой и задам именно этот вопрос, Я задавал этот вопрос снова и снова и снова, и я был очень удивлен, как часто они этот ответ был, что.
Вы знаете, это действительно не так сложно, может быть несколько дней работы максимум, чтобы получить в десять раз больше данных, как мы в настоящее время для машины, работающей приложения и очень часто, если вы можете получить cote в десять раз больше данных там, лучше.
Итак, вы знаете, если вы когда-либо присоединяетесь к команде продукта работая над некоторым продуктом машинного обучения приложения это очень хорошие вопросы задайте себе спросить команду не быть ты слишком удивлен, если после нескольких минут мозгового штурма, если ваша команда разработчиков придумывает чтобы получить буквально в десять раз больше данных, в в этом случае, я думаю, что вы бы быть героем этой команды, потому что с 10 раз больше, чем в больше данных, я думаю, что вы действительно получите гораздо лучшую производительность, просто из изучения столько данных.
Итак, есть несколько способов и , которые включали в себя как идеи генерации данных с нуля с использованием случайных шрифтов и так далее.
А также вторая идея взять существующий пример и и введение искажений, которые усиливают , чтобы увеличить обучающий набор А пару других примеров способов, чтобы получить гораздо больше данные собирают данные или сами их помечают.
Так что один полезный расчет, который я часто делаю, это, знаете, сколько минут, сколько часов занимает, чтобы получить определенное количество примеров, так что на самом деле садитесь и stots выяснить, вы знаете, предположим, что это займет у меня десять секунд, чтобы создать лейбл один пример, а затем hd и, предположим, что для нашего приложения, в настоящее время у нас есть 1000 помеченных примеров , так что в десять раз больше, чем , что было бы , если бы n были равны десяти тысячам.
Второй способ получить много данных - это , чтобы просто собрать данные, и вы сами их наклеиваете.
Итак, что я имею в виду под этим Я часто устанавливаю и делать расчет, чтобы понять, сколько времени, вы знаете точно так же, как сколько часов, это займет, сколько часов stots или сколько дней будет использовать это для меня или для кого-то другого, чтобы просто сесть и собрать десять раз столько данных, сколько у нас есть в настоящее время, собирая данные сами и маркируя их сами.
Например, для нашего приложения машинного обучения в настоящее время у нас есть 1000 примеров, поэтому M 1000.
То, что мы делаем, это сесть и спросить, как долго мне действительно нужно, чтобы собрать и пометить один пример.
И иногда, может быть, это возьмет вас, вы знаете десять секунд, чтобы отметить один новый пример, и поэтому , если я хочу 10 X как много примеров, я бы сделал расчет.
Если мне потребуется 10 секунд, чтобы получить один пример обучения.
Если бы я хотел получить в 10 больше данных, то мне нужно 10 000 примеров.
Итак, я делаю расчет, сколько времени потребуется для этикетирования, для ручной маркировки 10 000 примеров, , если мне потребуется 10 секунд, чтобы отметить 1 пример.
Так что, когда вы делаете этот расчет, часто я видел много вас будет удивлен, вы знаете, как мало, или иногда несколько дней на работе, иногда bit небольшое количество дней работы, stoth хорошо я видел много команд быть очень удивлен, что иногда, как мы мало работы это может быть, , чтобы просто получить гораздо больше данных, и пусть это будет способ дать ваше обучение приложение, чтобы дать вам огромный импульс в производительности, и обязательно, вы должны знать, иногда, когда вы просто hots удалось сделать это, вы будете герой и любой продукт разработки, независимо от , над которым вы работаете , потому что это может быть отличным способом получить гораздо лучшую производительность.
В-третьих и, наконец, иногда хороший способ получить много данных - использовать , что теперь называется толпой сорсинг.
Итак, сегодня есть несколько веб-сайтов или несколько сервисов, которые позволяют вам нанять людей на в Интернете, вы знаете, довольно bit дешево этикетки больших учебных наборов для вас.
Таким образом, эта идея поиска толпы , или толпы источника маркировки данных, это нечто, что имеет, очевидно, как и целую академическую литературу, у вас есть некоторые из своих собственных осложнений и stots так далее, относящиеся к надежности этикетировщика.
Может быть, вы знаете, сотни тысяч этикетировщиков, по всему миру , работая довольно недорого, чтобы помочь этикетки данных для вас, и о том, что я только что упомянул, есть еще одна альтернатива.
И, вероятно, системы Amazon Mechanical Turk являются, вероятно, самым популярным вариантом подбора толпы прямо сейчас.
Это часто довольно бит работы, чтобы добраться до работы, если вы хотите, чтобы , чтобы получить очень высокое качество этикетки, , но иногда это вариант, стоит рассмотреть также.
Если вы хотите попробовать нанять много людей, довольно недорого в Интернете, наши лейблы запускают мили данных для вас.
Итак, это видео, мы говорили об идее искусственный синтез данных либо создание новых данных с нуля, глядя, используя botm фондов в качестве примера, stoth или путем усиления опыта существующего обучающего набора, путем создания существующих примеров этикеток и искажений к нему, для создания дополнительных примеров этикеток.
И, наконец, одна вещь, которую я надеюсь, вы помните из этого видео эту идею, если вы сталкиваетесь с проблемой машинного обучения , часто стоит сделать две вещи.
Одна только проверка здравомыслия, с кривыми обучения, что иметь больше данных поможет.
И во-вторых, предполагая, что это так, Я часто сяду вниз и спросить себя серьезно: что бы он взял, чтобы получить в десять раз больше, чем больше творческих данных, как вы в настоящее время есть, и не всегда, stoth но иногда, вы можете быть удивлены, как легко, что оказывается, может быть, несколько дней, несколько недель на работе, и это может быть отличный способ дать вашему алгоритму обучения огромный импульс в производительности