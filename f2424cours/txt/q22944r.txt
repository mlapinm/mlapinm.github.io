Stochastic Gradient Descent Convergence.
Теперь вы знаете о алгоритме спуска стохастического градиента.
Но когда вы запускаете алгоритм, как вы убедитесь, что он полностью отлажен и сходится хорошо?
Не менее важно, как настроить скорость обучения альфа с помощью Stochastic Gradient Descent.
В этом видео мы поговорим о некоторых методах для выполнения этих вещей, для того, чтобы убедиться, что он сходится и для выбора уровня обучения альфа.
Когда мы использовали пакетный градиентный спуск, наш стандартный способ убедиться, что сходятся градиентный спуск , мы будем строить функцию оптимизации затрат как функцию количества итераций.
Так что это была функция стоимости, и мы бы убедились, что эта функция затрат уменьшается на каждой итерации.
Когда размеры тренировочных наборов были маленькими, мы могли бы это сделать, потому что мы могли бы вычислить сумму довольно эффективно.
Но когда у вас есть большой размер набора тренировок, вы не хотите периодически приостанавливать свой алгоритм.
Вы не хотите периодически приостанавливать стохастический градиентный спуск, чтобы вычислить эту функцию стоимости , так как для этого требуется сумма всего размера вашего тренировочного набора.
И весь смысл стохастического градиента заключался в том, что вы хотели начать прогресс , просмотрев только один пример без необходимости периодически сканировать весь учебный набор прямо в середине алгоритма, просто чтобы вычислить такие вещи, как функция стоимости всего тренировочный набор.
Итак, для стохастического градиентного спуска, чтобы проверить, что алгоритм сходится, вот что мы можем сделать вместо этого.
Давайте возьмем определение стоимости, которую мы имели ранее.
Таким образом, стоимость параметров тета по отношению к одному примеру обучения составляет всего половину квадратной ошибки на этом примере обучения.
Затем, пока учится стохастический градиентный спуск, прямо перед тем, как мы тренируемся на конкретном примере.
Итак, в стохастическом градиентном спуске мы собираемся посмотреть на примеры xi, yi, в порядке, и затем немного обновить в отношении этого примера.
И мы переходим к следующему примеру, xi плюс 1, yi плюс 1, и так далее, верно?
Вот что делает стохастический градиентный спуск.
Итак, пока алгоритм смотрит на пример xi, yi, но прежде чем он обновил параметры theta , используя этот пример, давайте вычислим стоимость этого примера.
Просто сказать то же самое еще раз, но используя несколько разные слова.
Стохастический градиентный спуск сканирует через наш тренировочный набор прямо перед тем, как мы обновили theta, используя конкретный пример обучения x (i) запятую y (i) давайте вычислить, насколько хорошо наша гипотеза работает на этом примере обучения.
И мы хотим сделать это перед обновлением theta, потому что, если мы только что обновили theta, используя пример , вы знаете, что это может быть лучше на этом примере, чем то, что было бы репрезентативным.
Наконец, чтобы проверить сходимость стохастического градиентного спуска, то, что мы можем сделать, это каждую тысячу итераций, мы можем построить эти затраты, которые мы вычислили на предыдущем шаге.
Мы можем построить эти затраты в среднем по сравнению, скажем, с последней тысячей примеров, обработанных алгоритмом.
И если вы это сделаете, это дает вам текущую оценку того, насколько хорошо работает алгоритм.
на, вы знаете, последние 1000 обучающих примеров, которые видел ваш алгоритм.
Итак, в отличие от вычислений J<u>поезд периодически, который нужно было сканировать весь тренировочный набор.
</u> С этой другой процедурой, ну, как часть стохастического градиентного спуска, не стоит много вычислять эти затраты, а прямо перед обновлением параметра theta.
И все, что мы делаем, это каждую тысячу интеграций или около того, мы просто усредняем последнюю тысячу затрат, которые мы вычислили и построили это.
И глядя на эти графики, это позволит нам проверить, сходится ли стохастический градиентный спуск.
Итак, вот несколько примеров того, как могут выглядеть эти сюжеты.
Предположим, что вы построили среднюю стоимость за последние тысячи примеров, , потому что они усреднены всего за тысячу примеров, они будут немного шумными, и поэтому он не может уменьшаться на каждой итерации.
Затем, если вы получите фигуру, которая выглядит так, так что сюжет шумный , потому что это среднее, вы знаете, просто небольшое подмножество, скажем, тысяча обучающих примеров.
Если вы получите фигуру, которая выглядит так, вы знаете, что это будет довольно приличный пробег с алгоритмом, может быть, где, похоже, стоимость упала, а затем это плато, которое выглядит как будто сплющено, ну знаешь, начиная с этой точки.
выглядит так, это то, как выглядит ваша стоимость, тогда, возможно, ваш алгоритм обучения сходился.
Если вы хотите попробовать использовать меньшую скорость обучения, то вы можете увидеть, что алгоритм может изначально учиться медленнее, так что стоимость снижается медленнее.
Но тогда, в конце концов, у вас есть меньшая скорость обучения, на самом деле возможно, для алгоритма в конечном итоге на, возможно, очень немного лучшее решение.
Таким образом, красная линия может представлять поведение стохастического градиентного спуска с использованием более медленного, используя меньшую скорость наклонения.
И причина в том, что, вы помните, стохастический градиентный спуск не просто сходится к глобальному минимуму, заключается в том, что параметры будут немного колебаться вокруг глобального минимума.
Таким образом, используя меньшую скорость обучения, вы будете в конечном итоге с меньшими колебаниями.
И иногда эта небольшая разница будет незначительной и иногда с меньшим, чем вы можете получить немного лучшее значение для параметров.
Вот некоторые другие вещи, которые могут произойти.
Допустим, вы запускаете стохастический градиентный спуск, и вы в среднем более тысячи примеров при построении этих затрат.
Итак, вы знаете, здесь может быть результат еще одного из этих сюжетов.
Опять же, похоже, что он сходится.
Если взять это число, тысячу, и увеличить в среднем более 5 тысяч примеров.
Тогда возможно, что вы можете получить более гладкую кривую, которая выглядит более похожей на эту.
И, усреднив более, скажем, 5000 примеров вместо 1000, вы можете получить более гладкую кривую, подобную этому.
И это эффект увеличения количества примеров, которые вы усреднёте.
Недостатком сделать это слишком большим, конечно, является то, что теперь вы получаете один момент даты только каждые 5 000 примеров.
И поэтому отзывы, которые вы получаете о том, насколько хорошо работает ваш алгоритм обучения, может быть, это более отложено , потому что вы получаете одну точку данных на вашем графике только каждые 5000 примеров, а не каждые 1000 примеров.
Вдоль аналогичной вены несколько раз вы можете запустить градиентный спуск и в конечном итоге с сюжетом, который выглядит так.
И с сюжетом, который выглядит так, вы знаете, похоже, что стоимость просто не уменьшается вообще.
Похоже, алгоритм просто не учится.
Это просто, выглядит так вот плоская кривая и стоимость просто не уменьшается.
Но опять же, если вы должны были увеличить это до усреднения по большему количеству примеров , возможно, что вы видите что-то вроде этой красной линии , похоже, что стоимость на самом деле уменьшается, это просто синяя линия, усредненная по 2, 3 примерам, синяя линия была слишком шумной, так что вы моглине видит фактической тенденции в фактическом снижении стоимости и, возможно, усреднение более 5 000 примеров вместо 1000 может помочь.
Конечно, мы усреднили больше примеров, которые мы усреднили здесь более 5000 примеров, Я просто использую другой цвет, также возможно, что вы видите кривую обучения выглядит так.
То, что он все еще плоский, даже если вы в среднем больше примеров.
И как вы это получаете, тогда это, возможно, просто более твердая проверка того, что , к сожалению, алгоритм просто не учится многому по какой-либо причине.
И вам нужно либо изменить скорость обучения, либо изменить функции, либо изменить что-то еще о алгоритме.
Наконец, последнее, что вы могли бы увидеть, если бы вы построили эти кривые , и вы увидите кривую, которая выглядит так, где она на самом деле выглядит так, как будто она увеличивается.
И если это так, то это признак того, что алгоритм расходится.
И то, что вы действительно должны сделать, это использовать меньшее значение уровня обучения альфа.
Итак, надеюсь, это дает вам представление о диапазоне явлений, которые вы можете увидеть , когда вы рисуете эти средние затраты по некоторым примерам, а также предлагает виды вещей, которые вы могли бы попытаться сделать в ответ на просмотр разных сюжетов.
Поэтому, если графики выглядят слишком шумными, или если они слишком сильно шевелится вверх и вниз, попробуйте увеличить количество примеров , которые вы усредняете, чтобы вы могли лучше видеть общую тенденцию на графике.
И если вы видите, что ошибки на самом деле растут, затраты на самом деле растут, попробуйте использовать меньшее значение альфа.
Наконец, стоит рассмотреть вопрос о темпе обучения чуть больше.
Мы видели, что когда мы запускаем стохастический градиентный спуск, алгоритм начнется здесь и вроде бы меандр к минимальному И тогда он не сходится, а вместо этого будет бродить по минимальному навсегда.
И поэтому вы получаете значение параметра, которое, надеюсь, близко к глобальному минимуму, который не будет точным на глобальном минимуме.
В большинстве типичных реализаций стохастического градиентного спуска скорость обучения альфа обычно удерживается постоянной.
И то, что вы в конечном итоге, это точно такая картина.
Если вы хотите, чтобы стохастический градиентный спуск фактически сходился к глобальному минимуму, есть одна вещь, которую вы можете сделать: вы можете медленно уменьшать скорость обучения альфа с течением времени.
Итак, довольно типичным способом сделать это было бы установить альфа равную некоторой константе 1, разделенной на число итераций плюс константу 2.
Итак, число итераций - это количество итераций, которые вы запустили стохастический градиентный спуск, так что это действительно количество обучающих примеров, которые вы видели И const 1 и const 2 являются дополнительными параметрами алгоритма , с которыми вам, возможно, придется играть немного, чтобы получить хорошую производительность.
Одна из причин, по которой люди, как правило, не делают этого, заключается в том, что вам нужно тратить время , играя с этими 2 дополнительными параметрами, постоянной 1 и постоянной 2, и поэтому это делает алгоритм более тонким.
Знаете, это просто больше параметров, которые можно использовать для того, чтобы алгоритм работал хорошо.
Но если вам удастся настроить параметры хорошо, то картина, которую вы можете получить, заключается в том, что алгоритм будет фактически приближаться к минимуму, но по мере приближения , потому что вы уменьшаете скорость обучения, значения будут становиться все меньше и меньше , пока это в значительной степени просто глобальный минимум.
Надеюсь, это имеет смысл, верно?
И причина, по которой эта формула имеет смысл, заключается в том, что по мере запуска алгоритма число итераций становится большим.
Таким образом, альфа будет медленно становиться маленьким, , и поэтому вы предпринимаете меньшие и меньшие шаги, пока он, надеюсь, не сходится к глобальному минимуму.
Таким образом, если вы медленно уменьшите альфа до нуля, вы можете в конечном итоге с немного лучшей гипотезой.
Но из-за дополнительной работы, необходимой для скрипки с константами, и потому, что, честно говоря, обычно мы довольны любым значением параметра, которое, знаете, довольно близко к глобальному минимуму.
Обычно этот процесс снижения альфа медленно обычно не выполняется и сохранение постоянной альфа скорости обучения является более распространенным применением стохастического градиентного спуска, хотя вы увидите, что люди используют любую версию.
Подводя итог в этом видео, мы говорим о способе приблизительно мониторинга , как делает стохастический градиентный спуск с точки зрения оптимизации функции затрат.
И это метод, который не требует сканирования всего набора тренировок периодически для вычисления функции затрат на весь учебный набор.
Но вместо этого он смотрит на говорят только последние тысячи примеров или около того.
И вы можете использовать этот метод как для того, чтобы убедиться, что стохастический градиентный спуск в порядке и сходится или использовать его для настройки скорости обучения альфа.