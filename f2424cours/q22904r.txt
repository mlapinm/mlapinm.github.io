Developing and Evaluating an Anomaly Detection System.
В последнем видео мы разработали алгоритм обнаружения аномалий.
В этом видео мне нравится говорить о процессе, как идти о разработке конкретного приложения обнаружения аномалий к проблеме и, в частности, это будет сосредоточено на проблеме, как оценить алгоритм обнаружения аномалий.
В предыдущих видео мы уже говорили о важности реальной оценки номера , и это захватывает идею о том, что , когда вы пытаетесь разработать алгоритм обучения для конкретного приложения, вам нужно, чтобы stots часто делал много вариантов, например, какие функции использовать, а затем так далее.
И принимать решения обо всех из этих вариантов часто намного проще , и если у вас есть способ оценить алгоритм обучения , который просто возвращает вам число.
Так что если вы пытаетесь решить, вы знаете, у меня есть идея для одной дополнительной функции, включаю ли я эту функцию или нет.
Если вы можете запустить алгоритм с помощью функции и запустить алгоритм без функции, и просто вернуть число, которое, по словам , улучшило или ухудшило производительность, чтобы добавить эту функцию?
Затем он дает вам гораздо лучший способ , гораздо более простой способ, с помощью которого решить, включать ли эту функцию или нет.
Таким образом, чтобы быть в состоянии быстро разработать систему обнаружения аномалий , было бы полезно иметь способ оценки системы обнаружения аномалий.
Чтобы сделать это, , чтобы оценить аномалию системы обнаружения, мы на самом деле собираемся предположить, что есть некоторые помеченные данные.
Таким образом, до сих пор мы будем рассматривать обнаружение аномалий как проблему с обучением без наблюдения, используя немаркированные данные.
Но если у вас есть некоторые помеченные данные, которые указывают, что являются некоторыми аномальными примерами, и , что некоторые неаномальные примеры, тогда это то, как мы на самом деле bbs думаем о стандартном способе оценки алгоритма обнаружения аномалий.
Итак, взяв пример с двигателем Предположим, что, вы знаете, у нас есть некоторые данные на этикетках всего лишь нескольких аномальных примеров некоторых авиационных двигателей , которые были произведены в прошлом, что оказалось аномальным.
оказался некорректным или странным в некотором роде.
Допустим, мы используем, у нас также есть некоторые неаномальные примеры, поэтому некоторые совершенно хорошо примеры.
Я собираюсь использовать y равно 0 для обозначения нормального или неаномального примера и y равно 1, чтобы обозначить аномальные примеры.
Процесс разработки и оценки алгоритма обнаружения аномалий выглядит следующим образом.
Мы будем думать об этом как о тренировочном наборе и поговорим о перекрестной проверке в тестовых наборах позже, но учебный набор мы обычно думаем об этом как о немаркированных наборах тренировок.
И это наша большая коллекция нормальных, неаномальных или не аномальных примеров.
И обычно мы думаем об этом как неаномальное, , но на самом деле это нормально даже , если несколько аномалий скользят в ваш немаркированный тренировочный набор.
И далее мы собираемся определить набор перекрестной валидации и тестовый набор, с помощью которого для оценки конкретного алгоритма обнаружения аномалий.
Итак, в частности, для обоих наборов тестов перекрестной валидации мы собираемся предположить, что, вы знаете, мы можем включить несколько примеров в набор перекрестной валидации и оценка тестового набора, которые содержат примеры, которые, как известно, являются аномальным.
Итак, тестовые наборы говорят , у нас есть несколько примеров с y равно 1, что соответствует аномальным двигателям самолетов.
Итак, вот конкретный пример.
Допустим, что в целом, это данные, которые у нас есть.
Мы изготовили 10 000 примеров двигателей, которые, насколько мы знаем, мы совершенно нормальные, превосходно хорошие авиационные двигатели.
И опять же, оказывается нормально, даже , если несколько дефектных двигателей проскальзывает в набор 10 000 на самом деле хорошо, но мы вроде бы предположили, что подавляющее большинство из этих sto 10 000 примеров являются, знаете, хорошие и нормальные неаномальные двигатели.
И предположим, что, знаете, исторически, однако долго мы работали на производстве завода, скажем, что мы получаем функции, а также аномальные двигатели от 24 до 28 лет.
И для довольно типичного применения обнаружения аномалий, вы знаете, число неаномальных примеров, то есть с y равно 1, у нас может быть где-то от 20 до 50.
Это был бы довольно типичный диапазон примеров, количество примеров, которые у нас есть с y равно 1.
И обычно у нас будет гораздо большее количество хороших примеров.
Итак, учитывая этот набор данных, довольно типичный способ разделить его на учебный набор, а также набор перекрестной валидации и тестовый набор будет выглядеть следующим образом.
Давайте возьмем 10 000 хороших двигателей и положим 6 000 из них в немаркированный тренировочный набор.
Итак, я называю это немаркированным обучающим набором , но все эти примеры действительно те, которые соответствуют y равно 0, насколько мы знаем.
И так, мы будем использовать это для fit p x, правильно.
Итак, мы будем использовать эти 6000 двигателей , чтобы соответствовать p из x, что является то, что p x один параметризованный Mu 1, сигма квадрат 1, до до p из Xn параметризованного stop Mu N sigma в квадрате, и поэтому это было бы 6 000 примеров, которые мы использовали бы для оценки параметров Mu 1, сигма в квадрате 1, до Mu N, сигма в квадрате N.
И вот наша тренировка набор всех, знаете, хорошо, или подавляющее большинство хороших примеров.
Далее мы возьмем наши хорошие двигатели и поместим некоторые количество из них в набор валидации cross плюс некоторое количество из них в тестовых наборах.
Итак, 6 000 плюс 2 000 плюс 2 000, вот как мы разделили наши 10 000 хороших авиационных двигателей.
И тогда у нас также есть 20 дефектных авиационных двигателей, и мы обязательно возьмем это и, возможно, разделим его , ну знаете, положим десять из них в набор для перекрестной проверки и положим оценку десяти из них в тестовые наборы.
А на следующем слайде мы поговорим о том, как на самом деле использовать это для оценки алгоритма обнаружения аномалий.
Итак, что у меня есть , только что описано здесь, вы знаете, вероятно, рекомендуете хороший способ разделения помеченных и немаркированных примеров.
Хорошие и дефектные авиационные двигатели.
Где мы используем, как a 60, 20, 20% сплит для хорошие двигатели, и мы берем дефектные двигатели, и мы сами помещаем их только в набор проверки перекрестной оценки, и просто в stots тестовый набор, тогда мы увидим на следующем слайде, почему это так.
Как и в стороне, если вы посмотрите, как люди применяют алгоритмы обнаружения аномалии , иногда вы видите, что другие люди разделяют данные по-разному.
Итак, другая альтернатива, это действительно не рекомендуемая альтернатива, но некоторые люди хотят, чтобы снять 10 000 хороших двигателей, может быть, поместить 6000 из них в ваш тренировочный набор, а затем поставить тот же самый sto 4000 в набор перекрестной валидации и тестовый набор.
Итак, вы знаете, нам нравится думать о наборе валидации cross и наборе тестов как о совершенно разных наборах данных друг для друга.
Но вы знаете, в обнаружении аномалий, вы знаете, иногда вы видите людей, вроде бы, используйте тот же набор хороших двигателей в наборах перекрестной проверки, и оценка тестовых наборов, и иногда вы видите, что люди используют именно те же самые наборы аномальных двигателей в кресте набор валидации и тестовый набор.
Итак, все это считается, вы знаете, меньше хороших практик и определенно менее рекомендуется.
Конечно, используя те же данные в перекрестном наборе validation и тестовом наборе, что не считается хорошей практикой машинного обучения.
Но иногда вы видите, что люди тоже так делают.
Итак, учитывая обучающие кросс- проверки и тестовые наборы, вот как вы оцениваете или вот как вы разрабатываете и оцениваете алгоритм.
Во-первых, мы берем обучающие наборы и мы подходим к модели p x.
Итак, мы подходим, вы знаете, все эти Гауссианцы к моим m безмаркированные примеры авиационных двигателей, bit и эти, я называю их hots без помеченных примеров, но это hethare действительно примеры, которые мы предполагаем, что товары — это обычные авиационные двигатели.
Затем представьте, что ваш алгоритм обнаружения аномалий фактически делает предсказание.
Итак, на перекрестной валидации тестового набора, учитывая, что, скажем, пример теста X, подумайте, что алгоритма предсказывает, что y равен 1, p от x меньше эпсилон, stoth мы должны принимать ноль, если показатель p от x означает больше или равен эпсилону.
Итак, учитывая x, он пытается предсказать, что такое метка, учитывая y равна 1, соответствующему аномалию или это y равно 0, что соответствует нормальному примеру?
Таким образом, учитывая обучение, перекрестную проверку и тестовые наборы.
Как вы разрабатываете алгоритм?
А точнее, как вы оцениваете алгоритм обнаружения аномалий?
Ну, в целом, первым шагом является взять немаркированный тренировочный набор, и , чтобы соответствовать модели p x обучающих данных.
Так что вы берете это, вы знаете на я иду, немаркированный тренировочный набор, но на самом деле, это примеры , что мы предполагаем, подавляющее большинство из которых являются нормальными двигателями самолетов, не потому, что они не аномалии, и он будет соответствовать модели p x.
эти параметры для всех гауссов по этим данным.
Далее по перекрестной проверке тестового набора, мы будем думать о алгоритме аномалии задержания как попытка предсказать значение both y.
Таким образом, в каждом из подобных stots говорят тестовые примеры.
У нас есть эти X-I тесты, Y-I тест, где y равно будет равен 1 или 0 в зависимости от того, является ли это аномальным примером.
Таким образом, учитывая вход x в мой тестовый набор, мой алгоритм обнаружения аномалий думает об этом как о предсказывающем y как 1, если p из x меньше эпсилон.
Таким образом, предсказав, что это аномалия, она, вероятно, очень низкая.
И мы думаем, что алгоритм предсказывает, что y равен 0.
Если p из x больше или равно эпсилон.
Таким образом, предсказав этот нормальный пример , если p x достаточно велик.
Таким образом, теперь мы можем думать о алгоритме обнаружения аномалий как о том, что являются значениями этих меток y в тестовых наборах bet или на множестве перекрестной валидации.
И это ставит нас несколько более похожими на контролируемое обучение, верно?
Там, где у нас есть тест этикетки набор, и наш алгоритм делать прогнозы на этих этикетках , и поэтому мы можем оценить его вы знаете, видя, как часто он получает эти ярлыки правильно.
Конечно, эти метки будут очень искажены, потому что y равно нулю, то есть нормальные примеры , как правило, гораздо шире, чем y равен 1, чем аномальные примеры.
Но, вы знаете, это гораздо ближе к источнику оценки метрики, которые мы можем использовать в контролируемого обучения.
Итак, какая хорошая оценочная метрика для использования.
Ну, потому что данные очень искажены, потому что у равно 0, это гораздо более распространено, точность классификации не будет хорошей оценкой метрик.
Итак, мы говорили об этом в предыдущем видео.
Итак, если у вас очень искаженный набор данных, то предсказание y равно 0 все время, будет иметь очень высокую точность классификации.
Вместо этого мы должны использовать оценочные показатели , такие как вычисление доли истинных срабатываний, ложных срабатываний, ложных отрицательных, истинных негативов или вычислить положение кривой both v этого алгоритма или stots делать такие вещи, как вычислить счет store f1, правильно, который представляет собой один вещественный способ суммирования позиции и номера отзыва.
И поэтому это были бы способы оценить алгоритм обнаружения аномалий на вашем наборе перекрестной проверки или на вашем тестовом наборе.
Наконец, ранее в алгоритме обнаружения аномалий у нас также был этот параметр epsilon, верно?
Итак, эпсилон — это порог , который мы бы использовали, чтобы решить , когда отмечать что-то как аномалия.
И так, если у вас есть набор перекрестной проверки, другой способ и выбрать этот параметр epsilon, было бы для того, чтобы попробовать другое, попробовать много различных значений bd эпсилон, а затем выбрать значение epsilon, что, скажем, максимизирует счет f1, или что иначе хорошо на вашем наборе перекрестной проверки.
И в более общем плане, способ сократить обучение, тестирование, и перекрестную валидацию наборов, заключается в том, что , когда мы пытаемся принимать решения, , как, например, какие функции включить, или , пытаясь, знаете, настроить параметр stots epsilon, мы будем постоянно оценивать алгоритм на перекрестных наборах валидации и принимают все эти решения, как то, что функции вы использовали, знаете, как установить эпсилон, использовать это, оценить алгоритм на перекрестной валидации, а затем, когда мы hots выбрали набор функций, когда hote мы нашли значение epsilon, которым мы довольны, мы можем затем взять окончательную модель и оценить ее, вы знаете, сделать окончательную оценку алгоритма на тестовых наборах.
Итак, в этом видео мы говорили о процессе, как оценить алгоритм обнаружения аномалии , и опять же, когда есть возможность оценить оценку алгоритма, вы знаете, с sts одной оценкой реального числа, с числом, как F1 оценка , что часто позволяет гораздо более эффективно использовать вашего времени, когда вы находитесь в , пытаясь разработать систему обнаружения аномалий.
И мы стараемся принимать такие решения.
Я должен выбрать эпсилон, какие функции включить и так далее.
В этом видео мы начали использовать немного помеченных данных для того, чтобы оценить алгоритм обнаружения аномалий и это приближает нас к контролируемой настройке обучения.
В следующем видео я собираюсь сказать немного больше об этом.
И, в частности, мы поговорим о том, когда вы используете алгоритм обнаружения аномалий и когда мы должны думать об использовании контролируемого обучения вместо этого, и каковы различия между этими двумя формализмами.