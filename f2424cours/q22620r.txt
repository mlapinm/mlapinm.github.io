Error Metrics for Skewed Classes.В предыдущем видео я говорил об анализе ошибок и о важности наличия метрик ошибки , то есть иметь единичную метрику оценки реального числа для вашего алгоритма обучения, чтобы сказать, насколько хорошо он работает.
Play video starting at ::14 and follow transcript0:14
В контексте оценки
Play video starting at ::16 and follow transcript0:16
и метрики ошибок, есть один важный случай, когда особенно сложно придумать с соответствующей метрикой ошибки, b или оценочной метрикой, для вашего алгоритма обучения.
Play video starting at ::28 and follow transcript0:28
Это случай того, что называют перекошенными классами.
Play video starting at ::32 and follow transcript0:32
Позвольте мне рассказать вам, что это значит.
Play video starting at ::36 and follow transcript0:36
Рассмотрим проблему классификации рака , где у нас есть особенности медицинских пациентов и мы хотим решить, есть ли у них рак. Это похоже на пример классификации злокачественных по сравнению с доброкачественной опухолью , который мы имели ранее.
Play video starting at ::51 and follow transcript0:51
Итак, скажем, у равен 1, если у пациента рак и у равен 0 , если у него нет. Мы обучили прогрессирующий классификатор и скажем мы тестируем наш классификатор на тестовый набор и обнаруживаем, что мы получаем ошибку 1 процента. Итак, мы поставили 99% правильный диагноз. Кажется, действительно впечатляющий результат, верно. Мы правильные 99% времени.
Play video starting at :1:12 and follow transcript1:12
Но теперь, скажем, мы выясним , что только 0,5 процента пациентов в наших наборах для тренировок на самом деле имеют рак. Так что только половина процентов пациентов, которые проходят через наш скрининг-процесс, имеют рак.
Play video starting at :1:26 and follow transcript1:26
В этом случае ошибка 1% больше не выглядит столь впечатляющей.
Play video starting at :1:31 and follow transcript1:31
И в частности, вот кусок кода, вот на самом деле кусок кода, не обучающего, который принимает этот ввод функций x, и он игнорирует его. Он просто устанавливает y равно 0 и всегда предсказывает, вы знаете, никто не имеет рака, и этот алгоритм на самом деле получит ошибку 0,5 процента. Так что это даже лучше, чем ошибка 1%, которую мы получали только сейчас , и это алгоритм обучения non , который вы знаете, это просто предсказание y равно 0 все время.
Play video starting at :1:57 and follow transcript1:57
Таким образом, эта настройка, когда отношение положительных к отрицательных примеров очень близко к одной из двух крайностей, где, в этом случае, количество положительных примеров bbbt много, stots гораздо меньше, чем число cothing отрицательных примеров, потому что y cetting равняется одному так редко, это - это то, что мы называем случай искаженными классами.
Play video starting at :2:20 and follow transcript2:20
У нас просто намного больше примеров из одного класса , чем из другого класса. И просто предсказав y равно 0 все время, или, может быть, наше предсказание y равно 1 все время, алгоритм может работать довольно хорошо. Таким образом, проблема с использованием ошибки классификации или точности классификации в качестве нашей оценочной метрики следующая.
Play video starting at :2:40 and follow transcript2:40
Допустим, у вас есть один алгоритм соединения , который получает точность 99,2%.
Play video starting at :2:46 and follow transcript2:46
Итак, это ошибка 0,8%. Допустим, вы внесите изменения в свой алгоритм , и теперь вы получаете точность 99,5%.
Play video starting at :2:59 and follow transcript2:59
Это ошибка 0.5%.
Play video starting at :3:4 and follow transcript3:04
Итак, это улучшение алгоритма или нет? Одна из приятных вещей о наличии одной реальной метрики оценки номера - это этот помогает нам быстро решить, нужно ли нам просто хорошее изменение алгоритма или нет. С точностью 99,2% до 99,5%.
Play video starting at :3:21 and follow transcript3:21
Знаете, мы только что сделали что-то полезное или же мы просто заменили наш код на что-то, что просто предсказывает y равно nero чаще? Итак, если у вас очень искаженные классы , становится намного сложнее использовать только точность классификации, потому что вы можете получить очень высокую точность классификации или очень низкие ошибки, и dembit это не всегда ясно, действительно ли stots делает это действительно улучшает качество вашего классификатора , потому что предсказание y равно 0 все время не похоже на особенно хороший классификатор.
Play video starting at :3:53 and follow transcript3:53
Но просто предсказание y равно 0 больше часто может привести к вашей ошибке до, вы знаете, может быть, как низкий, как 0,5%. Когда мы сталкиваемся с такими асимметричными классами, поэтому мы хотели бы придумать с другой метрикой ошибки или другой метрикой оценки. Одной из таких оценочных метрик являются , что называется повторной точностью.
Play video starting at :4:15 and follow transcript4:15
Позвольте мне объяснить, что это такое.
Play video starting at :4:17 and follow transcript4:17
Допустим, мы оцениваем классификатор на тестовом наборе. Для примеров в наборе тестов фактический класс
Play video starting at :4:25 and follow transcript4:25
этого примера в тестовом наборе будет иметь либо один, либо ноль, право, , если есть бинарная проблема классификации.
Play video starting at :4:33 and follow transcript4:33
И то, что наш алгоритм обучения сделает, это, вы знаете, предсказать некоторое значение для и наш алгоритм обучения будет предсказывать значение для каждого примера в моем наборе тестов , а прогнозируемое значение также будет либо одним, либо нулевым.
Play video starting at :4:50 and follow transcript4:50
Итак, позвольте мне нарисовать две на две таблицы следующим образом, в зависимости от полного этих записей в зависимости от того, что было фактическим классом и что было прогнозируемым классом. Если у нас есть пример , где фактический класс один, а предсказанный класс один, то это называется
Play video starting at :5:7 and follow transcript5:07
пример, который является истинным положительным, то это означает, что наш алгоритм stots предсказал, что это положительный результат, а на самом деле пример положительный. Если наш алгоритм обучения предсказал, что что-то отрицательное, класс ноль, и фактический класс также равен классу нулю, то это то, что называется истинным отрицательным. Мы предсказали ноль, и он на самом деле равен нулю.
Play video starting at :5:27 and follow transcript5:27
Чтобы найти две другие коробки, , если наш алгоритм обучения предсказывает, что класс один, а фактический класс
Play video starting at :5:34 and follow transcript5:34
равен нулю, тогда , который называется ложным положительным.
Play video starting at :5:39 and follow transcript5:39
Это означает, что наш алгоритм для пациент отменяется в реальности , если пациент этого не делает.
Play video starting at :5:44 and follow transcript5:44
И, наконец, последняя коробка равна нулю, единицу. Это называется ложным отрицательным , потому что наш алгоритм предсказал ноль, но фактический класс был одним.
Play video starting at :5:57 and follow transcript5:57
Итак, у нас есть такие маленькие две по две таблицы, основанные на , что было фактическим классом и что было предсказанным классом.
Play video starting at :6:7 and follow transcript6:07
Итак, вот другой способ оценки производительности нашего алгоритма. Мы собираемся вычислить два числа. Первый называется точность - и что это говорит,
Play video starting at :6:17 and follow transcript6:17
всех пациентов, где мы предсказал, что у них рак,
Play video starting at :6:20 and follow transcript6:20
, какая доля из них на самом деле рак?
Play video starting at :6:24 and follow transcript6:24
Итак, позвольте мне записать это, точность классификатора это число истинных положительных , деленное на
Play video starting at :6:32 and follow transcript6:32
число, которое мы предсказывали
Play video starting at :6:37 and follow transcript6:37
как положительный, верно?
Play video starting at :6:39 and follow transcript6:39
Из всех пациентов, которые мы пошли к этим пациентам и сказали им: «Мы думаем, что у вас рак». Из всех этих пациентов, какая у доля из них на самом деле рак? Так это называется точность. И еще один способ написать это будет истинными позитивами и то в знаменателе - это количество предсказанных положительных, и так, что бы сумма bit, вы знаете, записей в этой первой строке таблицы. Таким образом, это были бы истинные позитивы, разделенные на истинные позитивы. Я собираюсь аббревиатуру положительного как POS, а затем плюс ложные срабатывания, опять же аббревиатура положительного с помощью POS.
Play video starting at :7:20 and follow transcript7:20
Так что это называется точностью, и, как вы можете сказать, высокая точность будет хорошо. Это означает, что все пациенты , к которым мы пришли и сказали: «Знаете, нам очень жаль. Мы думаем, что у вас рак», высокая точность означает, что из этой группы пациентов, большинство из них , мы сделали точные предсказания о них, и у них есть рак.
Play video starting at :7:38 and follow transcript7:38
Второе число, которое мы собираемся вычислить , называется отзывом, и то, что вспомнить говорят, что если все пациенты в, допустим, в тестовом наборе или в наборе bet-cross validation, но если stots все пациенты в наборе данных, которые на самом деле имеют рак, мы правильно обнаруживаем как имеющую рак. Итак, если у всех пациентов есть рак, сколько из них мы на самом деле пошли к ним и вы знаете, правильно сказали им, что мы думаем, что им нужно лечение.
Play video starting at :8:5 and follow transcript8:05
Итак, записывая это, вспомнить определяется как число положительных, число истинных положительных, означает количество людей, у которых есть рак, и что stoth, который мы правильно предсказали, имеют рак, и мы берем это и делим, что на, разделяем это число на реальных положительных результатов,
Play video starting at :8:31 and follow transcript8:31
, так что это правильное количество фактических положительных результатов всех людей, у которых рак. Какую фракцию мы непосредственно флаг и вы знаете, отправить лечение.
Play video starting at :8:40 and follow transcript8:40
Итак, чтобы переписать это в другой форме, знаменателем будет количество фактических положительных , как вы знаете, это сумма записей в этом первом столбце здесь.
Play video starting at :8:50 and follow transcript8:50
И поэтому записывать вещи по-другому, это значит, количество истинных положительных, деленное на
Play video starting at :8:59 and follow transcript8:59
количество истинных положительных
Play video starting at :9:2 and follow transcript9:02
плюс количество bood ложных негативов.
Play video starting at :9:9 and follow transcript9:09
И так еще раз, иметь высокий отзыв было бы хорошо.
Play video starting at :9:14 and follow transcript9:14
Таким образом, вычисляя точность и , это обычно дает нам лучшее представление о , насколько хорошо работает наш классификатор.
Play video starting at :9:21 and follow transcript9:21
И, в частности, если у нас есть алгоритм обучения, который предсказывает y равен нулю все время, если он не предсказывает, что у кого-то нет рака, тогда этот классификатор будет иметь отметку , равную нулю, , потому что не будет никаких оценок истинных положительных результатов и так что это sts быстрый способ для нас, чтобы сказать, что, вы знаете, классификатор, который предсказывает y равен 0 все время, просто не очень хороший классификатор. И в более общем плане, даже для настроек, где у нас очень искаженные классы, это не возможно для алгоритма типа «обмануть», и каким-то образом получить очень высокую точность stots и очень высокий отзыв, делая некоторые простые вещи, такие как предсказание heth y равно 0 все время или предсказание y равно 1 все время. И поэтому мы гораздо более уверены, что классификатор высокой точности или высокой отзыва на самом деле является хорошим классификатором, , и это дает нам оценку более полезной метрике оценки, что stoth-это более прямой способ, чтобы thethi действительно понять, может ли наш алгоритм работать хорошо.
Play video starting at :10:21 and follow transcript10:21
Так что одно последнее примечание в определение точности и вспомнить, что мы бы определили точность и отзыв, как правило, мы используем соглашение, что у равно 1, в метках присутствие более редкого класса. Так что, если мы пытаемся обнаружить. редкие условия, такие как рак, надеюсь, что это редкое условие, точность и отзыв являются определенные установки y равно 1, а не y равно 0, чтобы быть своего рода stots, что присутствие этого редкого класса, который мы пытаемся обнаружить. И используя точность и отзыв, мы находим, что происходит, это , что даже если у нас есть очень искаженные классы, это не возможность для алгоритма, чтобы оценить вы знаете, «обмануть» и предсказать stots y равно 1 все время, stay или предсказать y равно 0 все время, и получить высокую точность и вспомнить. И в частности, если классификатор получает высокую точность и высокий отзыв, то мы на самом деле уверены, что алгоритм должен работать хорошо, даже , если у нас очень искаженные классы.
Play video starting at :11:18 and follow transcript11:18
Таким образом, для проблемы искаженные классы точность отзыв дает нам больше прямое понимание того, как алгоритм обучения делает , и это часто намного лучше способ оценить наши алгоритмы обучения, stoth, чем смотреть на классификационную ошибку или точность классификации, когда классы очень перекосы.