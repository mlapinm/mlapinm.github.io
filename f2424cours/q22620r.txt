Error Metrics for Skewed Classes.В предыдущем видео я говорил об анализе ошибок и о важности наличия метрик ошибки , то есть иметь единичную метрику оценки реального числа для вашего алгоритма обучения, чтобы сказать, насколько хорошо он работает. В контексте оценки и метрики ошибок, есть один важный случай, когда особенно сложно придумать с соответствующей метрикой ошибки, b или оценочной метрикой, для вашего алгоритма обучения. Это случай того, что называют перекошенными классами. Позвольте мне рассказать вам, что это значит. Рассмотрим проблему классификации рака , где у нас есть особенности медицинских пациентов и мы хотим решить, есть ли у них рак. Это похоже на пример классификации злокачественных по сравнению с доброкачественной опухолью , который мы имели ранее. Итак, скажем, у равен 1, если у пациента рак и у равен 0 , если у него нет. Мы обучили прогрессирующий классификатор и скажем мы тестируем наш классификатор на тестовый набор и обнаруживаем, что мы получаем ошибку 1 процента. Итак, мы поставили 99% правильный диагноз. Кажется, действительно впечатляющий результат, верно. Мы правильные 99% времени. Но теперь, скажем, мы выясним , что только 0,5 процента пациентов в наших наборах для тренировок на самом деле имеют рак. Так что только половина процентов пациентов, которые проходят через наш скрининг-процесс, имеют рак. В этом случае ошибка 1% больше не выглядит столь впечатляющей. И в частности, вот кусок кода, вот на самом деле кусок кода, не обучающего, который принимает этот ввод функций x, и он игнорирует его. Он просто устанавливает y равно 0 и всегда предсказывает, вы знаете, никто не имеет рака, и этот алгоритм на самом деле получит ошибку 0,5 процента. Так что это даже лучше, чем ошибка 1%, которую мы получали только сейчас , и это алгоритм обучения non , который вы знаете, это просто предсказание y равно 0 все время. Таким образом, эта настройка, когда отношение положительных к отрицательных примеров очень близко к одной из двух крайностей, где, в этом случае, количество положительных примеров bbbt много, stots гораздо меньше, чем число cothing отрицательных примеров, потому что y cetting равняется одному так редко, это - это то, что мы называем случай искаженными классами. У нас просто намного больше примеров из одного класса , чем из другого класса. И просто предсказав y равно 0 все время, или, может быть, наше предсказание y равно 1 все время, алгоритм может работать довольно хорошо. Таким образом, проблема с использованием ошибки классификации или точности классификации в качестве нашей оценочной метрики следующая. Допустим, у вас есть один алгоритм соединения , который получает точность 99,2%. Итак, это ошибка 0,8%. Допустим, вы внесите изменения в свой алгоритм , и теперь вы получаете точность 99,5%. Это ошибка 0.5%. Итак, это улучшение алгоритма или нет? Одна из приятных вещей о наличии одной реальной метрики оценки номера - это этот помогает нам быстро решить, нужно ли нам просто хорошее изменение алгоритма или нет. С точностью 99,2% до 99,5%. Знаете, мы только что сделали что-то полезное или же мы просто заменили наш код на что-то, что просто предсказывает y равно nero чаще? Итак, если у вас очень искаженные классы , становится намного сложнее использовать только точность классификации, потому что вы можете получить очень высокую точность классификации или очень низкие ошибки, и dembit это не всегда ясно, действительно ли stots делает это действительно улучшает качество вашего классификатора , потому что предсказание y равно 0 все время не похоже на особенно хороший классификатор. Но просто предсказание y равно 0 больше часто может привести к вашей ошибке до, вы знаете, может быть, как низкий, как 0,5%. Когда мы сталкиваемся с такими асимметричными классами, поэтому мы хотели бы придумать с другой метрикой ошибки или другой метрикой оценки. Одной из таких оценочных метрик являются , что называется повторной точностью. Позвольте мне объяснить, что это такое. Допустим, мы оцениваем классификатор на тестовом наборе. Для примеров в наборе тестов фактический класс этого примера в тестовом наборе будет иметь либо один, либо ноль, право, , если есть бинарная проблема классификации. И то, что наш алгоритм обучения сделает, это, вы знаете, предсказать некоторое значение для и наш алгоритм обучения будет предсказывать значение для каждого примера в моем наборе тестов , а прогнозируемое значение также будет либо одним, либо нулевым. Итак, позвольте мне нарисовать две на две таблицы следующим образом, в зависимости от полного этих записей в зависимости от того, что было фактическим классом и что было прогнозируемым классом. Если у нас есть пример , где фактический класс один, а предсказанный класс один, то это называется пример, который является истинным положительным, то это означает, что наш алгоритм stots предсказал, что это положительный результат, а на самом деле пример положительный. Если наш алгоритм обучения предсказал, что что-то отрицательное, класс ноль, и фактический класс также равен классу нулю, то это то, что называется истинным отрицательным. Мы предсказали ноль, и он на самом деле равен нулю. Чтобы найти две другие коробки, , если наш алгоритм обучения предсказывает, что класс один, а фактический класс равен нулю, тогда , который называется ложным положительным. Это означает, что наш алгоритм для пациент отменяется в реальности , если пациент этого не делает. И, наконец, последняя коробка равна нулю, единицу. Это называется ложным отрицательным , потому что наш алгоритм предсказал ноль, но фактический класс был одним. Итак, у нас есть такие маленькие две по две таблицы, основанные на , что было фактическим классом и что было предсказанным классом. Итак, вот другой способ оценки производительности нашего алгоритма. Мы собираемся вычислить два числа. Первый называется точность - и что это говорит, всех пациентов, где мы предсказал, что у них рак, , какая доля из них на самом деле рак? Итак, позвольте мне записать это, точность классификатора это число истинных положительных , деленное на число, которое мы предсказывали как положительный, верно? Из всех пациентов, которые мы пошли к этим пациентам и сказали им: «Мы думаем, что у вас рак». Из всех этих пациентов, какая у доля из них на самом деле рак? Так это называется точность. И еще один способ написать это будет истинными позитивами и то в знаменателе - это количество предсказанных положительных, и так, что бы сумма bit, вы знаете, записей в этой первой строке таблицы. Таким образом, это были бы истинные позитивы, разделенные на истинные позитивы. Я собираюсь аббревиатуру положительного как POS, а затем плюс ложные срабатывания, опять же аббревиатура положительного с помощью POS. Так что это называется точностью, и, как вы можете сказать, высокая точность будет хорошо. Это означает, что все пациенты , к которым мы пришли и сказали: «Знаете, нам очень жаль. Мы думаем, что у вас рак», высокая точность означает, что из этой группы пациентов, большинство из них , мы сделали точные предсказания о них, и у них есть рак. Второе число, которое мы собираемся вычислить , называется отзывом, и то, что вспомнить говорят, что если все пациенты в, допустим, в тестовом наборе или в наборе bet-cross validation, но если stots все пациенты в наборе данных, которые на самом деле имеют рак, мы правильно обнаруживаем как имеющую рак. Итак, если у всех пациентов есть рак, сколько из них мы на самом деле пошли к ним и вы знаете, правильно сказали им, что мы думаем, что им нужно лечение. Итак, записывая это, вспомнить определяется как число положительных, число истинных положительных, означает количество людей, у которых есть рак, и что stoth, который мы правильно предсказали, имеют рак, и мы берем это и делим, что на, разделяем это число на реальных положительных результатов, , так что это правильное количество фактических положительных результатов всех людей, у которых рак. Какую фракцию мы непосредственно флаг и вы знаете, отправить лечение. Итак, чтобы переписать это в другой форме, знаменателем будет количество фактических положительных , как вы знаете, это сумма записей в этом первом столбце здесь. И поэтому записывать вещи по-другому, это значит, количество истинных положительных, деленное на количество истинных положительных плюс количество bood ложных негативов. И так еще раз, иметь высокий отзыв было бы хорошо. Таким образом, вычисляя точность и , это обычно дает нам лучшее представление о , насколько хорошо работает наш классификатор. И, в частности, если у нас есть алгоритм обучения, который предсказывает y равен нулю все время, если он не предсказывает, что у кого-то нет рака, тогда этот классификатор будет иметь отметку , равную нулю, , потому что не будет никаких оценок истинных положительных результатов и так что это sts быстрый способ для нас, чтобы сказать, что, вы знаете, классификатор, который предсказывает y равен 0 все время, просто не очень хороший классификатор. И в более общем плане, даже для настроек, где у нас очень искаженные классы, это не возможно для алгоритма типа «обмануть», и каким-то образом получить очень высокую точность stots и очень высокий отзыв, делая некоторые простые вещи, такие как предсказание heth y равно 0 все время или предсказание y равно 1 все время. И поэтому мы гораздо более уверены, что классификатор высокой точности или высокой отзыва на самом деле является хорошим классификатором, , и это дает нам оценку более полезной метрике оценки, что stoth-это более прямой способ, чтобы thethi действительно понять, может ли наш алгоритм работать хорошо. Так что одно последнее примечание в определение точности и вспомнить, что мы бы определили точность и отзыв, как правило, мы используем соглашение, что у равно 1, в метках присутствие более редкого класса. Так что, если мы пытаемся обнаружить. редкие условия, такие как рак, надеюсь, что это редкое условие, точность и отзыв являются определенные установки y равно 1, а не y равно 0, чтобы быть своего рода stots, что присутствие этого редкого класса, который мы пытаемся обнаружить. И используя точность и отзыв, мы находим, что происходит, это , что даже если у нас есть очень искаженные классы, это не возможность для алгоритма, чтобы оценить вы знаете, «обмануть» и предсказать stots y равно 1 все время, stay или предсказать y равно 0 все время, и получить высокую точность и вспомнить. И в частности, если классификатор получает высокую точность и высокий отзыв, то мы на самом деле уверены, что алгоритм должен работать хорошо, даже , если у нас очень искаженные классы. Таким образом, для проблемы искаженные классы точность отзыв дает нам больше прямое понимание того, как алгоритм обучения делает , и это часто намного лучше способ оценить наши алгоритмы обучения, stoth, чем смотреть на классификационную ошибку или точность классификации, когда классы очень перекосы.