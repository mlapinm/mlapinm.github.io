Collaborative Filtering Algorithm.
В последних нескольких видео, мы говорили о идеях как, во-первых, если вы дали функции для фильмов, вы можете использовать это, чтобы узнать параметры данных для пользователей.
И во-вторых, если вам заданы параметры для пользователей, вы можете использовать их для изучения возможностей фильмов.
В этом видео мы собираемся взять эти идеи и положить их вместе, чтобы придумать с алгоритмом совместной фильтрации.
Таким образом, одна из вещей, которые мы разработали ранее, заключается в том, что если у вас есть функции для фильмов , то вы можете решить эту проблему минимизации, чтобы найти параметры theta для ваших пользователей.
И тогда мы также проработали, что, если вам заданы параметры theta, вы также можете использовать это для того, чтобы оценить особенности x, и вы можете это сделать, решив эту проблему минимизации.
Так что одна вещь, которую вы могли бы сделать, это идти туда и обратно.
Может быть, случайным образом инициализировать параметры , а затем решить для теты, решить для х, решить для теты, решить для х.
Но, это оказывается, что есть более эффективный алгоритм, который не stots нужно идти вперед и назад между х и hettas h's hetas, но это может решить для тета и x одновременно.
И вот оно.
То, что мы собираемся сделать, в основном взять обе эти цели оптимизации, и положить их в одну и ту же цель.
Итак, я собираюсь определить новую цель оптимизации j, которая является функцией стоимости, что является функцией моих функций x и функцией моих параметров тета.
И, это в основном две цели оптимизации , которые я имел на вершине, но я собрал вместе.
Итак, для того, чтобы объяснить это, во-первых, я хочу отметить, что этот термин здесь, этот квадратный термин ошибки , это тот же самый , что и этот квадратный термин ошибки, и суммирования bots немного отличаются, но давайте посмотрим, что на самом деле делают суммирования.
Первое суммирование является суммой над всеми пользователями J и затем суммой по всем фильмам, оцененным этим пользователем.
Итак, это действительно суммирование всех пар IJ, которые соответствуют фильму, который был оценен пользователем.
Сумма над J говорит, для каждого пользователя сумма всех фильмов, оцененных этим пользователем.
Это суммирование здесь, просто делает вещи в обратном порядке.
Это говорит для каждого фильма I, сумма по всем пользователей J, которые имеют оценили этот фильм и так, вы знаете эти суммирования, оба эти bot- это просто суммирование по всем парам sts ij, для которых stand r i J равен 1.
Это просто что-то над всеми пользовательскими кинопарами , для которых у вас есть рейтинг.
и так эти два условия , есть только именно этот первый термин, и Я только что написал суммирование здесь явно, , где я просто говорю сумму итога всех пар IJ, так что st RIJ равен 1.
Итак, что мы собираемся сделать, это определить комплексную цель оптимизации , которую мы хотим минимизировать для того, чтобы решать одновременно для x и тета.
А затем другие термины в цель оптимизации это, который является регуляризацией с точки зрения тета.
Так что пришел сюда и последний кусок это термин, который является моя цель оптимизации для х и это стало таковым.
И эта цель оптимизации j на самом деле имеет интересное свойство , что если бы вы были держать константу x и просто минимизировать по отношению к тетам, то вы бы решали именно эту проблему, stoth в то время как если бы вы делали это наоборот, если бы вы удерживайте константу thetas и сворачивайте j только по отношению к x, тогда она становится эквивалентной этому.
Потому что либо этот термин , либо этот термин является постоянным, если вы минимизируете только соответствующие x или только соответствующие thetas.
Итак, вот цель оптимизации , которая объединяет мои функции стоимости с точки зрения x и с точки зрения тета.
И для того, чтобы придумать только одну проблему оптимизации , то, что мы собираемся сделать, это рассматривать эту функцию стоимости , как функцию bot-моих особенностей, и моего пользователя vot-pro данных пользовательских параметров и wetting просто минимизировать все это, как function Xs и функция thetas.
И действительно единственное различие между этим и более старым алгоритмом заключается в том, что вместо из того, чтобы идти вперед и назад, ранее мы говорили о минимизации по отношению к тете, а затем минимизации по отношению к x, stoth в то время как минимизация по отношению к тете, минимизация по отношению к x и так далее.
В этой новой версии вместо последовательно идущие между 2 наборами параметров x и theta, то, что мы собираемся сделать просто минимизирует в отношении к обоим наборам параметров одновременно.
Наконец, одна последняя деталь заключается в том, что, когда мы изучаем особенности таким образом.
Ранее мы использовали это соглашение, что у нас есть функция x0, равная , которая соответствует перехватчику.
Когда мы используем этот вид формализма, где мы фактически изучаем функции, мы фактически собираемся покончить с этим соглашением.
И поэтому функции, которые мы будем изучать x, будут в Rn.
В то время как ранее у нас были функции x и Rn + 1, включая термин перехвата.
Избавившись от x0, мы теперь просто имеем x в Rn.
И так же, поскольку параметры theta находятся в в том же измерении, мы теперь также имеем theta в RN , потому что если нет значения x0, то нет необходимости stots параметр theta 0, а также.
И причина, по которой мы уходим с этой конвенцией, заключается в том, что мы изучаем все функции, верно?
Таким образом, нет необходимости жестко кодировать функцию, которая всегда равна единице.
Потому что, если алгоритм действительно хочет функцию, которая всегда равна 1, он может выбрать один для себя.
Таким образом, если алгоритм выбирает, он может установить функцию X1 равным 1.
Так что нет необходимости для жесткого кода функции 001, алгоритм теперь имеет гибкость, чтобы просто узнать его сам по себе.
Итак, собрав все вместе, вот наш алгоритм совместной фильтрации.
сначала мы собираемся инициализировать x и тета для небольших случайных значений.
И это немного , как обучение нейронной сети, где мы также инициализировали все параметры нейронной сети до небольших случайных значений.
Далее мы идем , чтобы минимизировать функцию затрат, используя большие перехваты или один из передовых алгоритмов оптимизации.
Итак, если вы берете производные, вы обнаружите, что большой перехват , как эти, и поэтому этот термин здесь является частичной производной от функции стоимости, Я не собираюсь записывать, что, ost в отношении функции stamote значение Xik и аналогично частичное производное значение функции стоимости по отношению к параметру тета, который мы минимизируем.
И как напоминание, в эта формула, что мы больше не это X0 равно 1 и поэтому у нас есть , что x находится в Rn, а тета - Rn.
В этом новом формализме мы регуляризируем каждый из наших периметров тета, знаете, каждый из наших параметров Xn.
Больше нет специального case theta zero, который был регуляризован по-разному, или который не был регуляризован по сравнению с параметры theta 1 до theta.
Так что теперь нет тета 0, поэтому в этих обновлениях, я не вырвал специальный случай для k равно 0.
Таким образом, мы используем градиентный спуск для минимизации стоимости функции j по отношению к функциям x и по отношению к параметрам тета.
И, наконец, учитывая пользователя , если у пользователя есть некоторые параметры, тета, и , если есть фильм с какой-то изученный особенности x, both мы тогда предсказываем, что stot-фильму будет присвоен рейтинг stabet-star этим пользователем от theta transpose j.
Или просто чтобы заполнить их, то мы говорим, что если пользователь J еще не рейтинг фильм I, то то, что мы делаем, это предсказать, что пользователь J собирается произведать скорость фильма I в соответствии со spotheta J транспонировать Xi.
Так что это совместный алгоритм фильтрации , и если вы реализуете этот алгоритм, вы на самом деле получаете довольно достойный алгоритм , который будет одновременно научить хорошие функции для надеюсь, что будет обучить все фильмы, а также параметры stoth узнать для всех пользователей сайта и, надеюсь, дать довольно хорошие прогнозы о том, как разные пользователи будут оценивать разные фильмы, которые они еще не оценили